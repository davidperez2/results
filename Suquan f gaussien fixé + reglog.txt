Images -> gris
f=tf.Variable(initial_value=tf.range(-10,10,20/576,dtype=tf.float32),trainable=False)
f fixé
pas de distored_inputs


EVALUATION


2018-02-02 11:25:28.104005: precision @ 1 = 0.101
2018-02-02 11:26:14.646423: precision @ 1 = 0.122
2018-02-02 11:27:04.881118: precision @ 1 = 0.129
2018-02-02 11:27:49.401741: precision @ 1 = 0.135
2018-02-02 11:28:40.639789: precision @ 1 = 0.132
2018-02-02 11:29:30.716066: precision @ 1 = 0.133
2018-02-02 11:30:15.253860: precision @ 1 = 0.135
2018-02-02 11:31:06.368076: precision @ 1 = 0.135
2018-02-02 11:31:51.813113: precision @ 1 = 0.134
2018-02-02 11:32:40.729689: precision @ 1 = 0.133
2018-02-02 11:33:30.475857: precision @ 1 = 0.133
2018-02-02 11:34:15.867169: precision @ 1 = 0.131
2018-02-02 11:35:06.011140: precision @ 1 = 0.135
2018-02-02 11:35:51.234641: precision @ 1 = 0.132
2018-02-02 11:36:40.521387: precision @ 1 = 0.132
2018-02-02 11:37:29.395847: precision @ 1 = 0.130
2018-02-02 11:38:15.128089: precision @ 1 = 0.132
2018-02-02 11:39:05.709701: precision @ 1 = 0.133
2018-02-02 11:39:52.136027: precision @ 1 = 0.131
2018-02-02 11:40:42.128083: precision @ 1 = 0.133


LOSS (Train)



2018-02-02 11:25:11.293731: step 0, loss = 2.58 (2650.9 examples/sec; 0.048 sec/batch)
2018-02-02 11:25:13.840877: step 100, loss = 112.69 (5025.2 examples/sec; 0.025 sec/batch)
2018-02-02 11:25:16.059865: step 200, loss = 127.97 (5768.4 examples/sec; 0.022 sec/batch)
2018-02-02 11:25:18.185092: step 300, loss = 99.03 (6022.9 examples/sec; 0.021 sec/batch)
2018-02-02 11:25:20.857251: step 400, loss = 118.61 (4790.1 examples/sec; 0.027 sec/batch)
2018-02-02 11:25:23.064130: step 500, loss = 116.14 (5800.0 examples/sec; 0.022 sec/batch)
2018-02-02 11:25:25.103684: step 600, loss = 117.83 (6275.9 examples/sec; 0.020 sec/batch)
2018-02-02 11:25:27.338298: step 700, loss = 100.02 (5728.1 examples/sec; 0.022 sec/batch)
2018-02-02 11:25:28.869711: step 800, loss = 112.31 (8358.3 examples/sec; 0.015 sec/batch)
2018-02-02 11:25:30.057338: step 900, loss = 124.85 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:31.260592: step 1000, loss = 126.90 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:32.463844: step 1100, loss = 118.03 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:33.651471: step 1200, loss = 114.73 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:34.864161: step 1300, loss = 108.66 (10555.0 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:36.067415: step 1400, loss = 94.22 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:37.270667: step 1500, loss = 117.59 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:38.473921: step 1600, loss = 105.71 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:39.677174: step 1700, loss = 127.51 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:41.552374: step 1800, loss = 119.25 (6825.9 examples/sec; 0.019 sec/batch)
2018-02-02 11:25:42.820621: step 1900, loss = 126.53 (10092.7 examples/sec; 0.013 sec/batch)
2018-02-02 11:25:44.055538: step 2000, loss = 124.33 (10365.1 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:45.450399: step 2100, loss = 119.22 (9176.5 examples/sec; 0.014 sec/batch)
2018-02-02 11:25:47.068949: step 2200, loss = 116.29 (7908.3 examples/sec; 0.016 sec/batch)
2018-02-02 11:25:48.287829: step 2300, loss = 100.08 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:49.584842: step 2400, loss = 122.55 (9868.8 examples/sec; 0.013 sec/batch)
2018-02-02 11:25:50.850602: step 2500, loss = 105.48 (10112.5 examples/sec; 0.013 sec/batch)
2018-02-02 11:25:52.085109: step 2600, loss = 126.52 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:53.335243: step 2700, loss = 101.82 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 11:25:54.554122: step 2800, loss = 118.03 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:25:55.808068: step 2900, loss = 114.27 (10207.8 examples/sec; 0.013 sec/batch)
2018-02-02 11:25:57.058202: step 3000, loss = 106.56 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 11:25:58.339590: step 3100, loss = 133.01 (9989.2 examples/sec; 0.013 sec/batch)
2018-02-02 11:25:59.620976: step 3200, loss = 118.06 (9989.2 examples/sec; 0.013 sec/batch)
2018-02-02 11:26:01.855590: step 3300, loss = 125.58 (5728.1 examples/sec; 0.022 sec/batch)
2018-02-02 11:26:04.192779: step 3400, loss = 109.11 (5476.7 examples/sec; 0.023 sec/batch)
2018-02-02 11:26:06.583063: step 3500, loss = 112.45 (5355.0 examples/sec; 0.024 sec/batch)
2018-02-02 11:26:08.911437: step 3600, loss = 111.87 (5497.4 examples/sec; 0.023 sec/batch)
2018-02-02 11:26:15.333997: step 3700, loss = 108.33 (1993.0 examples/sec; 0.064 sec/batch)
2018-02-02 11:26:16.537250: step 3800, loss = 125.81 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:17.740503: step 3900, loss = 111.87 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:18.943756: step 4000, loss = 115.74 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:20.147010: step 4100, loss = 112.15 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:21.350264: step 4200, loss = 132.96 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:22.590144: step 4300, loss = 118.44 (10323.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:23.786692: step 4400, loss = 123.31 (10697.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:24.987564: step 4500, loss = 109.08 (10658.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:26.190817: step 4600, loss = 112.33 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:27.378444: step 4700, loss = 122.61 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:28.581697: step 4800, loss = 117.63 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:29.769324: step 4900, loss = 97.80 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:30.972578: step 5000, loss = 115.08 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:32.160204: step 5100, loss = 126.88 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:33.363457: step 5200, loss = 114.76 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:34.582338: step 5300, loss = 117.91 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:35.780002: step 5400, loss = 124.28 (10687.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:36.983256: step 5500, loss = 112.09 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:38.170882: step 5600, loss = 109.89 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:39.358509: step 5700, loss = 122.73 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:41.124323: step 5800, loss = 106.28 (7248.8 examples/sec; 0.018 sec/batch)
2018-02-02 11:26:42.327576: step 5900, loss = 113.71 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:43.553886: step 6000, loss = 106.79 (10437.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:44.741514: step 6100, loss = 114.78 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:45.944766: step 6200, loss = 129.21 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:26:47.398046: step 6300, loss = 106.91 (8807.7 examples/sec; 0.015 sec/batch)
2018-02-02 11:26:49.684048: step 6400, loss = 119.65 (5599.3 examples/sec; 0.023 sec/batch)
2018-02-02 11:26:52.137436: step 6500, loss = 105.12 (5217.3 examples/sec; 0.025 sec/batch)
2018-02-02 11:26:54.340795: step 6600, loss = 107.42 (5809.3 examples/sec; 0.022 sec/batch)
2018-02-02 11:26:56.434579: step 6700, loss = 118.04 (6113.3 examples/sec; 0.021 sec/batch)
2018-02-02 11:26:58.872339: step 6800, loss = 115.74 (5250.7 examples/sec; 0.024 sec/batch)
2018-02-02 11:27:01.122579: step 6900, loss = 110.13 (5688.3 examples/sec; 0.023 sec/batch)
2018-02-02 11:27:03.396585: step 7000, loss = 126.35 (5628.8 examples/sec; 0.023 sec/batch)
2018-02-02 11:27:05.428052: step 7100, loss = 115.89 (6300.9 examples/sec; 0.020 sec/batch)
2018-02-02 11:27:06.630763: step 7200, loss = 126.63 (10642.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:07.834017: step 7300, loss = 119.88 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:09.021643: step 7400, loss = 129.26 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:10.834337: step 7500, loss = 103.37 (7061.3 examples/sec; 0.018 sec/batch)
2018-02-02 11:27:12.021963: step 7600, loss = 123.92 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:13.225216: step 7700, loss = 125.71 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:14.490976: step 7800, loss = 126.20 (10112.5 examples/sec; 0.013 sec/batch)
2018-02-02 11:27:15.772363: step 7900, loss = 121.12 (9989.2 examples/sec; 0.013 sec/batch)
2018-02-02 11:27:16.975616: step 8000, loss = 111.19 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:18.174330: step 8100, loss = 106.02 (10678.1 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:19.377584: step 8200, loss = 99.90 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:20.565211: step 8300, loss = 117.02 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:21.752837: step 8400, loss = 113.89 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:22.965335: step 8500, loss = 122.51 (10556.7 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:24.184215: step 8600, loss = 109.33 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:25.371841: step 8700, loss = 113.62 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:26.564991: step 8800, loss = 119.50 (10727.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:27.799498: step 8900, loss = 117.89 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:29.002751: step 9000, loss = 100.71 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:30.174751: step 9100, loss = 111.21 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:31.393632: step 9200, loss = 122.80 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:32.596884: step 9300, loss = 111.59 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:33.815764: step 9400, loss = 124.04 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:35.034644: step 9500, loss = 105.51 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:36.253525: step 9600, loss = 113.91 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:38.410004: step 9700, loss = 106.17 (5935.6 examples/sec; 0.022 sec/batch)
2018-02-02 11:27:46.510808: step 9800, loss = 108.86 (1580.1 examples/sec; 0.081 sec/batch)
2018-02-02 11:27:48.714167: step 9900, loss = 111.28 (5809.3 examples/sec; 0.022 sec/batch)
2018-02-02 11:27:50.245581: step 10000, loss = 115.02 (8358.3 examples/sec; 0.015 sec/batch)
2018-02-02 11:27:51.451396: step 10100, loss = 126.98 (10615.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:52.654650: step 10200, loss = 112.74 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:53.857903: step 10300, loss = 119.75 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:55.045529: step 10400, loss = 111.17 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:56.263009: step 10500, loss = 114.67 (10513.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:57.466262: step 10600, loss = 105.09 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:58.669516: step 10700, loss = 113.17 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:27:59.872768: step 10800, loss = 102.35 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:01.066681: step 10900, loss = 129.88 (10721.1 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:02.269933: step 11000, loss = 130.23 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:03.458491: step 11100, loss = 121.65 (10769.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:04.661743: step 11200, loss = 126.94 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:05.864996: step 11300, loss = 128.34 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:07.068250: step 11400, loss = 114.03 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:08.287130: step 11500, loss = 103.08 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:09.492286: step 11600, loss = 102.60 (10621.0 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:11.289353: step 11700, loss = 111.52 (7122.7 examples/sec; 0.018 sec/batch)
2018-02-02 11:28:12.492607: step 11800, loss = 106.07 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:13.711485: step 11900, loss = 115.83 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:14.914739: step 12000, loss = 107.99 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:16.117993: step 12100, loss = 120.11 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:17.336873: step 12200, loss = 111.46 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:18.540125: step 12300, loss = 126.23 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:19.759006: step 12400, loss = 128.90 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:20.991623: step 12500, loss = 110.90 (10384.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:22.716048: step 12600, loss = 110.57 (7422.8 examples/sec; 0.017 sec/batch)
2018-02-02 11:28:24.872528: step 12700, loss = 123.23 (5935.6 examples/sec; 0.022 sec/batch)
2018-02-02 11:28:26.888322: step 12800, loss = 122.70 (6349.9 examples/sec; 0.020 sec/batch)
2018-02-02 11:28:28.935415: step 12900, loss = 116.45 (6252.8 examples/sec; 0.020 sec/batch)
2018-02-02 11:28:31.185655: step 13000, loss = 116.10 (5688.3 examples/sec; 0.023 sec/batch)
2018-02-02 11:28:33.545282: step 13100, loss = 113.06 (5424.6 examples/sec; 0.024 sec/batch)
2018-02-02 11:28:35.561122: step 13200, loss = 113.29 (6349.7 examples/sec; 0.020 sec/batch)
2018-02-02 11:28:37.639469: step 13300, loss = 120.00 (6158.7 examples/sec; 0.021 sec/batch)
2018-02-02 11:28:39.842828: step 13400, loss = 113.23 (5809.3 examples/sec; 0.022 sec/batch)
2018-02-02 11:28:42.249335: step 13500, loss = 112.31 (5318.9 examples/sec; 0.024 sec/batch)
2018-02-02 11:28:43.446473: step 13600, loss = 114.13 (10692.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:44.665353: step 13700, loss = 113.10 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:45.852980: step 13800, loss = 109.02 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:47.056233: step 13900, loss = 110.40 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:48.243860: step 14000, loss = 128.37 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:49.558414: step 14100, loss = 106.19 (9737.1 examples/sec; 0.013 sec/batch)
2018-02-02 11:28:50.871054: step 14200, loss = 110.89 (9751.3 examples/sec; 0.013 sec/batch)
2018-02-02 11:28:52.105561: step 14300, loss = 118.63 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:53.371321: step 14400, loss = 118.37 (10112.5 examples/sec; 0.013 sec/batch)
2018-02-02 11:28:54.574573: step 14500, loss = 117.47 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:55.777828: step 14600, loss = 111.72 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:56.988439: step 14700, loss = 125.87 (10573.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:58.199942: step 14800, loss = 117.34 (10565.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:28:59.410795: step 14900, loss = 124.41 (10571.1 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:00.629676: step 15000, loss = 131.53 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:01.817302: step 15100, loss = 115.68 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:03.026567: step 15200, loss = 124.97 (10584.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:04.229820: step 15300, loss = 114.04 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:05.433073: step 15400, loss = 104.79 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:06.636327: step 15500, loss = 114.30 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:07.839580: step 15600, loss = 113.30 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:09.058460: step 15700, loss = 103.97 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:10.902617: step 15800, loss = 134.79 (6940.8 examples/sec; 0.018 sec/batch)
2018-02-02 11:29:12.137123: step 15900, loss = 107.68 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:14.449869: step 16000, loss = 112.05 (5534.5 examples/sec; 0.023 sec/batch)
2018-02-02 11:29:16.512589: step 16100, loss = 114.24 (6205.4 examples/sec; 0.021 sec/batch)
2018-02-02 11:29:18.700324: step 16200, loss = 103.10 (5850.8 examples/sec; 0.022 sec/batch)
2018-02-02 11:29:20.997442: step 16300, loss = 113.58 (5572.2 examples/sec; 0.023 sec/batch)
2018-02-02 11:29:23.216447: step 16400, loss = 119.52 (5768.4 examples/sec; 0.022 sec/batch)
2018-02-02 11:29:25.435435: step 16500, loss = 125.99 (5768.4 examples/sec; 0.022 sec/batch)
2018-02-02 11:29:27.514464: step 16600, loss = 114.78 (6156.7 examples/sec; 0.021 sec/batch)
2018-02-02 11:29:30.153505: step 16700, loss = 114.17 (4850.2 examples/sec; 0.026 sec/batch)
2018-02-02 11:29:31.622412: step 16800, loss = 121.32 (8714.0 examples/sec; 0.015 sec/batch)
2018-02-02 11:29:32.841293: step 16900, loss = 123.20 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:34.044546: step 17000, loss = 115.02 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:35.247799: step 17100, loss = 115.50 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:36.451052: step 17200, loss = 105.87 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:37.664245: step 17300, loss = 110.56 (10550.7 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:38.867499: step 17400, loss = 124.01 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:40.633312: step 17500, loss = 117.00 (7248.8 examples/sec; 0.018 sec/batch)
2018-02-02 11:29:41.831724: step 17600, loss = 117.79 (10680.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:43.014103: step 17700, loss = 105.18 (10825.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:44.217357: step 17800, loss = 105.59 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:45.436237: step 17900, loss = 109.55 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:46.655117: step 18000, loss = 110.14 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:47.842744: step 18100, loss = 118.52 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:49.065053: step 18200, loss = 110.33 (10472.0 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:50.268307: step 18300, loss = 119.71 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:51.487186: step 18400, loss = 120.74 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:52.690440: step 18500, loss = 117.18 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:53.893693: step 18600, loss = 109.95 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:55.096947: step 18700, loss = 104.91 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:56.300200: step 18800, loss = 109.81 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:57.503453: step 18900, loss = 128.41 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:58.717604: step 19000, loss = 115.46 (10542.3 examples/sec; 0.012 sec/batch)
2018-02-02 11:29:59.920858: step 19100, loss = 113.63 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:01.139737: step 19200, loss = 113.87 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:02.499257: step 19300, loss = 131.45 (9415.1 examples/sec; 0.014 sec/batch)
2018-02-02 11:30:04.978964: step 19400, loss = 112.79 (5161.9 examples/sec; 0.025 sec/batch)
2018-02-02 11:30:07.314784: step 19500, loss = 119.74 (5479.9 examples/sec; 0.023 sec/batch)
2018-02-02 11:30:09.831106: step 19600, loss = 112.96 (5086.8 examples/sec; 0.025 sec/batch)
2018-02-02 11:30:16.343611: step 19700, loss = 118.60 (1965.4 examples/sec; 0.065 sec/batch)
2018-02-02 11:30:17.573925: step 19800, loss = 102.02 (10403.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:18.808431: step 19900, loss = 120.71 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:20.038855: step 20000, loss = 114.19 (10402.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:21.257735: step 20100, loss = 126.18 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:22.507868: step 20200, loss = 122.06 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 11:30:23.716545: step 20300, loss = 114.51 (10590.1 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:24.951051: step 20400, loss = 105.32 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:26.133695: step 20500, loss = 122.05 (10823.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:27.336948: step 20600, loss = 132.35 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:28.555996: step 20700, loss = 124.39 (10500.0 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:29.753540: step 20800, loss = 105.80 (10688.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:30.956793: step 20900, loss = 116.11 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:32.144419: step 21000, loss = 119.52 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:33.363299: step 21100, loss = 105.40 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:34.566553: step 21200, loss = 98.34 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:35.769806: step 21300, loss = 115.87 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:36.988686: step 21400, loss = 111.29 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:38.176313: step 21500, loss = 130.37 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:39.379567: step 21600, loss = 109.42 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:41.207886: step 21700, loss = 123.89 (7001.0 examples/sec; 0.018 sec/batch)
2018-02-02 11:30:42.411140: step 21800, loss = 118.27 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:43.614488: step 21900, loss = 109.56 (10637.0 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:44.802115: step 22000, loss = 121.26 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:46.020994: step 22100, loss = 109.75 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:30:47.568035: step 22200, loss = 111.80 (8273.9 examples/sec; 0.015 sec/batch)
2018-02-02 11:30:49.607721: step 22300, loss = 105.73 (6275.5 examples/sec; 0.020 sec/batch)
2018-02-02 11:30:51.873586: step 22400, loss = 118.83 (5649.1 examples/sec; 0.023 sec/batch)
2018-02-02 11:30:53.967560: step 22500, loss = 123.80 (6112.8 examples/sec; 0.021 sec/batch)
2018-02-02 11:30:56.074662: step 22600, loss = 105.68 (6074.7 examples/sec; 0.021 sec/batch)
2018-02-02 11:30:58.293647: step 22700, loss = 120.56 (5768.4 examples/sec; 0.022 sec/batch)
2018-02-02 11:31:00.486398: step 22800, loss = 117.94 (5837.4 examples/sec; 0.022 sec/batch)
2018-02-02 11:31:02.736639: step 22900, loss = 114.51 (5688.3 examples/sec; 0.023 sec/batch)
2018-02-02 11:31:04.727276: step 23000, loss = 110.54 (6430.1 examples/sec; 0.020 sec/batch)
2018-02-02 11:31:06.680610: step 23100, loss = 121.30 (6552.9 examples/sec; 0.020 sec/batch)
2018-02-02 11:31:07.899490: step 23200, loss = 125.90 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:09.087117: step 23300, loss = 121.09 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:10.868557: step 23400, loss = 119.94 (7185.2 examples/sec; 0.018 sec/batch)
2018-02-02 11:31:12.056183: step 23500, loss = 115.75 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:13.259436: step 23600, loss = 118.24 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:14.462703: step 23700, loss = 117.49 (10637.7 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:15.681583: step 23800, loss = 113.44 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:16.884837: step 23900, loss = 122.81 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:18.088090: step 24000, loss = 122.37 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:19.275716: step 24100, loss = 120.32 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:20.457243: step 24200, loss = 116.41 (10833.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:21.644871: step 24300, loss = 120.01 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:22.848123: step 24400, loss = 111.30 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:24.048505: step 24500, loss = 125.52 (10663.3 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:25.236130: step 24600, loss = 110.99 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:26.455010: step 24700, loss = 116.68 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:27.642637: step 24800, loss = 115.41 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:28.830264: step 24900, loss = 112.76 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:30.038652: step 25000, loss = 116.42 (10592.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:31.241906: step 25100, loss = 112.95 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:32.445159: step 25200, loss = 135.44 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:33.664039: step 25300, loss = 117.73 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:34.874846: step 25400, loss = 121.36 (10571.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:36.078100: step 25500, loss = 116.43 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:37.328233: step 25600, loss = 115.21 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 11:31:39.071622: step 25700, loss = 107.82 (7342.0 examples/sec; 0.017 sec/batch)
2018-02-02 11:31:46.076119: step 25800, loss = 120.42 (1827.4 examples/sec; 0.070 sec/batch)
2018-02-02 11:31:48.341986: step 25900, loss = 117.47 (5649.1 examples/sec; 0.023 sec/batch)
2018-02-02 11:31:50.562980: step 26000, loss = 113.42 (5763.2 examples/sec; 0.022 sec/batch)
2018-02-02 11:31:52.375673: step 26100, loss = 115.09 (7061.3 examples/sec; 0.018 sec/batch)
2018-02-02 11:31:53.578927: step 26200, loss = 113.92 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:54.782180: step 26300, loss = 111.44 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:56.016687: step 26400, loss = 105.42 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:57.204313: step 26500, loss = 101.80 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:58.391940: step 26600, loss = 114.54 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:31:59.579566: step 26700, loss = 116.95 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:00.791086: step 26800, loss = 107.14 (10565.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:01.978712: step 26900, loss = 115.48 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:03.191725: step 27000, loss = 111.95 (10552.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:04.379353: step 27100, loss = 124.53 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:05.582605: step 27200, loss = 117.83 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:06.770232: step 27300, loss = 127.59 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:07.942233: step 27400, loss = 115.29 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:09.145485: step 27500, loss = 112.77 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:10.973805: step 27600, loss = 113.86 (7001.0 examples/sec; 0.018 sec/batch)
2018-02-02 11:32:12.177059: step 27700, loss = 110.47 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:13.391355: step 27800, loss = 101.88 (10541.1 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:14.563356: step 27900, loss = 105.40 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:15.775280: step 28000, loss = 123.58 (10561.7 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:16.962907: step 28100, loss = 109.16 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:18.181787: step 28200, loss = 114.70 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:19.369414: step 28300, loss = 120.52 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:20.583620: step 28400, loss = 105.76 (10541.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:21.771248: step 28500, loss = 116.91 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:22.993421: step 28600, loss = 120.45 (10473.1 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:25.196781: step 28700, loss = 113.10 (5809.3 examples/sec; 0.022 sec/batch)
2018-02-02 11:32:27.712674: step 28800, loss = 118.24 (5087.7 examples/sec; 0.025 sec/batch)
2018-02-02 11:32:30.119179: step 28900, loss = 100.62 (5318.9 examples/sec; 0.024 sec/batch)
2018-02-02 11:32:32.400674: step 29000, loss = 113.81 (5610.4 examples/sec; 0.023 sec/batch)
2018-02-02 11:32:34.479020: step 29100, loss = 118.70 (6158.7 examples/sec; 0.021 sec/batch)
2018-02-02 11:32:36.916780: step 29200, loss = 126.08 (5250.7 examples/sec; 0.024 sec/batch)
2018-02-02 11:32:39.135767: step 29300, loss = 119.97 (5768.4 examples/sec; 0.022 sec/batch)
2018-02-02 11:32:41.886060: step 29400, loss = 120.13 (4654.0 examples/sec; 0.028 sec/batch)
2018-02-02 11:32:43.106994: step 29500, loss = 128.51 (10483.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:44.325874: step 29600, loss = 100.25 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:45.513500: step 29700, loss = 111.09 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:46.728453: step 29800, loss = 110.68 (10535.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:47.916080: step 29900, loss = 112.06 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:49.119332: step 30000, loss = 120.15 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:50.306960: step 30100, loss = 100.27 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:51.505154: step 30200, loss = 111.57 (10682.7 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:52.737412: step 30300, loss = 120.47 (10387.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:53.925039: step 30400, loss = 115.09 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:55.128291: step 30500, loss = 128.73 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:56.331545: step 30600, loss = 120.90 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:57.519172: step 30700, loss = 113.84 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:58.738052: step 30800, loss = 116.51 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:32:59.941305: step 30900, loss = 114.11 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:01.144559: step 31000, loss = 110.44 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:02.332429: step 31100, loss = 111.81 (10775.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:03.541302: step 31200, loss = 114.09 (10588.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:04.728928: step 31300, loss = 126.23 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:05.967352: step 31400, loss = 121.61 (10335.7 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:07.186233: step 31500, loss = 116.82 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:08.389485: step 31600, loss = 104.14 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:09.608365: step 31700, loss = 114.49 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:11.405432: step 31800, loss = 114.47 (7122.7 examples/sec; 0.018 sec/batch)
2018-02-02 11:33:12.983728: step 31900, loss = 117.43 (8110.0 examples/sec; 0.016 sec/batch)
2018-02-02 11:33:15.155833: step 32000, loss = 111.77 (5892.9 examples/sec; 0.022 sec/batch)
2018-02-02 11:33:17.234179: step 32100, loss = 122.93 (6158.7 examples/sec; 0.021 sec/batch)
2018-02-02 11:33:19.578178: step 32200, loss = 120.22 (5460.8 examples/sec; 0.023 sec/batch)
2018-02-02 11:33:22.062819: step 32300, loss = 121.88 (5151.7 examples/sec; 0.025 sec/batch)
2018-02-02 11:33:24.256443: step 32400, loss = 109.01 (5835.1 examples/sec; 0.022 sec/batch)
2018-02-02 11:33:26.491058: step 32500, loss = 116.34 (5728.1 examples/sec; 0.022 sec/batch)
2018-02-02 11:33:28.788177: step 32600, loss = 112.58 (5572.2 examples/sec; 0.023 sec/batch)
2018-02-02 11:33:30.781527: step 32700, loss = 121.41 (6421.4 examples/sec; 0.020 sec/batch)
2018-02-02 11:33:31.984781: step 32800, loss = 117.61 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:33.202584: step 32900, loss = 108.77 (10510.7 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:34.405837: step 33000, loss = 131.47 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:35.609090: step 33100, loss = 106.94 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:36.812343: step 33200, loss = 119.08 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:38.015596: step 33300, loss = 111.26 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:39.187597: step 33400, loss = 114.35 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:40.953410: step 33500, loss = 126.90 (7248.8 examples/sec; 0.018 sec/batch)
2018-02-02 11:33:42.172290: step 33600, loss = 122.79 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:43.374247: step 33700, loss = 102.82 (10649.3 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:44.561874: step 33800, loss = 121.25 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:45.749501: step 33900, loss = 113.39 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:46.968380: step 34000, loss = 128.98 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:48.171635: step 34100, loss = 111.47 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:49.406141: step 34200, loss = 130.61 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:50.625021: step 34300, loss = 110.20 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:51.812648: step 34400, loss = 113.03 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:53.045252: step 34500, loss = 100.61 (10384.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:54.232879: step 34600, loss = 117.78 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:55.436132: step 34700, loss = 110.30 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:56.655012: step 34800, loss = 114.27 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:57.827013: step 34900, loss = 105.68 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:33:59.030268: step 35000, loss = 100.86 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:00.233519: step 35100, loss = 134.63 (10637.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:01.468025: step 35200, loss = 108.93 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:02.936932: step 35300, loss = 118.48 (8714.0 examples/sec; 0.015 sec/batch)
2018-02-02 11:34:05.174858: step 35400, loss = 115.52 (5719.6 examples/sec; 0.022 sec/batch)
2018-02-02 11:34:07.143819: step 35500, loss = 113.75 (6500.9 examples/sec; 0.020 sec/batch)
2018-02-02 11:34:09.425312: step 35600, loss = 105.03 (5610.4 examples/sec; 0.023 sec/batch)
2018-02-02 11:34:16.523489: step 35700, loss = 111.59 (1803.3 examples/sec; 0.071 sec/batch)
2018-02-02 11:34:17.726741: step 35800, loss = 121.10 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:18.929995: step 35900, loss = 117.57 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:20.123007: step 36000, loss = 126.23 (10729.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:21.320953: step 36100, loss = 108.90 (10685.0 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:22.524688: step 36200, loss = 117.30 (10633.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:23.732592: step 36300, loss = 119.85 (10596.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:24.951473: step 36400, loss = 112.95 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:26.121791: step 36500, loss = 128.30 (10937.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:27.325044: step 36600, loss = 120.03 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:28.528297: step 36700, loss = 114.83 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:29.715924: step 36800, loss = 110.74 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:30.957101: step 36900, loss = 118.01 (10312.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:32.160354: step 37000, loss = 127.56 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:33.379234: step 37100, loss = 109.12 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:34.588078: step 37200, loss = 103.38 (10588.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:35.791331: step 37300, loss = 114.78 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:37.010210: step 37400, loss = 117.47 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:38.197837: step 37500, loss = 112.35 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:39.385464: step 37600, loss = 109.01 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:41.157745: step 37700, loss = 135.48 (7222.3 examples/sec; 0.018 sec/batch)
2018-02-02 11:34:42.360998: step 37800, loss = 126.71 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:43.562215: step 37900, loss = 109.55 (10655.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:44.749842: step 38000, loss = 128.58 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:45.953096: step 38100, loss = 108.96 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:47.187603: step 38200, loss = 109.58 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:34:49.285528: step 38300, loss = 120.43 (6101.3 examples/sec; 0.021 sec/batch)
2018-02-02 11:34:51.526993: step 38400, loss = 123.28 (5710.6 examples/sec; 0.022 sec/batch)
2018-02-02 11:34:53.699100: step 38500, loss = 128.54 (5892.9 examples/sec; 0.022 sec/batch)
2018-02-02 11:34:55.871206: step 38600, loss = 118.51 (5892.9 examples/sec; 0.022 sec/batch)
2018-02-02 11:34:58.090193: step 38700, loss = 117.77 (5768.4 examples/sec; 0.022 sec/batch)
2018-02-02 11:35:00.121659: step 38800, loss = 120.59 (6300.9 examples/sec; 0.020 sec/batch)
2018-02-02 11:35:02.309392: step 38900, loss = 123.98 (5850.8 examples/sec; 0.022 sec/batch)
2018-02-02 11:35:04.734251: step 39000, loss = 105.06 (5278.7 examples/sec; 0.024 sec/batch)
2018-02-02 11:35:06.589328: step 39100, loss = 107.89 (6900.0 examples/sec; 0.019 sec/batch)
2018-02-02 11:35:07.808208: step 39200, loss = 113.25 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:08.995834: step 39300, loss = 122.62 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:10.861993: step 39400, loss = 115.55 (6859.0 examples/sec; 0.019 sec/batch)
2018-02-02 11:35:12.065246: step 39500, loss = 121.72 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:13.268500: step 39600, loss = 125.59 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:14.471753: step 39700, loss = 107.93 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:15.675005: step 39800, loss = 109.04 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:16.893886: step 39900, loss = 107.06 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:18.097139: step 40000, loss = 118.22 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:19.300393: step 40100, loss = 122.73 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:20.503646: step 40200, loss = 114.61 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:21.691273: step 40300, loss = 112.51 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:22.896061: step 40400, loss = 117.33 (10624.3 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:24.087561: step 40500, loss = 119.18 (10742.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:25.275188: step 40600, loss = 117.59 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:26.483362: step 40700, loss = 110.40 (10594.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:27.687702: step 40800, loss = 115.27 (10628.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:28.896090: step 40900, loss = 106.01 (10592.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:30.090765: step 41000, loss = 115.38 (10714.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:31.278391: step 41100, loss = 109.02 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:32.486395: step 41200, loss = 115.60 (10596.0 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:33.689648: step 41300, loss = 111.56 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:34.924155: step 41400, loss = 116.51 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:36.111782: step 41500, loss = 93.23 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:37.361914: step 41600, loss = 117.11 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 11:35:39.299621: step 41700, loss = 102.83 (6605.7 examples/sec; 0.019 sec/batch)
2018-02-02 11:35:46.687281: step 41800, loss = 113.49 (1732.6 examples/sec; 0.074 sec/batch)
2018-02-02 11:35:48.875015: step 41900, loss = 136.24 (5850.8 examples/sec; 0.022 sec/batch)
2018-02-02 11:35:51.172134: step 42000, loss = 107.41 (5572.2 examples/sec; 0.023 sec/batch)
2018-02-02 11:35:52.469149: step 42100, loss = 123.02 (9868.8 examples/sec; 0.013 sec/batch)
2018-02-02 11:35:53.655883: step 42200, loss = 118.85 (10785.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:54.861632: step 42300, loss = 117.85 (10615.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:56.033632: step 42400, loss = 130.64 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:57.236885: step 42500, loss = 118.69 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:58.440139: step 42600, loss = 109.09 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:35:59.627765: step 42700, loss = 114.48 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:00.799765: step 42800, loss = 120.99 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:02.018645: step 42900, loss = 110.70 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:03.266460: step 43000, loss = 122.62 (10257.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:04.469715: step 43100, loss = 114.25 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:05.719847: step 43200, loss = 125.23 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 11:36:06.922912: step 43300, loss = 103.99 (10639.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:08.110539: step 43400, loss = 121.17 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:09.313792: step 43500, loss = 117.89 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:11.102434: step 43600, loss = 119.13 (7156.3 examples/sec; 0.018 sec/batch)
2018-02-02 11:36:12.305689: step 43700, loss = 106.94 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:13.508942: step 43800, loss = 102.22 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:14.712195: step 43900, loss = 124.42 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:15.915449: step 44000, loss = 111.43 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:17.103076: step 44100, loss = 119.57 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:18.321955: step 44200, loss = 106.49 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:19.509582: step 44300, loss = 130.91 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:20.697209: step 44400, loss = 113.07 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:21.931715: step 44500, loss = 120.20 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:23.546921: step 44600, loss = 116.85 (7924.7 examples/sec; 0.016 sec/batch)
2018-02-02 11:36:25.613547: step 44700, loss = 121.44 (6193.7 examples/sec; 0.021 sec/batch)
2018-02-02 11:36:27.754401: step 44800, loss = 121.80 (5978.9 examples/sec; 0.021 sec/batch)
2018-02-02 11:36:30.129654: step 44900, loss = 114.79 (5388.9 examples/sec; 0.024 sec/batch)
2018-02-02 11:36:32.379894: step 45000, loss = 114.52 (5688.3 examples/sec; 0.023 sec/batch)
2018-02-02 11:36:34.692641: step 45100, loss = 112.06 (5534.5 examples/sec; 0.023 sec/batch)
2018-02-02 11:36:37.036640: step 45200, loss = 121.62 (5460.8 examples/sec; 0.023 sec/batch)
2018-02-02 11:36:39.427520: step 45300, loss = 110.61 (5353.7 examples/sec; 0.024 sec/batch)
2018-02-02 11:36:41.943413: step 45400, loss = 114.73 (5087.7 examples/sec; 0.025 sec/batch)
2018-02-02 11:36:43.141544: step 45500, loss = 126.74 (10683.3 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:44.344797: step 45600, loss = 128.85 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:45.561245: step 45700, loss = 117.72 (10522.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:46.764373: step 45800, loss = 99.12 (10638.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:47.983253: step 45900, loss = 124.55 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:49.186507: step 46000, loss = 97.31 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:50.389760: step 46100, loss = 105.17 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:51.624266: step 46200, loss = 120.22 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:52.843146: step 46300, loss = 121.41 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:54.062027: step 46400, loss = 108.65 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:55.258289: step 46500, loss = 99.71 (10700.0 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:56.467514: step 46600, loss = 116.91 (10585.3 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:57.670767: step 46700, loss = 125.52 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:36:58.889647: step 46800, loss = 114.69 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:00.108527: step 46900, loss = 111.03 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:01.311780: step 47000, loss = 116.99 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:02.499407: step 47100, loss = 112.83 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:03.697331: step 47200, loss = 124.71 (10685.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:04.900584: step 47300, loss = 128.34 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:06.088210: step 47400, loss = 119.13 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:07.291465: step 47500, loss = 120.42 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:08.494717: step 47600, loss = 108.79 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:09.700086: step 47700, loss = 113.56 (10619.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:12.903553: step 47800, loss = 112.46 (3995.7 examples/sec; 0.032 sec/batch)
2018-02-02 11:37:15.122539: step 47900, loss = 113.02 (5768.4 examples/sec; 0.022 sec/batch)
2018-02-02 11:37:17.419660: step 48000, loss = 114.23 (5572.2 examples/sec; 0.023 sec/batch)
2018-02-02 11:37:19.357367: step 48100, loss = 108.49 (6605.7 examples/sec; 0.019 sec/batch)
2018-02-02 11:37:21.357579: step 48200, loss = 117.71 (6399.3 examples/sec; 0.020 sec/batch)
2018-02-02 11:37:23.504128: step 48300, loss = 112.47 (5963.1 examples/sec; 0.021 sec/batch)
2018-02-02 11:37:25.644279: step 48400, loss = 99.99 (5980.9 examples/sec; 0.021 sec/batch)
2018-02-02 11:37:27.676912: step 48500, loss = 110.87 (6297.2 examples/sec; 0.020 sec/batch)
2018-02-02 11:37:29.661500: step 48600, loss = 116.46 (6449.7 examples/sec; 0.020 sec/batch)
2018-02-02 11:37:30.864754: step 48700, loss = 108.44 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:32.052380: step 48800, loss = 115.90 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:33.271260: step 48900, loss = 121.30 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:34.474514: step 49000, loss = 113.69 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:35.677767: step 49100, loss = 114.12 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:36.881019: step 49200, loss = 111.50 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:38.084272: step 49300, loss = 109.40 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:39.287527: step 49400, loss = 115.63 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:41.140820: step 49500, loss = 117.33 (6906.6 examples/sec; 0.019 sec/batch)
2018-02-02 11:37:42.328447: step 49600, loss = 119.99 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:43.556287: step 49700, loss = 120.35 (10424.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:44.775167: step 49800, loss = 124.54 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:45.978420: step 49900, loss = 102.19 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:47.181673: step 50000, loss = 120.05 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:48.384927: step 50100, loss = 126.10 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:49.572553: step 50200, loss = 107.95 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:50.760180: step 50300, loss = 121.01 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:51.979060: step 50400, loss = 121.22 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:53.166687: step 50500, loss = 114.11 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:54.369940: step 50600, loss = 103.18 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:55.573193: step 50700, loss = 122.31 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:56.760820: step 50800, loss = 123.97 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:57.991449: step 50900, loss = 117.02 (10401.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:37:59.195431: step 51000, loss = 110.37 (10631.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:00.429939: step 51100, loss = 109.81 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:02.164497: step 51200, loss = 122.37 (7379.4 examples/sec; 0.017 sec/batch)
2018-02-02 11:38:04.433632: step 51300, loss = 131.81 (5640.9 examples/sec; 0.023 sec/batch)
2018-02-02 11:38:06.496353: step 51400, loss = 116.71 (6205.4 examples/sec; 0.021 sec/batch)
2018-02-02 11:38:08.541855: step 51500, loss = 109.32 (6257.6 examples/sec; 0.020 sec/batch)
2018-02-02 11:38:15.534386: step 51600, loss = 122.36 (1830.5 examples/sec; 0.070 sec/batch)
2018-02-02 11:38:16.722008: step 51700, loss = 124.66 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:17.925262: step 51800, loss = 112.29 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:19.112888: step 51900, loss = 116.78 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:20.331768: step 52000, loss = 122.22 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:21.550649: step 52100, loss = 112.46 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:22.753901: step 52200, loss = 116.26 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:23.956004: step 52300, loss = 116.95 (10648.0 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:25.143631: step 52400, loss = 115.76 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:26.362510: step 52500, loss = 113.48 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:27.581389: step 52600, loss = 124.22 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:28.771268: step 52700, loss = 114.01 (10757.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:29.968920: step 52800, loss = 107.19 (10687.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:31.203427: step 52900, loss = 131.45 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:32.391053: step 53000, loss = 123.78 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:33.625560: step 53100, loss = 114.42 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:34.813187: step 53200, loss = 102.91 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:36.016440: step 53300, loss = 115.92 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:37.219693: step 53400, loss = 113.43 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:38.438574: step 53500, loss = 110.42 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:39.657453: step 53600, loss = 123.76 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:41.423267: step 53700, loss = 112.43 (7248.8 examples/sec; 0.018 sec/batch)
2018-02-02 11:38:42.622887: step 53800, loss = 122.96 (10670.0 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:43.845849: step 53900, loss = 124.85 (10466.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:45.033476: step 54000, loss = 122.54 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:46.252357: step 54100, loss = 113.82 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:38:48.143184: step 54200, loss = 114.17 (6769.5 examples/sec; 0.019 sec/batch)
2018-02-02 11:38:50.284037: step 54300, loss = 119.87 (5978.9 examples/sec; 0.021 sec/batch)
2018-02-02 11:38:52.581156: step 54400, loss = 113.74 (5572.2 examples/sec; 0.023 sec/batch)
2018-02-02 11:38:54.487610: step 54500, loss = 106.97 (6714.0 examples/sec; 0.019 sec/batch)
2018-02-02 11:38:56.706596: step 54600, loss = 128.34 (5768.4 examples/sec; 0.022 sec/batch)
2018-02-02 11:38:58.917464: step 54700, loss = 120.85 (5789.6 examples/sec; 0.022 sec/batch)
2018-02-02 11:39:01.167703: step 54800, loss = 110.82 (5688.3 examples/sec; 0.023 sec/batch)
2018-02-02 11:39:03.256315: step 54900, loss = 116.63 (6128.5 examples/sec; 0.021 sec/batch)
2018-02-02 11:39:05.569061: step 55000, loss = 100.92 (5534.5 examples/sec; 0.023 sec/batch)
2018-02-02 11:39:06.866074: step 55100, loss = 107.89 (9868.8 examples/sec; 0.013 sec/batch)
2018-02-02 11:39:08.069328: step 55200, loss = 121.73 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:09.272582: step 55300, loss = 109.53 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:11.100639: step 55400, loss = 113.88 (7002.0 examples/sec; 0.018 sec/batch)
2018-02-02 11:39:12.319519: step 55500, loss = 113.56 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:13.520888: step 55600, loss = 106.60 (10654.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:14.755395: step 55700, loss = 116.01 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:15.927394: step 55800, loss = 119.38 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:17.115021: step 55900, loss = 122.95 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:18.302648: step 56000, loss = 118.80 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:19.505901: step 56100, loss = 111.92 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:20.709155: step 56200, loss = 118.24 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:21.924644: step 56300, loss = 105.95 (10530.7 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:23.127897: step 56400, loss = 119.57 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:24.333441: step 56500, loss = 111.13 (10617.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:25.536694: step 56600, loss = 121.04 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:26.724902: step 56700, loss = 115.14 (10772.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:27.943783: step 56800, loss = 102.65 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:29.147036: step 56900, loss = 102.08 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:30.347444: step 57000, loss = 115.42 (10663.0 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:31.544577: step 57100, loss = 119.55 (10692.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:32.759143: step 57200, loss = 102.20 (10538.7 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:33.946770: step 57300, loss = 114.12 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:35.134397: step 57400, loss = 121.68 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:36.337651: step 57500, loss = 125.05 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:37.556530: step 57600, loss = 114.68 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:39.603624: step 57700, loss = 107.37 (6252.8 examples/sec; 0.020 sec/batch)
2018-02-02 11:39:46.463547: step 57800, loss = 113.87 (1865.9 examples/sec; 0.069 sec/batch)
2018-02-02 11:39:48.666907: step 57900, loss = 112.76 (5809.3 examples/sec; 0.022 sec/batch)
2018-02-02 11:39:50.870267: step 58000, loss = 118.15 (5809.3 examples/sec; 0.022 sec/batch)
2018-02-02 11:39:52.620452: step 58100, loss = 109.78 (7313.5 examples/sec; 0.018 sec/batch)
2018-02-02 11:39:53.823707: step 58200, loss = 115.83 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:55.042587: step 58300, loss = 115.80 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:56.230213: step 58400, loss = 98.86 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:57.449094: step 58500, loss = 109.34 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:58.636720: step 58600, loss = 112.05 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:39:59.855600: step 58700, loss = 110.65 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:01.060454: step 58800, loss = 110.23 (10623.7 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:02.294960: step 58900, loss = 116.10 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:03.510450: step 59000, loss = 122.31 (10530.7 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:04.701397: step 59100, loss = 129.63 (10747.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:05.907085: step 59200, loss = 113.72 (10616.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:07.125965: step 59300, loss = 107.16 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:08.313592: step 59400, loss = 91.65 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:09.516845: step 59500, loss = 124.39 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:11.376418: step 59600, loss = 118.93 (6883.3 examples/sec; 0.019 sec/batch)
2018-02-02 11:40:12.564047: step 59700, loss = 108.83 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:13.784182: step 59800, loss = 122.48 (10490.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:14.983972: step 59900, loss = 119.38 (10668.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:16.207951: step 60000, loss = 120.68 (10457.7 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:17.395577: step 60100, loss = 117.08 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:18.598831: step 60200, loss = 129.20 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:19.786458: step 60300, loss = 114.42 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:20.989711: step 60400, loss = 120.54 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:22.192964: step 60500, loss = 116.12 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:23.416552: step 60600, loss = 115.38 (10461.0 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:25.229246: step 60700, loss = 127.55 (7061.3 examples/sec; 0.018 sec/batch)
2018-02-02 11:40:27.510740: step 60800, loss = 120.01 (5610.4 examples/sec; 0.023 sec/batch)
2018-02-02 11:40:29.651592: step 60900, loss = 121.80 (5978.9 examples/sec; 0.021 sec/batch)
2018-02-02 11:40:31.639309: step 61000, loss = 115.05 (6439.5 examples/sec; 0.020 sec/batch)
2018-02-02 11:40:33.655149: step 61100, loss = 109.22 (6349.7 examples/sec; 0.020 sec/batch)
2018-02-02 11:40:35.701348: step 61200, loss = 113.90 (6255.5 examples/sec; 0.020 sec/batch)
2018-02-02 11:40:37.732816: step 61300, loss = 96.12 (6300.9 examples/sec; 0.020 sec/batch)
2018-02-02 11:40:39.690322: step 61400, loss = 108.51 (6538.9 examples/sec; 0.020 sec/batch)
2018-02-02 11:40:43.411890: step 61500, loss = 99.69 (3439.4 examples/sec; 0.037 sec/batch)
2018-02-02 11:40:44.615142: step 61600, loss = 115.38 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:45.834022: step 61700, loss = 108.68 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:47.078053: step 61800, loss = 114.49 (10289.1 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:48.281306: step 61900, loss = 115.02 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:49.531440: step 62000, loss = 121.22 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 11:40:50.719066: step 62100, loss = 101.99 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:51.922320: step 62200, loss = 113.71 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:53.141200: step 62300, loss = 104.44 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:54.344453: step 62400, loss = 105.36 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:55.563333: step 62500, loss = 113.05 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:56.766586: step 62600, loss = 116.95 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:57.969840: step 62700, loss = 118.47 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:40:59.141840: step 62800, loss = 106.80 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:41:00.376347: step 62900, loss = 117.16 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:41:01.595227: step 63000, loss = 127.63 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:41:02.784246: step 63100, loss = 121.51 (10765.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:41:03.956890: step 63200, loss = 111.91 (10915.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:41:05.175769: step 63300, loss = 100.46 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:41:06.363398: step 63400, loss = 130.91 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:41:07.558548: step 63500, loss = 114.88 (10709.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:41:08.777428: step 63600, loss = 103.16 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:41:09.996308: step 63700, loss = 112.38 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:41:11.762122: step 63800, loss = 126.91 (7248.8 examples/sec; 0.018 sec/batch)
2018-02-02 11:41:13.001728: step 63900, loss = 116.88 (10325.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:41:14.955061: step 64000, loss = 115.02 (6552.9 examples/sec; 0.020 sec/batch)
2018-02-02 11:41:17.033408: step 64100, loss = 121.82 (6158.7 examples/sec; 0.021 sec/batch)
2018-02-02 11:41:19.233236: step 64200, loss = 115.79 (5818.6 examples/sec; 0.022 sec/batch)
2018-02-02 11:41:21.436595: step 64300, loss = 110.39 (5809.3 examples/sec; 0.022 sec/batch)
2018-02-02 11:41:24.014996: step 64400, loss = 116.62 (4964.3 examples/sec; 0.026 sec/batch)


