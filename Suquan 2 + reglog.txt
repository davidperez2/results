Images -> gris
pas de distored_inputs
f=tf.Variable(initial_value=tf.range(-1,1,2/576,dtype=tf.float32),trainable=True)



EVALUATION


2018-01-30 20:24:14.492681: precision @ 1 = 0.105
2018-01-30 20:24:43.601097: precision @ 1 = 0.105
2018-01-30 20:25:09.868931: precision @ 1 = 0.198
2018-01-30 20:25:38.602349: precision @ 1 = 0.198
2018-01-30 20:26:01.016963: precision @ 1 = 0.198
2018-01-30 20:26:29.123715: precision @ 1 = 0.196
2018-01-30 20:26:55.299331: precision @ 1 = 0.196
2018-01-30 20:27:23.464415: precision @ 1 = 0.195
2018-01-30 20:27:52.638004: precision @ 1 = 0.195
2018-01-30 20:28:20.816750: precision @ 1 = 0.195
2018-01-30 20:28:49.237336: precision @ 1 = 0.195
2018-01-30 20:29:17.767228: precision @ 1 = 0.193
2018-01-30 20:29:46.395367: precision @ 1 = 0.193
2018-01-30 20:30:14.751357: precision @ 1 = 0.190
2018-01-30 20:30:43.415592: precision @ 1 = 0.190
2018-01-30 20:31:08.131021: precision @ 1 = 0.185
2018-01-30 20:31:35.983096: precision @ 1 = 0.185
2018-01-30 20:31:59.293091: precision @ 1 = 0.185
2018-01-30 20:32:28.194196: precision @ 1 = 0.185
2018-01-30 20:32:54.813993: precision @ 1 = 0.185
2018-01-30 20:33:23.226322: precision @ 1 = 0.181
2018-01-30 20:33:50.917971: precision @ 1 = 0.181
2018-01-30 20:34:19.518312: precision @ 1 = 0.184
2018-01-30 20:34:47.532819: precision @ 1 = 0.184
2018-01-30 20:35:16.117725: precision @ 1 = 0.184
2018-01-30 20:35:44.474141: precision @ 1 = 0.184
2018-01-30 20:36:12.781335: precision @ 1 = 0.184
2018-01-30 20:36:41.078594: precision @ 1 = 0.184
2018-01-30 20:37:02.561730: precision @ 1 = 0.184
2018-01-30 20:37:30.944215: precision @ 1 = 0.182
2018-01-30 20:37:56.759874: precision @ 1 = 0.182
2018-01-30 20:38:25.243630: precision @ 1 = 0.180
2018-01-30 20:38:53.172910: precision @ 1 = 0.180
2018-01-30 20:39:21.155329: precision @ 1 = 0.179
2018-01-30 20:39:49.728320: precision @ 1 = 0.179
2018-01-30 20:40:18.389932: precision @ 1 = 0.181
2018-01-30 20:40:46.925825: precision @ 1 = 0.181
2018-01-30 20:41:16.018747: precision @ 1 = 0.180
2018-01-30 20:41:44.175633: precision @ 1 = 0.180
2018-01-30 20:42:11.645693: precision @ 1 = 0.181
2018-01-30 20:42:40.016147: precision @ 1 = 0.181
2018-01-30 20:43:02.165053: precision @ 1 = 0.181
2018-01-30 20:43:30.547538: precision @ 1 = 0.180
2018-01-30 20:43:56.353171: precision @ 1 = 0.180
2018-01-30 20:44:25.290339: precision @ 1 = 0.179
2018-01-30 20:44:53.345955: precision @ 1 = 0.179
2018-01-30 20:45:21.382562: precision @ 1 = 0.180
2018-01-30 20:45:50.480951: precision @ 1 = 0.180
2018-01-30 20:46:18.977399: precision @ 1 = 0.179
2018-01-30 20:46:47.334817: precision @ 1 = 0.179
2018-01-30 20:47:15.044350: precision @ 1 = 0.180
2018-01-30 20:47:43.431848: precision @ 1 = 0.180
2018-01-30 20:48:07.703143: precision @ 1 = 0.181
2018-01-30 20:48:36.386429: precision @ 1 = 0.181
2018-01-30 20:48:59.754579: precision @ 1 = 0.181
2018-01-30 20:49:28.172157: precision @ 1 = 0.181
2018-01-30 20:49:55.062674: precision @ 1 = 0.181
2018-01-30 20:50:23.324868: precision @ 1 = 0.180
2018-01-30 20:50:51.815641: precision @ 1 = 0.180
2018-01-30 20:51:19.875272: precision @ 1 = 0.181
2018-01-30 20:51:48.036168: precision @ 1 = 0.181
2018-01-30 20:52:16.051941: precision @ 1 = 0.183
2018-01-30 20:52:44.629946: precision @ 1 = 0.183
2018-01-30 20:53:13.034459: precision @ 1 = 0.182
2018-01-30 20:53:41.336731: precision @ 1 = 0.182
2018-01-30 20:54:03.417457: precision @ 1 = 0.182
2018-01-30 20:54:31.936305: precision @ 1 = 0.181
2018-01-30 20:54:58.006283: precision @ 1 = 0.181
2018-01-30 20:55:26.260767: precision @ 1 = 0.181
2018-01-30 20:55:54.302346: precision @ 1 = 0.181
2018-01-30 20:56:22.738235: precision @ 1 = 0.181
2018-01-30 20:56:51.020455: precision @ 1 = 0.181
2018-01-30 20:57:20.222940: precision @ 1 = 0.181
2018-01-30 20:57:48.475079: precision @ 1 = 0.181
2018-01-30 20:58:16.829521: precision @ 1 = 0.182
2018-01-30 20:58:45.601041: precision @ 1 = 0.182
2018-01-30 20:59:14.328416: precision @ 1 = 0.182
2018-01-30 20:59:43.220256: precision @ 1 = 0.182
2018-01-30 21:00:06.290646: precision @ 1 = 0.183
2018-01-30 21:00:34.674135: precision @ 1 = 0.183
2018-01-30 21:00:58.760193: precision @ 1 = 0.183
2018-01-30 21:01:27.414718: precision @ 1 = 0.183
2018-01-30 21:01:54.692777: precision @ 1 = 0.183
2018-01-30 21:02:26.268755: precision @ 1 = 0.182
2018-01-30 21:02:54.943017: precision @ 1 = 0.182
2018-01-30 21:03:23.857355: precision @ 1 = 0.181
2018-01-30 21:03:53.148257: precision @ 1 = 0.181
2018-01-30 21:04:21.752361: precision @ 1 = 0.181
2018-01-30 21:04:50.259177: precision @ 1 = 0.181
2018-01-30 21:05:18.992046: precision @ 1 = 0.180
2018-01-30 21:05:48.073390: precision @ 1 = 0.180
2018-01-30 21:06:17.403390: precision @ 1 = 0.180
2018-01-30 21:06:46.935935: precision @ 1 = 0.180
2018-01-30 21:07:16.256898: precision @ 1 = 0.180
2018-01-30 21:07:45.567853: precision @ 1 = 0.180
2018-01-30 21:08:14.019470: precision @ 1 = 0.179
2018-01-30 21:08:42.741879: precision @ 1 = 0.179
2018-01-30 21:09:05.023138: precision @ 1 = 0.179
2018-01-30 21:09:33.834764: precision @ 1 = 0.179
2018-01-30 21:09:58.551500: precision @ 1 = 0.179
2018-01-30 21:10:27.497850: precision @ 1 = 0.179
2018-01-30 21:10:54.957882: precision @ 1 = 0.179
2018-01-30 21:11:24.031460: precision @ 1 = 0.179
2018-01-30 21:11:53.202041: precision @ 1 = 0.179
2018-01-30 21:12:22.072031: precision @ 1 = 0.179
2018-01-30 21:12:50.758325: precision @ 1 = 0.179
2018-01-30 21:13:20.690910: precision @ 1 = 0.180
2018-01-30 21:13:49.369182: precision @ 1 = 0.180
2018-01-30 21:14:18.213640: precision @ 1 = 0.179
2018-01-30 21:14:47.143582: precision @ 1 = 0.179
2018-01-30 21:15:15.935771: precision @ 1 = 0.179
2018-01-30 21:15:44.996059: precision @ 1 = 0.179
2018-01-30 21:16:13.959264: precision @ 1 = 0.180
2018-01-30 21:16:42.660597: precision @ 1 = 0.180
2018-01-30 21:17:04.346272: precision @ 1 = 0.180
2018-01-30 21:17:33.420598: precision @ 1 = 0.179
2018-01-30 21:17:58.831179: precision @ 1 = 0.179
2018-01-30 21:18:27.070259: precision @ 1 = 0.180
2018-01-30 21:18:55.016585: precision @ 1 = 0.180
2018-01-30 21:19:23.292706: precision @ 1 = 0.180
2018-01-30 21:19:52.272781: precision @ 1 = 0.180
2018-01-30 21:20:20.986052: precision @ 1 = 0.180
2018-01-30 21:20:49.626222: precision @ 1 = 0.180
2018-01-30 21:21:18.139104: precision @ 1 = 0.179
2018-01-30 21:21:47.084085: precision @ 1 = 0.179
2018-01-30 21:22:16.163291: precision @ 1 = 0.179
2018-01-30 21:22:44.825521: precision @ 1 = 0.179
2018-01-30 21:23:13.061458: precision @ 1 = 0.179
2018-01-30 21:23:42.264124: precision @ 1 = 0.179
2018-01-30 21:24:04.873255: precision @ 1 = 0.179
2018-01-30 21:24:33.835282: precision @ 1 = 0.179
2018-01-30 21:24:58.797671: precision @ 1 = 0.179
2018-01-30 21:25:27.747665: precision @ 1 = 0.179
2018-01-30 21:25:55.606759: precision @ 1 = 0.179
2018-01-30 21:26:24.277471: precision @ 1 = 0.179
2018-01-30 21:26:52.899594: precision @ 1 = 0.179
2018-01-30 21:27:22.000656: precision @ 1 = 0.179
2018-01-30 21:27:50.792230: precision @ 1 = 0.179
2018-01-30 21:28:19.593949: precision @ 1 = 0.178
2018-01-30 21:28:48.620147: precision @ 1 = 0.178
2018-01-30 21:29:17.775081: precision @ 1 = 0.178
2018-01-30 21:29:46.655892: precision @ 1 = 0.178
2018-01-30 21:30:15.840802: precision @ 1 = 0.178
2018-01-30 21:30:44.659448: precision @ 1 = 0.178
2018-01-30 21:31:12.417239: precision @ 1 = 0.178
2018-01-30 21:31:41.370240: precision @ 1 = 0.178
2018-01-30 21:32:04.004437: precision @ 1 = 0.178
2018-01-30 21:32:33.117867: precision @ 1 = 0.178
2018-01-30 21:32:58.219627: precision @ 1 = 0.178
2018-01-30 21:33:27.239259: precision @ 1 = 0.178
2018-01-30 21:33:54.838662: precision @ 1 = 0.178
2018-01-30 21:34:23.318424: precision @ 1 = 0.178
2018-01-30 21:34:51.628718: precision @ 1 = 0.178
2018-01-30 21:35:20.534199: precision @ 1 = 0.178
2018-01-30 21:35:49.609527: precision @ 1 = 0.178
2018-01-30 21:36:18.540860: precision @ 1 = 0.178
2018-01-30 21:36:47.508903: precision @ 1 = 0.178
2018-01-30 21:37:16.313252: precision @ 1 = 0.178
2018-01-30 21:37:45.594126: precision @ 1 = 0.178
2018-01-30 21:38:14.616451: precision @ 1 = 0.178
2018-01-30 21:38:43.483225: precision @ 1 = 0.178



LOSS (Train)


2018-01-30 20:23:54.327075: step 0, loss = 2.30 (3133.0 examples/sec; 0.041 sec/batch)
2018-01-30 20:23:58.309640: step 200, loss = 2.17 (6428.0 examples/sec; 0.020 sec/batch)
2018-01-30 20:24:03.880456: step 400, loss = 2.08 (4595.4 examples/sec; 0.028 sec/batch)
2018-01-30 20:24:09.304883: step 600, loss = 2.17 (4719.4 examples/sec; 0.027 sec/batch)
2018-01-30 20:24:14.840606: step 800, loss = 2.26 (4624.5 examples/sec; 0.028 sec/batch)
2018-01-30 20:24:17.845598: step 1000, loss = 2.15 (8519.2 examples/sec; 0.015 sec/batch)
2018-01-30 20:24:20.897715: step 1200, loss = 2.23 (8387.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:24:23.892680: step 1400, loss = 2.08 (8547.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:24:28.372595: step 1600, loss = 2.10 (5714.4 examples/sec; 0.022 sec/batch)
2018-01-30 20:24:33.851166: step 1800, loss = 2.06 (4672.8 examples/sec; 0.027 sec/batch)
2018-01-30 20:24:39.284616: step 2000, loss = 2.07 (4711.6 examples/sec; 0.027 sec/batch)
2018-01-30 20:24:44.369139: step 2200, loss = 2.09 (5034.9 examples/sec; 0.025 sec/batch)
2018-01-30 20:24:47.440307: step 2400, loss = 2.19 (8335.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:24:50.594696: step 2600, loss = 2.24 (8115.7 examples/sec; 0.016 sec/batch)
2018-01-30 20:24:57.664472: step 2800, loss = 2.16 (3621.0 examples/sec; 0.035 sec/batch)
2018-01-30 20:25:03.690499: step 3000, loss = 2.07 (4248.2 examples/sec; 0.030 sec/batch)
2018-01-30 20:25:09.184110: step 3200, loss = 2.25 (4660.0 examples/sec; 0.027 sec/batch)
2018-01-30 20:25:12.508952: step 3400, loss = 2.26 (7699.6 examples/sec; 0.017 sec/batch)
2018-01-30 20:25:15.559064: step 3600, loss = 2.13 (8393.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:25:18.605165: step 3800, loss = 2.15 (8404.2 examples/sec; 0.015 sec/batch)
2018-01-30 20:25:22.466435: step 4000, loss = 2.13 (6629.9 examples/sec; 0.019 sec/batch)
2018-01-30 20:25:28.196674: step 4200, loss = 2.25 (4467.5 examples/sec; 0.029 sec/batch)
2018-01-30 20:25:33.434605: step 4400, loss = 2.14 (4887.4 examples/sec; 0.026 sec/batch)
2018-01-30 20:25:38.703618: step 4600, loss = 2.21 (4858.6 examples/sec; 0.026 sec/batch)
2018-01-30 20:25:41.772781: step 4800, loss = 2.07 (8341.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:25:44.848962: step 5000, loss = 2.22 (8322.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:25:47.879021: step 5200, loss = 2.18 (8448.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:25:52.227587: step 5400, loss = 2.03 (5887.0 examples/sec; 0.022 sec/batch)
2018-01-30 20:26:03.970819: step 5600, loss = 2.16 (2180.0 examples/sec; 0.059 sec/batch)
2018-01-30 20:26:06.952750: step 5800, loss = 2.10 (8587.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:26:10.004867: step 6000, loss = 2.17 (8387.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:26:14.142872: step 6200, loss = 2.05 (6185.1 examples/sec; 0.021 sec/batch)
2018-01-30 20:26:19.857070: step 6400, loss = 2.10 (4480.1 examples/sec; 0.029 sec/batch)
2018-01-30 20:26:25.560238: step 6600, loss = 2.29 (4488.7 examples/sec; 0.029 sec/batch)
2018-01-30 20:26:30.333933: step 6800, loss = 2.22 (5362.7 examples/sec; 0.024 sec/batch)
2018-01-30 20:26:33.356973: step 7000, loss = 2.15 (8468.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:26:36.355949: step 7200, loss = 2.09 (8536.2 examples/sec; 0.015 sec/batch)
2018-01-30 20:26:39.384003: step 7400, loss = 2.10 (8454.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:26:44.547736: step 7600, loss = 2.24 (4957.7 examples/sec; 0.026 sec/batch)
2018-01-30 20:26:50.425368: step 7800, loss = 2.21 (4355.5 examples/sec; 0.029 sec/batch)
2018-01-30 20:26:58.339593: step 8000, loss = 2.08 (3234.7 examples/sec; 0.040 sec/batch)
2018-01-30 20:27:01.376670: step 8200, loss = 2.15 (8429.2 examples/sec; 0.015 sec/batch)
2018-01-30 20:27:04.410740: step 8400, loss = 1.97 (8437.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:27:08.663049: step 8600, loss = 2.09 (6020.3 examples/sec; 0.021 sec/batch)
2018-01-30 20:27:14.314078: step 8800, loss = 2.18 (4530.1 examples/sec; 0.028 sec/batch)
2018-01-30 20:27:19.993183: step 9000, loss = 2.14 (4507.8 examples/sec; 0.028 sec/batch)
2018-01-30 20:27:24.564340: step 9200, loss = 2.17 (5600.3 examples/sec; 0.023 sec/batch)
2018-01-30 20:27:27.591390: step 9400, loss = 2.16 (8457.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:27:30.700660: step 9600, loss = 2.12 (8233.4 examples/sec; 0.016 sec/batch)
2018-01-30 20:27:33.778846: step 9800, loss = 2.05 (8316.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:27:38.882420: step 10000, loss = 2.03 (5016.1 examples/sec; 0.026 sec/batch)
2018-01-30 20:27:44.277769: step 10200, loss = 2.16 (4744.8 examples/sec; 0.027 sec/batch)
2018-01-30 20:27:49.836553: step 10400, loss = 2.21 (4605.3 examples/sec; 0.028 sec/batch)
2018-01-30 20:27:55.623747: step 10600, loss = 2.10 (4423.6 examples/sec; 0.029 sec/batch)
2018-01-30 20:27:58.663832: step 10800, loss = 2.06 (8420.8 examples/sec; 0.015 sec/batch)
2018-01-30 20:28:01.732995: step 11000, loss = 2.04 (8341.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:28:06.149742: step 11200, loss = 2.16 (5796.1 examples/sec; 0.022 sec/batch)
2018-01-30 20:28:11.645358: step 11400, loss = 2.11 (4658.3 examples/sec; 0.027 sec/batch)
2018-01-30 20:28:17.004611: step 11600, loss = 2.06 (4776.8 examples/sec; 0.027 sec/batch)
2018-01-30 20:28:21.862531: step 11800, loss = 2.09 (5269.7 examples/sec; 0.024 sec/batch)
2018-01-30 20:28:24.905624: step 12000, loss = 2.10 (8412.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:28:27.970776: step 12200, loss = 2.09 (8352.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:28:31.156248: step 12400, loss = 2.12 (8036.5 examples/sec; 0.016 sec/batch)
2018-01-30 20:28:36.394179: step 12600, loss = 2.17 (4887.4 examples/sec; 0.026 sec/batch)
2018-01-30 20:28:41.941934: step 12800, loss = 2.08 (4614.5 examples/sec; 0.028 sec/batch)
2018-01-30 20:28:47.572910: step 13000, loss = 2.09 (4546.3 examples/sec; 0.028 sec/batch)
2018-01-30 20:28:51.353966: step 13200, loss = 2.08 (6770.6 examples/sec; 0.019 sec/batch)
2018-01-30 20:28:56.029415: step 13400, loss = 2.16 (5475.4 examples/sec; 0.023 sec/batch)
2018-01-30 20:28:59.079527: step 13600, loss = 2.01 (8393.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:29:04.046737: step 13800, loss = 2.08 (5153.8 examples/sec; 0.025 sec/batch)
2018-01-30 20:29:09.475175: step 14000, loss = 2.18 (4715.9 examples/sec; 0.027 sec/batch)
2018-01-30 20:29:14.667985: step 14200, loss = 2.14 (4929.9 examples/sec; 0.026 sec/batch)
2018-01-30 20:29:19.099771: step 14400, loss = 2.13 (5776.5 examples/sec; 0.022 sec/batch)
2018-01-30 20:29:22.094737: step 14600, loss = 2.03 (8547.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:29:25.129809: step 14800, loss = 2.08 (8434.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:29:28.187942: step 15000, loss = 2.18 (8371.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:29:33.292519: step 15200, loss = 2.11 (5015.1 examples/sec; 0.026 sec/batch)
2018-01-30 20:29:38.767079: step 15400, loss = 2.03 (4676.2 examples/sec; 0.027 sec/batch)
2018-01-30 20:29:44.184487: step 15600, loss = 2.19 (4725.5 examples/sec; 0.027 sec/batch)
2018-01-30 20:29:48.259323: step 15800, loss = 2.10 (6282.5 examples/sec; 0.020 sec/batch)
2018-01-30 20:29:51.264443: step 16000, loss = 2.16 (8518.8 examples/sec; 0.015 sec/batch)
2018-01-30 20:29:55.877160: step 16200, loss = 2.02 (5549.9 examples/sec; 0.023 sec/batch)
2018-01-30 20:30:00.513490: step 16400, loss = 2.11 (5521.6 examples/sec; 0.023 sec/batch)
2018-01-30 20:30:06.001085: step 16600, loss = 2.22 (4665.1 examples/sec; 0.027 sec/batch)
2018-01-30 20:30:11.384402: step 16800, loss = 2.20 (4755.4 examples/sec; 0.027 sec/batch)
2018-01-30 20:30:15.932498: step 17000, loss = 2.06 (5628.7 examples/sec; 0.023 sec/batch)
2018-01-30 20:30:18.924456: step 17200, loss = 2.11 (8556.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:30:21.957522: step 17400, loss = 2.10 (8440.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:30:24.961512: step 17600, loss = 2.12 (8522.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:30:30.282664: step 17800, loss = 2.15 (4811.0 examples/sec; 0.027 sec/batch)
2018-01-30 20:30:35.732157: step 18000, loss = 1.96 (4697.7 examples/sec; 0.027 sec/batch)
2018-01-30 20:30:41.232786: step 18200, loss = 2.07 (4654.0 examples/sec; 0.028 sec/batch)
2018-01-30 20:30:45.306621: step 18400, loss = 2.00 (6284.0 examples/sec; 0.020 sec/batch)
2018-01-30 20:30:48.337682: step 18600, loss = 2.05 (8445.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:30:51.338664: step 18800, loss = 2.03 (8530.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:31:01.103331: step 19000, loss = 2.11 (2621.7 examples/sec; 0.049 sec/batch)
2018-01-30 20:31:06.549816: step 19200, loss = 2.10 (4700.3 examples/sec; 0.027 sec/batch)
2018-01-30 20:31:10.427128: step 19400, loss = 2.06 (6602.5 examples/sec; 0.019 sec/batch)
2018-01-30 20:31:13.451170: step 19600, loss = 2.03 (8465.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:31:16.445133: step 19800, loss = 2.03 (8550.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:31:20.112888: step 20000, loss = 2.05 (6979.7 examples/sec; 0.018 sec/batch)
2018-01-30 20:31:25.498211: step 20200, loss = 2.11 (4753.7 examples/sec; 0.027 sec/batch)
2018-01-30 20:31:31.251512: step 20400, loss = 2.04 (4449.6 examples/sec; 0.029 sec/batch)
2018-01-30 20:31:36.552611: step 20600, loss = 2.15 (4829.2 examples/sec; 0.027 sec/batch)
2018-01-30 20:31:39.600718: step 20800, loss = 2.12 (8398.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:31:42.621752: step 21000, loss = 2.09 (8473.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:31:45.613709: step 21200, loss = 2.09 (8556.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:31:50.402445: step 21400, loss = 2.03 (5345.9 examples/sec; 0.024 sec/batch)
2018-01-30 20:32:01.573396: step 21600, loss = 2.18 (2291.7 examples/sec; 0.056 sec/batch)
2018-01-30 20:32:04.594431: step 21800, loss = 2.18 (8473.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:32:07.598420: step 22000, loss = 2.09 (8522.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:32:11.075668: step 22200, loss = 2.15 (7362.1 examples/sec; 0.017 sec/batch)
2018-01-30 20:32:16.591337: step 22400, loss = 2.16 (4641.3 examples/sec; 0.028 sec/batch)
2018-01-30 20:32:21.783145: step 22600, loss = 2.04 (4930.8 examples/sec; 0.026 sec/batch)
2018-01-30 20:32:27.272745: step 22800, loss = 2.09 (4663.4 examples/sec; 0.027 sec/batch)
2018-01-30 20:32:30.719913: step 23000, loss = 2.06 (7426.4 examples/sec; 0.017 sec/batch)
2018-01-30 20:32:33.738943: step 23200, loss = 2.14 (8479.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:32:36.756969: step 23400, loss = 2.07 (8482.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:32:40.629268: step 23600, loss = 2.12 (6611.1 examples/sec; 0.019 sec/batch)
2018-01-30 20:32:46.095806: step 23800, loss = 2.13 (4683.0 examples/sec; 0.027 sec/batch)
2018-01-30 20:32:51.878185: step 24000, loss = 2.00 (4427.2 examples/sec; 0.029 sec/batch)
2018-01-30 20:32:58.754238: step 24200, loss = 1.95 (3723.1 examples/sec; 0.034 sec/batch)
2018-01-30 20:33:01.781288: step 24400, loss = 2.13 (8457.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:33:04.821374: step 24600, loss = 2.00 (8420.8 examples/sec; 0.015 sec/batch)
2018-01-30 20:33:09.722408: step 24800, loss = 2.11 (5223.4 examples/sec; 0.025 sec/batch)
2018-01-30 20:33:15.132798: step 25000, loss = 2.18 (4731.6 examples/sec; 0.027 sec/batch)
2018-01-30 20:33:20.743720: step 25200, loss = 2.07 (4562.5 examples/sec; 0.028 sec/batch)
2018-01-30 20:33:24.994024: step 25400, loss = 2.11 (6023.1 examples/sec; 0.021 sec/batch)
2018-01-30 20:33:28.027090: step 25600, loss = 2.09 (8440.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:33:31.039102: step 25800, loss = 2.20 (8499.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:33:34.311806: step 26000, loss = 2.08 (7822.3 examples/sec; 0.016 sec/batch)
2018-01-30 20:33:40.287698: step 26200, loss = 2.11 (4283.9 examples/sec; 0.030 sec/batch)
2018-01-30 20:33:45.764264: step 26400, loss = 2.03 (4674.5 examples/sec; 0.027 sec/batch)
2018-01-30 20:33:51.151592: step 26600, loss = 2.03 (4751.9 examples/sec; 0.027 sec/batch)
2018-01-30 20:33:55.788200: step 26800, loss = 2.10 (5521.3 examples/sec; 0.023 sec/batch)
2018-01-30 20:33:58.796200: step 27000, loss = 2.12 (8510.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:34:01.937555: step 27200, loss = 2.08 (8149.3 examples/sec; 0.016 sec/batch)
2018-01-30 20:34:07.376018: step 27400, loss = 2.17 (4707.2 examples/sec; 0.027 sec/batch)
2018-01-30 20:34:12.606931: step 27600, loss = 2.22 (4894.0 examples/sec; 0.026 sec/batch)
2018-01-30 20:34:18.162707: step 27800, loss = 2.12 (4607.8 examples/sec; 0.028 sec/batch)
2018-01-30 20:34:21.812413: step 28000, loss = 2.05 (7014.3 examples/sec; 0.018 sec/batch)
2018-01-30 20:34:24.875560: step 28200, loss = 2.13 (8357.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:34:27.911634: step 28400, loss = 2.03 (8431.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:34:31.512210: step 28600, loss = 2.09 (7110.0 examples/sec; 0.018 sec/batch)
2018-01-30 20:34:36.848403: step 28800, loss = 2.06 (4797.4 examples/sec; 0.027 sec/batch)
2018-01-30 20:34:42.551571: step 29000, loss = 2.07 (4488.7 examples/sec; 0.029 sec/batch)
2018-01-30 20:34:47.966974: step 29200, loss = 2.04 (4727.3 examples/sec; 0.027 sec/batch)
2018-01-30 20:34:51.012072: step 29400, loss = 2.06 (8407.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:34:55.661319: step 29600, loss = 2.07 (5506.3 examples/sec; 0.023 sec/batch)
2018-01-30 20:34:59.189703: step 29800, loss = 2.16 (7255.4 examples/sec; 0.018 sec/batch)
2018-01-30 20:35:04.616135: step 30000, loss = 2.27 (4717.6 examples/sec; 0.027 sec/batch)
2018-01-30 20:35:10.038557: step 30200, loss = 2.02 (4721.1 examples/sec; 0.027 sec/batch)
2018-01-30 20:35:15.414855: step 30400, loss = 2.03 (4761.6 examples/sec; 0.027 sec/batch)
2018-01-30 20:35:18.800861: step 30600, loss = 2.05 (7560.5 examples/sec; 0.017 sec/batch)
2018-01-30 20:35:21.805853: step 30800, loss = 2.06 (8519.2 examples/sec; 0.015 sec/batch)
2018-01-30 20:35:24.812850: step 31000, loss = 2.06 (8513.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:35:28.674119: step 31200, loss = 2.17 (6629.9 examples/sec; 0.019 sec/batch)
2018-01-30 20:35:34.083506: step 31400, loss = 2.09 (4732.5 examples/sec; 0.027 sec/batch)
2018-01-30 20:35:39.580124: step 31600, loss = 2.10 (4657.4 examples/sec; 0.027 sec/batch)
2018-01-30 20:35:44.866183: step 31800, loss = 2.09 (4842.9 examples/sec; 0.026 sec/batch)
2018-01-30 20:35:47.932338: step 32000, loss = 2.02 (8349.2 examples/sec; 0.015 sec/batch)
2018-01-30 20:35:50.959389: step 32200, loss = 1.97 (8457.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:35:55.851310: step 32400, loss = 2.12 (5233.1 examples/sec; 0.024 sec/batch)
2018-01-30 20:36:01.508353: step 32600, loss = 2.10 (4525.3 examples/sec; 0.028 sec/batch)
2018-01-30 20:36:06.809453: step 32800, loss = 2.15 (4829.2 examples/sec; 0.027 sec/batch)
2018-01-30 20:36:12.462487: step 33000, loss = 2.08 (4528.5 examples/sec; 0.028 sec/batch)
2018-01-30 20:36:15.625900: step 33200, loss = 2.17 (8092.5 examples/sec; 0.016 sec/batch)
2018-01-30 20:36:18.635906: step 33400, loss = 2.04 (8505.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:36:21.706071: step 33600, loss = 2.10 (8338.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:36:25.863127: step 33800, loss = 2.10 (6158.2 examples/sec; 0.021 sec/batch)
2018-01-30 20:36:31.449986: step 34000, loss = 2.05 (4582.2 examples/sec; 0.028 sec/batch)
2018-01-30 20:36:36.978690: step 34200, loss = 2.18 (4630.4 examples/sec; 0.028 sec/batch)
2018-01-30 20:36:41.857666: step 34400, loss = 2.20 (5247.0 examples/sec; 0.024 sec/batch)
2018-01-30 20:36:44.908780: step 34600, loss = 2.11 (8390.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:36:47.931821: step 34800, loss = 1.95 (8468.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:36:51.063148: step 35000, loss = 2.12 (8175.4 examples/sec; 0.016 sec/batch)
2018-01-30 20:37:04.056706: step 35200, loss = 2.03 (1970.2 examples/sec; 0.065 sec/batch)
2018-01-30 20:37:07.049666: step 35400, loss = 2.08 (8553.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:37:10.019564: step 35600, loss = 2.08 (8619.8 examples/sec; 0.015 sec/batch)
2018-01-30 20:37:13.074690: step 35800, loss = 2.06 (8379.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:37:18.415895: step 36000, loss = 2.21 (4792.9 examples/sec; 0.027 sec/batch)
2018-01-30 20:37:23.860375: step 36200, loss = 2.08 (4702.0 examples/sec; 0.027 sec/batch)
2018-01-30 20:37:29.650775: step 36400, loss = 2.09 (4421.1 examples/sec; 0.029 sec/batch)
2018-01-30 20:37:33.217260: step 36600, loss = 2.10 (7177.9 examples/sec; 0.018 sec/batch)
2018-01-30 20:37:36.236290: step 36800, loss = 2.23 (8479.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:37:39.234263: step 37000, loss = 1.91 (8539.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:37:42.708503: step 37200, loss = 2.07 (7368.5 examples/sec; 0.017 sec/batch)
2018-01-30 20:37:47.992556: step 37400, loss = 2.16 (4844.8 examples/sec; 0.026 sec/batch)
2018-01-30 20:37:58.007192: step 37600, loss = 2.08 (2556.3 examples/sec; 0.050 sec/batch)
2018-01-30 20:38:01.052290: step 37800, loss = 2.10 (8407.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:38:04.042242: step 38000, loss = 2.14 (8562.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:38:07.035203: step 38200, loss = 2.16 (8553.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:38:12.066584: step 38400, loss = 2.01 (5088.1 examples/sec; 0.025 sec/batch)
2018-01-30 20:38:17.559192: step 38600, loss = 2.06 (4660.8 examples/sec; 0.027 sec/batch)
2018-01-30 20:38:23.177133: step 38800, loss = 2.05 (4556.8 examples/sec; 0.028 sec/batch)
2018-01-30 20:38:27.150701: step 39000, loss = 2.14 (6442.6 examples/sec; 0.020 sec/batch)
2018-01-30 20:38:30.146669: step 39200, loss = 2.09 (8544.8 examples/sec; 0.015 sec/batch)
2018-01-30 20:38:33.185752: step 39400, loss = 1.99 (8423.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:38:36.527640: step 39600, loss = 2.01 (7660.3 examples/sec; 0.017 sec/batch)
2018-01-30 20:38:42.097454: step 39800, loss = 2.09 (4596.2 examples/sec; 0.028 sec/batch)
2018-01-30 20:38:47.437656: step 40000, loss = 2.18 (4793.8 examples/sec; 0.027 sec/batch)
2018-01-30 20:38:54.920555: step 40200, loss = 2.12 (3421.1 examples/sec; 0.037 sec/batch)
2018-01-30 20:38:57.896470: step 40400, loss = 2.20 (8602.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:39:00.954603: step 40600, loss = 2.09 (8371.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:39:04.013739: step 40800, loss = 1.90 (8368.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:39:09.877334: step 41000, loss = 2.05 (4365.9 examples/sec; 0.029 sec/batch)
2018-01-30 20:39:15.629632: step 41200, loss = 2.11 (4450.4 examples/sec; 0.029 sec/batch)
2018-01-30 20:39:21.145302: step 41400, loss = 2.05 (4641.3 examples/sec; 0.028 sec/batch)
2018-01-30 20:39:24.195414: step 41600, loss = 2.00 (8393.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:39:27.220459: step 41800, loss = 2.12 (8462.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:39:30.248512: step 42000, loss = 2.10 (8454.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:39:34.544939: step 42200, loss = 2.06 (5958.4 examples/sec; 0.021 sec/batch)
2018-01-30 20:39:40.084672: step 42400, loss = 2.11 (4621.2 examples/sec; 0.028 sec/batch)
2018-01-30 20:39:45.483030: step 42600, loss = 2.00 (4742.2 examples/sec; 0.027 sec/batch)
2018-01-30 20:39:50.320897: step 42800, loss = 2.13 (5291.6 examples/sec; 0.024 sec/batch)
2018-01-30 20:39:54.944577: step 43000, loss = 2.21 (5536.7 examples/sec; 0.023 sec/batch)
2018-01-30 20:39:57.989676: step 43200, loss = 2.06 (8407.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:40:01.702551: step 43400, loss = 2.15 (6894.9 examples/sec; 0.019 sec/batch)
2018-01-30 20:40:07.025709: step 43600, loss = 2.09 (4809.2 examples/sec; 0.027 sec/batch)
2018-01-30 20:40:12.688770: step 43800, loss = 2.01 (4520.5 examples/sec; 0.028 sec/batch)
2018-01-30 20:40:17.849495: step 44000, loss = 2.01 (4960.5 examples/sec; 0.026 sec/batch)
2018-01-30 20:40:21.074071: step 44200, loss = 2.04 (7939.0 examples/sec; 0.016 sec/batch)
2018-01-30 20:40:24.087084: step 44400, loss = 2.25 (8496.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:40:27.116140: step 44600, loss = 1.98 (8451.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:40:30.994455: step 44800, loss = 2.10 (6600.8 examples/sec; 0.019 sec/batch)
2018-01-30 20:40:36.757783: step 45000, loss = 2.08 (4441.9 examples/sec; 0.029 sec/batch)
2018-01-30 20:40:42.152130: step 45200, loss = 2.10 (4745.7 examples/sec; 0.027 sec/batch)
2018-01-30 20:40:47.088257: step 45400, loss = 2.14 (5186.3 examples/sec; 0.025 sec/batch)
2018-01-30 20:40:50.084225: step 45600, loss = 2.12 (8544.8 examples/sec; 0.015 sec/batch)
2018-01-30 20:40:54.676987: step 45800, loss = 2.06 (5574.0 examples/sec; 0.023 sec/batch)
2018-01-30 20:40:57.860454: step 46000, loss = 2.05 (8041.5 examples/sec; 0.016 sec/batch)
2018-01-30 20:41:03.218705: step 46200, loss = 2.11 (4777.7 examples/sec; 0.027 sec/batch)
2018-01-30 20:41:08.393467: step 46400, loss = 2.08 (4947.1 examples/sec; 0.026 sec/batch)
2018-01-30 20:41:13.574246: step 46600, loss = 2.16 (4941.3 examples/sec; 0.026 sec/batch)
2018-01-30 20:41:17.660113: step 46800, loss = 2.01 (6265.5 examples/sec; 0.020 sec/batch)
2018-01-30 20:41:20.677137: step 47000, loss = 2.10 (8485.2 examples/sec; 0.015 sec/batch)
2018-01-30 20:41:23.716219: step 47200, loss = 1.98 (8423.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:41:26.800422: step 47400, loss = 2.05 (8300.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:41:32.137617: step 47600, loss = 2.13 (4796.5 examples/sec; 0.027 sec/batch)
2018-01-30 20:41:37.938043: step 47800, loss = 2.08 (4413.5 examples/sec; 0.029 sec/batch)
2018-01-30 20:41:43.404582: step 48000, loss = 2.14 (4683.0 examples/sec; 0.027 sec/batch)
2018-01-30 20:41:46.809638: step 48200, loss = 2.06 (7518.2 examples/sec; 0.017 sec/batch)
2018-01-30 20:41:49.819643: step 48400, loss = 2.02 (8505.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:41:54.974354: step 48600, loss = 2.05 (4966.3 examples/sec; 0.026 sec/batch)
2018-01-30 20:42:00.444904: step 48800, loss = 2.11 (4679.6 examples/sec; 0.027 sec/batch)
2018-01-30 20:42:06.135038: step 49000, loss = 1.98 (4499.0 examples/sec; 0.028 sec/batch)
2018-01-30 20:42:11.532392: step 49200, loss = 2.04 (4743.1 examples/sec; 0.027 sec/batch)
2018-01-30 20:42:14.686781: step 49400, loss = 2.02 (8115.7 examples/sec; 0.016 sec/batch)
2018-01-30 20:42:17.731880: step 49600, loss = 2.01 (8407.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:42:20.747901: step 49800, loss = 2.10 (8488.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:42:24.922002: step 50000, loss = 2.16 (6133.1 examples/sec; 0.021 sec/batch)
2018-01-30 20:42:30.271229: step 50200, loss = 2.13 (4785.7 examples/sec; 0.027 sec/batch)
2018-01-30 20:42:35.763837: step 50400, loss = 2.15 (4660.8 examples/sec; 0.027 sec/batch)
2018-01-30 20:42:40.807250: step 50600, loss = 2.03 (5075.9 examples/sec; 0.025 sec/batch)
2018-01-30 20:42:43.867389: step 50800, loss = 2.13 (8365.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:42:46.930536: step 51000, loss = 1.98 (8357.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:42:49.971624: step 51200, loss = 2.11 (8418.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:43:02.948136: step 51400, loss = 2.14 (1972.8 examples/sec; 0.065 sec/batch)
2018-01-30 20:43:05.997246: step 51600, loss = 2.21 (8395.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:43:09.025298: step 51800, loss = 2.14 (8454.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:43:12.026280: step 52000, loss = 1.96 (8530.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:43:16.543294: step 52200, loss = 2.09 (5667.5 examples/sec; 0.023 sec/batch)
2018-01-30 20:43:22.068989: step 52400, loss = 2.11 (4632.9 examples/sec; 0.028 sec/batch)
2018-01-30 20:43:27.692946: step 52600, loss = 2.08 (4552.0 examples/sec; 0.028 sec/batch)
2018-01-30 20:43:32.020456: step 52800, loss = 2.07 (5915.6 examples/sec; 0.022 sec/batch)
2018-01-30 20:43:35.057533: step 53000, loss = 2.15 (8429.2 examples/sec; 0.015 sec/batch)
2018-01-30 20:43:38.119677: step 53200, loss = 2.12 (8360.2 examples/sec; 0.015 sec/batch)
2018-01-30 20:43:41.127677: step 53400, loss = 2.10 (8510.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:43:46.445822: step 53600, loss = 1.97 (4813.7 examples/sec; 0.027 sec/batch)
2018-01-30 20:43:52.098856: step 53800, loss = 2.01 (4528.5 examples/sec; 0.028 sec/batch)
2018-01-30 20:43:59.886776: step 54000, loss = 2.08 (3287.1 examples/sec; 0.039 sec/batch)
2018-01-30 20:44:02.920845: step 54200, loss = 2.03 (8437.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:44:05.934862: step 54400, loss = 2.03 (8493.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:44:10.431822: step 54600, loss = 2.11 (5692.7 examples/sec; 0.022 sec/batch)
2018-01-30 20:44:15.667746: step 54800, loss = 2.21 (4889.3 examples/sec; 0.026 sec/batch)
2018-01-30 20:44:20.904675: step 55000, loss = 2.12 (4888.4 examples/sec; 0.026 sec/batch)
2018-01-30 20:44:25.978168: step 55200, loss = 2.05 (5045.8 examples/sec; 0.025 sec/batch)
2018-01-30 20:44:29.045326: step 55400, loss = 2.10 (8346.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:44:32.096440: step 55600, loss = 2.01 (8390.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:44:35.094414: step 55800, loss = 2.06 (8539.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:44:39.713698: step 56000, loss = 2.05 (5542.0 examples/sec; 0.023 sec/batch)
2018-01-30 20:44:45.592334: step 56200, loss = 1.93 (4354.8 examples/sec; 0.029 sec/batch)
2018-01-30 20:44:51.095970: step 56400, loss = 2.13 (4651.5 examples/sec; 0.028 sec/batch)
2018-01-30 20:44:56.897442: step 56600, loss = 2.05 (4412.7 examples/sec; 0.029 sec/batch)
2018-01-30 20:44:59.884386: step 56800, loss = 2.05 (8570.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:45:02.887372: step 57000, loss = 1.97 (8524.8 examples/sec; 0.015 sec/batch)
2018-01-30 20:45:07.537740: step 57200, loss = 2.17 (5504.9 examples/sec; 0.023 sec/batch)
2018-01-30 20:45:13.201804: step 57400, loss = 2.13 (4519.7 examples/sec; 0.028 sec/batch)
2018-01-30 20:45:18.889933: step 57600, loss = 2.09 (4500.6 examples/sec; 0.028 sec/batch)
2018-01-30 20:45:23.065036: step 57800, loss = 2.00 (6131.6 examples/sec; 0.021 sec/batch)
2018-01-30 20:45:26.079052: step 58000, loss = 2.13 (8493.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:45:29.131170: step 58200, loss = 2.03 (8387.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:45:32.143180: step 58400, loss = 2.14 (8499.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:45:37.269815: step 58600, loss = 2.11 (4993.5 examples/sec; 0.026 sec/batch)
2018-01-30 20:45:42.718306: step 58800, loss = 2.02 (4698.5 examples/sec; 0.027 sec/batch)
2018-01-30 20:45:48.086583: step 59000, loss = 2.19 (4768.8 examples/sec; 0.027 sec/batch)
2018-01-30 20:45:52.135351: step 59200, loss = 2.15 (6322.9 examples/sec; 0.020 sec/batch)
2018-01-30 20:45:56.799415: step 59400, loss = 2.03 (5488.8 examples/sec; 0.023 sec/batch)
2018-01-30 20:45:59.803404: step 59600, loss = 2.07 (8522.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:46:04.337463: step 59800, loss = 2.03 (5646.2 examples/sec; 0.023 sec/batch)
2018-01-30 20:46:09.819041: step 60000, loss = 2.03 (4670.2 examples/sec; 0.027 sec/batch)
2018-01-30 20:46:15.087052: step 60200, loss = 2.08 (4859.5 examples/sec; 0.026 sec/batch)
2018-01-30 20:46:19.803596: step 60400, loss = 2.04 (5427.7 examples/sec; 0.024 sec/batch)
2018-01-30 20:46:22.841676: step 60600, loss = 2.00 (8426.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:46:25.806561: step 60800, loss = 2.03 (8634.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:46:28.809547: step 61000, loss = 2.09 (8524.8 examples/sec; 0.015 sec/batch)
2018-01-30 20:46:33.626359: step 61200, loss = 2.00 (5314.7 examples/sec; 0.024 sec/batch)
2018-01-30 20:46:39.147041: step 61400, loss = 2.07 (4637.1 examples/sec; 0.028 sec/batch)
2018-01-30 20:46:44.732897: step 61600, loss = 2.07 (4583.0 examples/sec; 0.028 sec/batch)
2018-01-30 20:46:48.944098: step 61800, loss = 2.06 (6079.0 examples/sec; 0.021 sec/batch)
2018-01-30 20:46:51.970146: step 62000, loss = 2.13 (8459.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:46:56.579239: step 62200, loss = 2.12 (5554.2 examples/sec; 0.023 sec/batch)
2018-01-30 20:47:01.046120: step 62400, loss = 2.01 (5731.1 examples/sec; 0.022 sec/batch)
2018-01-30 20:47:06.992936: step 62600, loss = 2.07 (4304.8 examples/sec; 0.030 sec/batch)
2018-01-30 20:47:12.936744: step 62800, loss = 2.08 (4307.0 examples/sec; 0.030 sec/batch)
2018-01-30 20:47:16.998546: step 63000, loss = 1.98 (6302.6 examples/sec; 0.020 sec/batch)
2018-01-30 20:47:20.145917: step 63200, loss = 2.19 (8133.8 examples/sec; 0.016 sec/batch)
2018-01-30 20:47:23.310333: step 63400, loss = 2.01 (8090.0 examples/sec; 0.016 sec/batch)
2018-01-30 20:47:26.913917: step 63600, loss = 2.04 (7104.0 examples/sec; 0.018 sec/batch)
2018-01-30 20:47:32.398504: step 63800, loss = 1.96 (4667.6 examples/sec; 0.027 sec/batch)
2018-01-30 20:47:38.061565: step 64000, loss = 2.05 (4520.5 examples/sec; 0.028 sec/batch)
2018-01-30 20:47:43.616338: step 64200, loss = 2.06 (4608.6 examples/sec; 0.028 sec/batch)
2018-01-30 20:47:46.603282: step 64400, loss = 2.00 (8570.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:47:49.600253: step 64600, loss = 2.07 (8542.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:47:52.626301: step 64800, loss = 2.12 (8459.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:48:03.533053: step 65000, loss = 2.14 (2347.2 examples/sec; 0.055 sec/batch)
2018-01-30 20:48:08.442109: step 65200, loss = 2.02 (5214.9 examples/sec; 0.025 sec/batch)
2018-01-30 20:48:11.470162: step 65400, loss = 2.02 (8454.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:48:14.491197: step 65600, loss = 2.07 (8473.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:48:17.502205: step 65800, loss = 2.03 (8502.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:48:22.206717: step 66000, loss = 1.94 (5441.6 examples/sec; 0.024 sec/batch)
2018-01-30 20:48:27.606077: step 66200, loss = 2.07 (4741.3 examples/sec; 0.027 sec/batch)
2018-01-30 20:48:33.178898: step 66400, loss = 2.16 (4593.7 examples/sec; 0.028 sec/batch)
2018-01-30 20:48:37.624722: step 66600, loss = 2.02 (5758.2 examples/sec; 0.022 sec/batch)
2018-01-30 20:48:40.649767: step 66800, loss = 1.96 (8462.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:48:43.682834: step 67000, loss = 2.10 (8440.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:48:46.694845: step 67200, loss = 2.09 (8499.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:48:51.873618: step 67400, loss = 2.08 (4943.3 examples/sec; 0.026 sec/batch)
2018-01-30 20:49:02.602152: step 67600, loss = 2.24 (2386.2 examples/sec; 0.054 sec/batch)
2018-01-30 20:49:05.625192: step 67800, loss = 2.03 (8468.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:49:08.684328: step 68000, loss = 2.09 (8368.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:49:12.890514: step 68200, loss = 2.12 (6086.3 examples/sec; 0.021 sec/batch)
2018-01-30 20:49:18.546557: step 68400, loss = 2.10 (4526.1 examples/sec; 0.028 sec/batch)
2018-01-30 20:49:23.656146: step 68600, loss = 2.05 (5010.2 examples/sec; 0.026 sec/batch)
2018-01-30 20:49:28.800829: step 68800, loss = 2.09 (4976.0 examples/sec; 0.026 sec/batch)
2018-01-30 20:49:31.845928: step 69000, loss = 2.15 (8407.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:49:35.028391: step 69200, loss = 2.05 (8044.1 examples/sec; 0.016 sec/batch)
2018-01-30 20:49:38.054440: step 69400, loss = 2.05 (8459.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:49:42.896317: step 69600, loss = 2.11 (5287.2 examples/sec; 0.024 sec/batch)
2018-01-30 20:49:48.388925: step 69800, loss = 2.09 (4660.8 examples/sec; 0.027 sec/batch)
2018-01-30 20:49:56.745177: step 70000, loss = 2.11 (3063.6 examples/sec; 0.042 sec/batch)
2018-01-30 20:49:59.861465: step 70200, loss = 2.03 (8214.9 examples/sec; 0.016 sec/batch)
2018-01-30 20:50:02.913583: step 70400, loss = 2.09 (8387.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:50:06.163225: step 70600, loss = 2.14 (7877.8 examples/sec; 0.016 sec/batch)
2018-01-30 20:50:11.807236: step 70800, loss = 2.01 (4535.8 examples/sec; 0.028 sec/batch)
2018-01-30 20:50:17.217626: step 71000, loss = 1.97 (4731.6 examples/sec; 0.027 sec/batch)
2018-01-30 20:50:22.831556: step 71200, loss = 2.08 (4560.1 examples/sec; 0.028 sec/batch)
2018-01-30 20:50:26.072175: step 71400, loss = 2.04 (7899.7 examples/sec; 0.016 sec/batch)
2018-01-30 20:50:29.100228: step 71600, loss = 2.08 (8454.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:50:32.126276: step 71800, loss = 2.09 (8459.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:50:36.026649: step 72000, loss = 2.17 (6563.5 examples/sec; 0.020 sec/batch)
2018-01-30 20:50:41.552345: step 72200, loss = 2.10 (4632.9 examples/sec; 0.028 sec/batch)
2018-01-30 20:50:47.146223: step 72400, loss = 2.05 (4576.4 examples/sec; 0.028 sec/batch)
2018-01-30 20:50:52.210692: step 72600, loss = 2.06 (5054.8 examples/sec; 0.025 sec/batch)
2018-01-30 20:50:56.937267: step 72800, loss = 1.99 (5416.2 examples/sec; 0.024 sec/batch)
2018-01-30 20:51:00.023475: step 73000, loss = 2.07 (8295.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:51:03.645107: step 73200, loss = 1.96 (7068.6 examples/sec; 0.018 sec/batch)
2018-01-30 20:51:08.945203: step 73400, loss = 2.16 (4830.1 examples/sec; 0.027 sec/batch)
2018-01-30 20:51:14.557128: step 73600, loss = 2.07 (4561.7 examples/sec; 0.028 sec/batch)
2018-01-30 20:51:20.117918: step 73800, loss = 2.05 (4603.7 examples/sec; 0.028 sec/batch)
2018-01-30 20:51:23.143966: step 74000, loss = 1.99 (8459.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:51:26.188062: step 74200, loss = 2.20 (8409.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:51:29.224136: step 74400, loss = 2.24 (8431.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:51:33.872499: step 74600, loss = 2.10 (5507.3 examples/sec; 0.023 sec/batch)
2018-01-30 20:51:39.457352: step 74800, loss = 2.11 (4583.8 examples/sec; 0.028 sec/batch)
2018-01-30 20:51:44.902836: step 75000, loss = 2.14 (4701.1 examples/sec; 0.027 sec/batch)
2018-01-30 20:51:49.398792: step 75200, loss = 2.10 (5694.0 examples/sec; 0.022 sec/batch)
2018-01-30 20:51:52.531123: step 75400, loss = 2.03 (8172.8 examples/sec; 0.016 sec/batch)
2018-01-30 20:51:57.162703: step 75600, loss = 2.03 (5527.3 examples/sec; 0.023 sec/batch)
2018-01-30 20:52:01.574437: step 75800, loss = 2.03 (5802.7 examples/sec; 0.022 sec/batch)
2018-01-30 20:52:07.136229: step 76000, loss = 2.24 (4602.8 examples/sec; 0.028 sec/batch)
2018-01-30 20:52:12.843407: step 76200, loss = 2.05 (4485.6 examples/sec; 0.029 sec/batch)
2018-01-30 20:52:17.326330: step 76400, loss = 2.11 (5710.6 examples/sec; 0.022 sec/batch)
2018-01-30 20:52:20.350373: step 76600, loss = 2.01 (8465.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:52:23.347343: step 76800, loss = 2.06 (8542.0 examples/sec; 0.015 sec/batch)
2018-01-30 20:52:26.386426: step 77000, loss = 2.05 (8423.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:52:31.405776: step 77200, loss = 2.08 (5100.3 examples/sec; 0.025 sec/batch)
2018-01-30 20:52:36.880335: step 77400, loss = 2.05 (4676.2 examples/sec; 0.027 sec/batch)
2018-01-30 20:52:42.258639: step 77600, loss = 2.10 (4759.9 examples/sec; 0.027 sec/batch)
2018-01-30 20:52:46.394640: step 77800, loss = 1.97 (6189.6 examples/sec; 0.021 sec/batch)
2018-01-30 20:52:49.493882: step 78000, loss = 2.22 (8260.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:52:52.574074: step 78200, loss = 2.09 (8311.2 examples/sec; 0.015 sec/batch)
2018-01-30 20:52:59.240774: step 78400, loss = 2.08 (3840.0 examples/sec; 0.033 sec/batch)
2018-01-30 20:53:04.729371: step 78600, loss = 2.11 (4664.2 examples/sec; 0.027 sec/batch)
2018-01-30 20:53:10.413489: step 78800, loss = 2.08 (4503.8 examples/sec; 0.028 sec/batch)
2018-01-30 20:53:14.543473: step 79000, loss = 1.98 (6198.6 examples/sec; 0.021 sec/batch)
2018-01-30 20:53:17.530417: step 79200, loss = 2.15 (8570.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:53:20.556465: step 79400, loss = 2.12 (8459.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:53:23.604571: step 79600, loss = 2.09 (8398.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:53:28.995910: step 79800, loss = 2.01 (4748.4 examples/sec; 0.027 sec/batch)
2018-01-30 20:53:34.427355: step 80000, loss = 2.16 (4713.3 examples/sec; 0.027 sec/batch)
2018-01-30 20:53:40.113478: step 80200, loss = 1.97 (4502.2 examples/sec; 0.028 sec/batch)
2018-01-30 20:53:43.728091: step 80400, loss = 2.05 (7082.4 examples/sec; 0.018 sec/batch)
2018-01-30 20:53:46.741105: step 80600, loss = 2.05 (8496.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:53:49.774171: step 80800, loss = 2.13 (8440.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:54:02.360646: step 81000, loss = 2.09 (2033.9 examples/sec; 0.063 sec/batch)
2018-01-30 20:54:06.010353: step 81200, loss = 2.02 (7014.3 examples/sec; 0.018 sec/batch)
2018-01-30 20:54:09.040411: step 81400, loss = 2.03 (8448.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:54:12.043398: step 81600, loss = 2.02 (8524.8 examples/sec; 0.015 sec/batch)
2018-01-30 20:54:15.984881: step 81800, loss = 2.04 (6495.0 examples/sec; 0.020 sec/batch)
2018-01-30 20:54:21.448411: step 82000, loss = 2.06 (4685.6 examples/sec; 0.027 sec/batch)
2018-01-30 20:54:26.682331: step 82200, loss = 2.01 (4891.2 examples/sec; 0.026 sec/batch)
2018-01-30 20:54:32.148870: step 82400, loss = 2.03 (4683.0 examples/sec; 0.027 sec/batch)
2018-01-30 20:54:35.161883: step 82600, loss = 2.05 (8496.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:54:38.200966: step 82800, loss = 2.07 (8423.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:54:41.257094: step 83000, loss = 2.05 (8376.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:54:45.577585: step 83200, loss = 2.15 (5925.3 examples/sec; 0.022 sec/batch)
2018-01-30 20:54:51.155062: step 83400, loss = 2.17 (4589.9 examples/sec; 0.028 sec/batch)
2018-01-30 20:55:00.828127: step 83600, loss = 2.11 (2646.5 examples/sec; 0.048 sec/batch)
2018-01-30 20:55:03.899295: step 83800, loss = 2.15 (8335.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:55:06.868191: step 84000, loss = 2.14 (8622.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:55:10.914954: step 84200, loss = 2.05 (6326.0 examples/sec; 0.020 sec/batch)
2018-01-30 20:55:16.390517: step 84400, loss = 2.07 (4675.3 examples/sec; 0.027 sec/batch)
2018-01-30 20:55:21.897162: step 84600, loss = 2.07 (4648.9 examples/sec; 0.028 sec/batch)
2018-01-30 20:55:26.961631: step 84800, loss = 2.06 (5054.8 examples/sec; 0.025 sec/batch)
2018-01-30 20:55:30.042826: step 85000, loss = 2.08 (8308.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:55:33.073887: step 85200, loss = 2.07 (8445.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:55:36.056820: step 85400, loss = 2.08 (8582.2 examples/sec; 0.015 sec/batch)
2018-01-30 20:55:40.513674: step 85600, loss = 2.13 (5744.0 examples/sec; 0.022 sec/batch)
2018-01-30 20:55:46.062431: step 85800, loss = 2.08 (4613.6 examples/sec; 0.028 sec/batch)
2018-01-30 20:55:51.577097: step 86000, loss = 2.03 (4642.2 examples/sec; 0.028 sec/batch)
2018-01-30 20:55:58.105723: step 86200, loss = 1.99 (3921.2 examples/sec; 0.033 sec/batch)
2018-01-30 20:56:01.124753: step 86400, loss = 2.08 (8479.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:56:04.133756: step 86600, loss = 2.01 (8507.8 examples/sec; 0.015 sec/batch)
2018-01-30 20:56:08.599633: step 86800, loss = 2.15 (5732.4 examples/sec; 0.022 sec/batch)
2018-01-30 20:56:14.540433: step 87000, loss = 2.11 (4309.2 examples/sec; 0.030 sec/batch)
2018-01-30 20:56:20.056102: step 87200, loss = 1.98 (4641.3 examples/sec; 0.028 sec/batch)
2018-01-30 20:56:24.237223: step 87400, loss = 2.14 (6122.8 examples/sec; 0.021 sec/batch)
2018-01-30 20:56:27.249233: step 87600, loss = 2.08 (8499.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:56:30.288315: step 87800, loss = 2.10 (8423.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:56:33.356476: step 88000, loss = 2.07 (8343.8 examples/sec; 0.015 sec/batch)
2018-01-30 20:56:38.998481: step 88200, loss = 2.07 (4537.4 examples/sec; 0.028 sec/batch)
2018-01-30 20:56:44.584337: step 88400, loss = 2.07 (4583.0 examples/sec; 0.028 sec/batch)
2018-01-30 20:56:50.171196: step 88600, loss = 2.10 (4582.2 examples/sec; 0.028 sec/batch)
2018-01-30 20:56:55.219442: step 88800, loss = 2.03 (5071.1 examples/sec; 0.025 sec/batch)
2018-01-30 20:56:58.337735: step 89000, loss = 2.04 (8209.6 examples/sec; 0.016 sec/batch)
2018-01-30 20:57:01.373809: step 89200, loss = 1.96 (8431.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:57:06.140487: step 89400, loss = 2.15 (5370.6 examples/sec; 0.024 sec/batch)
2018-01-30 20:57:11.455623: step 89600, loss = 2.15 (4816.4 examples/sec; 0.027 sec/batch)
2018-01-30 20:57:16.889073: step 89800, loss = 2.07 (4711.6 examples/sec; 0.027 sec/batch)
2018-01-30 20:57:21.403079: step 90000, loss = 2.16 (5671.2 examples/sec; 0.023 sec/batch)
2018-01-30 20:57:24.456199: step 90200, loss = 2.10 (8384.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:57:27.463195: step 90400, loss = 2.03 (8513.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:57:30.496263: step 90600, loss = 2.00 (8440.3 examples/sec; 0.015 sec/batch)
2018-01-30 20:57:35.542684: step 90800, loss = 2.04 (5072.9 examples/sec; 0.025 sec/batch)
2018-01-30 20:57:40.997191: step 91000, loss = 2.18 (4693.4 examples/sec; 0.027 sec/batch)
2018-01-30 20:57:46.521883: step 91200, loss = 1.98 (4633.7 examples/sec; 0.028 sec/batch)
2018-01-30 20:57:50.545585: step 91400, loss = 2.14 (6362.3 examples/sec; 0.020 sec/batch)
2018-01-30 20:57:55.265169: step 91600, loss = 2.14 (5424.2 examples/sec; 0.024 sec/batch)
2018-01-30 20:57:58.321297: step 91800, loss = 2.13 (8376.6 examples/sec; 0.015 sec/batch)
2018-01-30 20:58:03.159163: step 92000, loss = 2.14 (5291.6 examples/sec; 0.024 sec/batch)
2018-01-30 20:58:08.423163: step 92200, loss = 2.05 (4863.2 examples/sec; 0.026 sec/batch)
2018-01-30 20:58:14.111291: step 92400, loss = 2.11 (4500.6 examples/sec; 0.028 sec/batch)
2018-01-30 20:58:18.440806: step 92600, loss = 2.05 (5912.9 examples/sec; 0.022 sec/batch)
2018-01-30 20:58:21.460838: step 92800, loss = 2.06 (8476.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:58:24.489894: step 93000, loss = 2.03 (8451.5 examples/sec; 0.015 sec/batch)
2018-01-30 20:58:27.507921: step 93200, loss = 2.07 (8482.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:58:32.775931: step 93400, loss = 2.02 (4859.5 examples/sec; 0.026 sec/batch)
2018-01-30 20:58:38.169275: step 93600, loss = 2.09 (4746.6 examples/sec; 0.027 sec/batch)
2018-01-30 20:58:43.580667: step 93800, loss = 2.11 (4730.8 examples/sec; 0.027 sec/batch)
2018-01-30 20:58:47.505105: step 94000, loss = 2.11 (6523.2 examples/sec; 0.020 sec/batch)
2018-01-30 20:58:50.530150: step 94200, loss = 2.04 (8462.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:58:55.158432: step 94400, loss = 2.05 (5531.2 examples/sec; 0.023 sec/batch)
2018-01-30 20:58:59.902048: step 94600, loss = 2.03 (5396.7 examples/sec; 0.024 sec/batch)
2018-01-30 20:59:05.584160: step 94800, loss = 2.00 (4505.4 examples/sec; 0.028 sec/batch)
2018-01-30 20:59:10.826101: step 95000, loss = 2.06 (4883.7 examples/sec; 0.026 sec/batch)
2018-01-30 20:59:15.448395: step 95200, loss = 2.09 (5538.4 examples/sec; 0.023 sec/batch)
2018-01-30 20:59:18.473440: step 95400, loss = 2.16 (8462.7 examples/sec; 0.015 sec/batch)
2018-01-30 20:59:21.494475: step 95600, loss = 2.03 (8473.9 examples/sec; 0.015 sec/batch)
2018-01-30 20:59:24.552608: step 95800, loss = 2.07 (8371.1 examples/sec; 0.015 sec/batch)
2018-01-30 20:59:29.785525: step 96000, loss = 1.97 (4892.1 examples/sec; 0.026 sec/batch)
2018-01-30 20:59:35.219979: step 96200, loss = 1.96 (4710.7 examples/sec; 0.027 sec/batch)
2018-01-30 20:59:40.703563: step 96400, loss = 2.17 (4668.5 examples/sec; 0.027 sec/batch)
2018-01-30 20:59:44.912757: step 96600, loss = 2.11 (6081.9 examples/sec; 0.021 sec/batch)
2018-01-30 20:59:47.967883: step 96800, loss = 2.06 (8379.4 examples/sec; 0.015 sec/batch)
2018-01-30 20:59:51.017995: step 97000, loss = 2.03 (8393.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:00:02.110529: step 97200, loss = 2.06 (2307.9 examples/sec; 0.055 sec/batch)
2018-01-30 21:00:06.930347: step 97400, loss = 2.21 (5311.4 examples/sec; 0.024 sec/batch)
2018-01-30 21:00:09.925313: step 97600, loss = 2.03 (8547.7 examples/sec; 0.015 sec/batch)
2018-01-30 21:00:12.999489: step 97800, loss = 2.08 (8327.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:00:15.991446: step 98000, loss = 2.03 (8556.3 examples/sec; 0.015 sec/batch)
2018-01-30 21:00:20.610731: step 98200, loss = 2.04 (5542.0 examples/sec; 0.023 sec/batch)
2018-01-30 21:00:25.985025: step 98400, loss = 1.99 (4763.4 examples/sec; 0.027 sec/batch)
2018-01-30 21:00:31.954902: step 98600, loss = 2.12 (4288.2 examples/sec; 0.030 sec/batch)
2018-01-30 21:00:36.134017: step 98800, loss = 2.03 (6125.7 examples/sec; 0.021 sec/batch)
2018-01-30 21:00:39.168086: step 99000, loss = 2.13 (8437.5 examples/sec; 0.015 sec/batch)
2018-01-30 21:00:42.324481: step 99200, loss = 2.08 (8110.5 examples/sec; 0.016 sec/batch)
2018-01-30 21:00:45.349527: step 99400, loss = 2.15 (8462.7 examples/sec; 0.015 sec/batch)
2018-01-30 21:00:50.995543: step 99600, loss = 2.06 (4534.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:01:01.336361: step 99800, loss = 2.15 (2475.6 examples/sec; 0.052 sec/batch)
2018-01-30 21:01:04.365417: step 100000, loss = 2.10 (8451.5 examples/sec; 0.015 sec/batch)
2018-01-30 21:01:07.382441: step 100200, loss = 2.05 (8485.2 examples/sec; 0.015 sec/batch)
2018-01-30 21:01:11.225662: step 100400, loss = 2.07 (6661.1 examples/sec; 0.019 sec/batch)
2018-01-30 21:01:16.710250: step 100600, loss = 2.07 (4667.6 examples/sec; 0.027 sec/batch)
2018-01-30 21:01:22.164755: step 100800, loss = 2.20 (4693.4 examples/sec; 0.027 sec/batch)
2018-01-30 21:01:27.406697: step 101000, loss = 2.03 (4883.7 examples/sec; 0.026 sec/batch)
2018-01-30 21:01:30.446782: step 101200, loss = 2.02 (8420.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:01:33.448766: step 101400, loss = 2.13 (8527.7 examples/sec; 0.015 sec/batch)
2018-01-30 21:01:36.474814: step 101600, loss = 2.08 (8459.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:01:40.701054: step 101800, loss = 2.08 (6057.4 examples/sec; 0.021 sec/batch)
2018-01-30 21:01:46.374142: step 102000, loss = 2.11 (4512.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:01:52.039720: step 102200, loss = 2.09 (4518.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:01:58.493886: step 102400, loss = 1.98 (3966.4 examples/sec; 0.032 sec/batch)
2018-01-30 21:02:01.614184: step 102600, loss = 2.06 (8204.3 examples/sec; 0.016 sec/batch)
2018-01-30 21:02:04.816702: step 102800, loss = 2.06 (7993.7 examples/sec; 0.016 sec/batch)
2018-01-30 21:02:10.638184: step 103000, loss = 2.11 (4397.5 examples/sec; 0.029 sec/batch)
2018-01-30 21:02:16.374440: step 103200, loss = 2.04 (4462.8 examples/sec; 0.029 sec/batch)
2018-01-30 21:02:21.847998: step 103400, loss = 2.10 (4677.0 examples/sec; 0.027 sec/batch)
2018-01-30 21:02:26.813203: step 103600, loss = 2.08 (5155.9 examples/sec; 0.025 sec/batch)
2018-01-30 21:02:29.915454: step 103800, loss = 2.02 (8252.1 examples/sec; 0.016 sec/batch)
2018-01-30 21:02:33.044777: step 104000, loss = 2.05 (8180.7 examples/sec; 0.016 sec/batch)
2018-01-30 21:02:36.143017: step 104200, loss = 2.01 (8262.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:02:41.437098: step 104400, loss = 2.02 (4835.6 examples/sec; 0.026 sec/batch)
2018-01-30 21:02:47.090131: step 104600, loss = 2.05 (4528.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:02:52.518568: step 104800, loss = 2.04 (4716.8 examples/sec; 0.027 sec/batch)
2018-01-30 21:02:59.029323: step 105000, loss = 2.12 (3931.4 examples/sec; 0.033 sec/batch)
2018-01-30 21:03:02.093472: step 105200, loss = 2.15 (8354.7 examples/sec; 0.015 sec/batch)
2018-01-30 21:03:05.169655: step 105400, loss = 2.05 (8322.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:03:10.340406: step 105600, loss = 2.03 (4950.9 examples/sec; 0.026 sec/batch)
2018-01-30 21:03:16.266166: step 105800, loss = 2.07 (4320.1 examples/sec; 0.030 sec/batch)
2018-01-30 21:03:21.740726: step 106000, loss = 2.14 (4676.2 examples/sec; 0.027 sec/batch)
2018-01-30 21:03:26.050188: step 106200, loss = 2.04 (5940.4 examples/sec; 0.022 sec/batch)
2018-01-30 21:03:29.336929: step 106400, loss = 2.15 (7788.9 examples/sec; 0.016 sec/batch)
2018-01-30 21:03:32.388043: step 106600, loss = 2.05 (8390.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:03:36.228256: step 106800, loss = 2.12 (6666.3 examples/sec; 0.019 sec/batch)
2018-01-30 21:03:41.914379: step 107000, loss = 2.09 (4502.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:03:47.352843: step 107200, loss = 2.08 (4707.2 examples/sec; 0.027 sec/batch)
2018-01-30 21:03:52.831414: step 107400, loss = 2.07 (4672.8 examples/sec; 0.027 sec/batch)
2018-01-30 21:03:57.666302: step 107600, loss = 2.05 (5294.8 examples/sec; 0.024 sec/batch)
2018-01-30 21:04:00.749502: step 107800, loss = 2.16 (8303.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:04:03.858771: step 108000, loss = 2.10 (8233.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:04:09.782526: step 108200, loss = 2.07 (4321.6 examples/sec; 0.030 sec/batch)
2018-01-30 21:04:15.538836: step 108400, loss = 2.03 (4447.3 examples/sec; 0.029 sec/batch)
2018-01-30 21:04:21.020414: step 108600, loss = 2.11 (4670.2 examples/sec; 0.027 sec/batch)
2018-01-30 21:04:24.457556: step 108800, loss = 2.24 (7448.0 examples/sec; 0.017 sec/batch)
2018-01-30 21:04:27.507668: step 109000, loss = 2.14 (8393.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:04:30.585854: step 109200, loss = 2.10 (8316.6 examples/sec; 0.015 sec/batch)
2018-01-30 21:04:34.884286: step 109400, loss = 2.01 (5955.7 examples/sec; 0.021 sec/batch)
2018-01-30 21:04:40.552361: step 109600, loss = 2.14 (4516.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:04:46.255529: step 109800, loss = 2.06 (4488.7 examples/sec; 0.029 sec/batch)
2018-01-30 21:04:51.192660: step 110000, loss = 2.08 (5185.2 examples/sec; 0.025 sec/batch)
2018-01-30 21:04:56.048024: step 110200, loss = 2.16 (5272.5 examples/sec; 0.024 sec/batch)
2018-01-30 21:04:59.148269: step 110400, loss = 2.02 (8257.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:05:03.215085: step 110600, loss = 2.15 (6294.9 examples/sec; 0.020 sec/batch)
2018-01-30 21:05:08.868120: step 110800, loss = 2.06 (4528.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:05:14.416877: step 111000, loss = 2.10 (4613.6 examples/sec; 0.028 sec/batch)
2018-01-30 21:05:19.693912: step 111200, loss = 2.10 (4851.2 examples/sec; 0.026 sec/batch)
2018-01-30 21:05:22.782125: step 111400, loss = 2.11 (8289.6 examples/sec; 0.015 sec/batch)
2018-01-30 21:05:25.878359: step 111600, loss = 2.12 (8268.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:05:28.928472: step 111800, loss = 2.00 (8393.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:05:33.746285: step 112000, loss = 2.14 (5313.6 examples/sec; 0.024 sec/batch)
2018-01-30 21:05:39.107544: step 112200, loss = 2.08 (4775.0 examples/sec; 0.027 sec/batch)
2018-01-30 21:05:44.649282: step 112400, loss = 2.10 (4619.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:05:49.384877: step 112600, loss = 1.94 (5405.9 examples/sec; 0.024 sec/batch)
2018-01-30 21:05:52.422957: step 112800, loss = 2.17 (8426.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:05:57.136489: step 113000, loss = 2.14 (5431.2 examples/sec; 0.024 sec/batch)
2018-01-30 21:06:01.357716: step 113200, loss = 2.11 (6064.6 examples/sec; 0.021 sec/batch)
2018-01-30 21:06:06.666836: step 113400, loss = 2.07 (4821.9 examples/sec; 0.027 sec/batch)
2018-01-30 21:06:12.198548: step 113600, loss = 2.24 (4627.9 examples/sec; 0.028 sec/batch)
2018-01-30 21:06:17.585875: step 113800, loss = 2.13 (4751.9 examples/sec; 0.027 sec/batch)
2018-01-30 21:06:20.643006: step 114000, loss = 2.10 (8373.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:06:23.755284: step 114200, loss = 2.13 (8225.5 examples/sec; 0.016 sec/batch)
2018-01-30 21:06:26.820435: step 114400, loss = 2.08 (8352.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:06:31.347476: step 114600, loss = 2.01 (5654.9 examples/sec; 0.023 sec/batch)
2018-01-30 21:06:36.851113: step 114800, loss = 2.07 (4651.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:06:42.140180: step 115000, loss = 2.14 (4840.2 examples/sec; 0.026 sec/batch)
2018-01-30 21:06:47.246761: step 115200, loss = 2.04 (5013.1 examples/sec; 0.026 sec/batch)
2018-01-30 21:06:50.314921: step 115400, loss = 2.14 (8343.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:06:55.271085: step 115600, loss = 2.06 (5165.3 examples/sec; 0.025 sec/batch)
2018-01-30 21:06:59.052141: step 115800, loss = 2.07 (6770.6 examples/sec; 0.019 sec/batch)
2018-01-30 21:07:04.399362: step 116000, loss = 2.07 (4787.5 examples/sec; 0.027 sec/batch)
2018-01-30 21:07:09.728536: step 116200, loss = 2.08 (4803.7 examples/sec; 0.027 sec/batch)
2018-01-30 21:07:15.270274: step 116400, loss = 2.11 (4619.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:07:18.814701: step 116600, loss = 2.23 (7222.6 examples/sec; 0.018 sec/batch)
2018-01-30 21:07:21.892888: step 116800, loss = 2.19 (8316.6 examples/sec; 0.015 sec/batch)
2018-01-30 21:07:24.985111: step 117000, loss = 2.11 (8278.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:07:28.800258: step 117200, loss = 2.15 (6710.1 examples/sec; 0.019 sec/batch)
2018-01-30 21:07:34.562583: step 117400, loss = 2.04 (4442.7 examples/sec; 0.029 sec/batch)
2018-01-30 21:07:39.917826: step 117600, loss = 2.05 (4780.4 examples/sec; 0.027 sec/batch)
2018-01-30 21:07:45.558830: step 117800, loss = 2.03 (4538.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:07:48.684141: step 118000, loss = 2.10 (8191.2 examples/sec; 0.016 sec/batch)
2018-01-30 21:07:51.753304: step 118200, loss = 2.13 (8341.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:07:56.774607: step 118400, loss = 2.00 (5098.3 examples/sec; 0.025 sec/batch)
2018-01-30 21:08:02.639205: step 118600, loss = 2.07 (4365.2 examples/sec; 0.029 sec/batch)
2018-01-30 21:08:08.190969: step 118800, loss = 2.03 (4611.1 examples/sec; 0.028 sec/batch)
2018-01-30 21:08:14.059577: step 119000, loss = 2.03 (4362.2 examples/sec; 0.029 sec/batch)
2018-01-30 21:08:17.133753: step 119200, loss = 2.05 (8327.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:08:20.253068: step 119400, loss = 2.09 (8206.9 examples/sec; 0.016 sec/batch)
2018-01-30 21:08:23.342284: step 119600, loss = 2.00 (8286.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:08:27.981623: step 119800, loss = 2.09 (5518.0 examples/sec; 0.023 sec/batch)
2018-01-30 21:08:33.831180: step 120000, loss = 2.04 (4376.4 examples/sec; 0.029 sec/batch)
2018-01-30 21:08:39.329805: step 120200, loss = 2.08 (4655.7 examples/sec; 0.027 sec/batch)
2018-01-30 21:08:43.944076: step 120400, loss = 2.13 (5548.0 examples/sec; 0.023 sec/batch)
2018-01-30 21:08:47.053345: step 120600, loss = 2.08 (8233.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:08:50.142561: step 120800, loss = 2.06 (8286.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:09:02.385122: step 121000, loss = 1.99 (2091.1 examples/sec; 0.061 sec/batch)
2018-01-30 21:09:06.627404: step 121200, loss = 2.15 (6034.5 examples/sec; 0.021 sec/batch)
2018-01-30 21:09:09.730658: step 121400, loss = 2.04 (8249.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:09:12.829900: step 121600, loss = 2.20 (8260.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:09:16.042444: step 121800, loss = 2.08 (7968.8 examples/sec; 0.016 sec/batch)
2018-01-30 21:09:21.579169: step 122000, loss = 2.18 (4623.7 examples/sec; 0.028 sec/batch)
2018-01-30 21:09:26.921378: step 122200, loss = 2.08 (4792.0 examples/sec; 0.027 sec/batch)
2018-01-30 21:09:32.747874: step 122400, loss = 2.03 (4393.7 examples/sec; 0.029 sec/batch)
2018-01-30 21:09:36.375521: step 122600, loss = 2.14 (7056.9 examples/sec; 0.018 sec/batch)
2018-01-30 21:09:39.478775: step 122800, loss = 2.07 (8249.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:09:42.578018: step 123000, loss = 2.09 (8260.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:09:46.685943: step 123200, loss = 1.95 (6231.9 examples/sec; 0.021 sec/batch)
2018-01-30 21:09:52.365047: step 123400, loss = 2.12 (4507.8 examples/sec; 0.028 sec/batch)
2018-01-30 21:10:02.016079: step 123600, loss = 2.07 (2652.6 examples/sec; 0.048 sec/batch)
2018-01-30 21:10:05.142394: step 123800, loss = 2.14 (8188.6 examples/sec; 0.016 sec/batch)
2018-01-30 21:10:08.224591: step 124000, loss = 2.20 (8305.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:10:13.036389: step 124200, loss = 2.02 (5320.3 examples/sec; 0.024 sec/batch)
2018-01-30 21:10:18.371578: step 124400, loss = 2.06 (4798.3 examples/sec; 0.027 sec/batch)
2018-01-30 21:10:24.109840: step 124600, loss = 2.15 (4461.3 examples/sec; 0.029 sec/batch)
2018-01-30 21:10:28.787280: step 124800, loss = 2.09 (5473.1 examples/sec; 0.023 sec/batch)
2018-01-30 21:10:31.887525: step 125000, loss = 2.07 (8257.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:10:34.997797: step 125200, loss = 2.07 (8230.8 examples/sec; 0.016 sec/batch)
2018-01-30 21:10:38.060944: step 125400, loss = 2.05 (8357.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:10:43.494394: step 125600, loss = 2.00 (4711.6 examples/sec; 0.027 sec/batch)
2018-01-30 21:10:49.280783: step 125800, loss = 1.99 (4424.2 examples/sec; 0.029 sec/batch)
2018-01-30 21:10:57.342478: step 126000, loss = 2.07 (3175.5 examples/sec; 0.040 sec/batch)
2018-01-30 21:11:00.465785: step 126200, loss = 1.99 (8196.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:11:03.518905: step 126400, loss = 2.07 (8384.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:11:07.361124: step 126600, loss = 2.19 (6662.8 examples/sec; 0.019 sec/batch)
2018-01-30 21:11:12.869775: step 126800, loss = 1.96 (4647.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:11:18.298212: step 127000, loss = 2.08 (4715.9 examples/sec; 0.027 sec/batch)
2018-01-30 21:11:23.802852: step 127200, loss = 2.14 (4650.6 examples/sec; 0.028 sec/batch)
2018-01-30 21:11:27.039460: step 127400, loss = 2.11 (7909.5 examples/sec; 0.016 sec/batch)
2018-01-30 21:11:30.141711: step 127600, loss = 1.91 (8252.1 examples/sec; 0.016 sec/batch)
2018-01-30 21:11:33.198841: step 127800, loss = 2.02 (8373.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:11:37.431097: step 128000, loss = 2.07 (6048.8 examples/sec; 0.021 sec/batch)
2018-01-30 21:11:42.862543: step 128200, loss = 2.08 (4713.3 examples/sec; 0.027 sec/batch)
2018-01-30 21:11:48.444389: step 128400, loss = 2.12 (4586.3 examples/sec; 0.028 sec/batch)
2018-01-30 21:11:55.340938: step 128600, loss = 2.09 (3712.0 examples/sec; 0.034 sec/batch)
2018-01-30 21:11:58.420127: step 128800, loss = 2.09 (8313.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:12:01.501322: step 129000, loss = 1.96 (8308.5 examples/sec; 0.015 sec/batch)
2018-01-30 21:12:04.951498: step 129200, loss = 2.11 (7419.9 examples/sec; 0.017 sec/batch)
2018-01-30 21:12:10.761951: step 129400, loss = 2.11 (4405.9 examples/sec; 0.029 sec/batch)
2018-01-30 21:12:16.340791: step 129600, loss = 2.17 (4588.8 examples/sec; 0.028 sec/batch)
2018-01-30 21:12:22.042954: step 129800, loss = 2.10 (4489.5 examples/sec; 0.029 sec/batch)
2018-01-30 21:12:25.144202: step 130000, loss = 2.11 (8254.7 examples/sec; 0.016 sec/batch)
2018-01-30 21:12:28.196319: step 130200, loss = 2.11 (8387.6 examples/sec; 0.015 sec/batch)
2018-01-30 21:12:31.280522: step 130400, loss = 2.13 (8300.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:12:35.764448: step 130600, loss = 2.14 (5709.3 examples/sec; 0.022 sec/batch)
2018-01-30 21:12:41.385397: step 130800, loss = 2.06 (4554.4 examples/sec; 0.028 sec/batch)
2018-01-30 21:12:47.059487: step 131000, loss = 2.04 (4511.7 examples/sec; 0.028 sec/batch)
2018-01-30 21:12:51.862261: step 131200, loss = 2.11 (5330.3 examples/sec; 0.024 sec/batch)
2018-01-30 21:12:56.587806: step 131400, loss = 2.03 (5417.4 examples/sec; 0.024 sec/batch)
2018-01-30 21:12:59.659977: step 131600, loss = 2.11 (8332.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:13:03.736819: step 131800, loss = 2.09 (6279.4 examples/sec; 0.020 sec/batch)
2018-01-30 21:13:09.316659: step 132000, loss = 2.05 (4587.9 examples/sec; 0.028 sec/batch)
2018-01-30 21:13:14.498441: step 132200, loss = 2.08 (4940.4 examples/sec; 0.026 sec/batch)
2018-01-30 21:13:20.096328: step 132400, loss = 2.07 (4573.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:13:23.469299: step 132600, loss = 2.16 (7589.7 examples/sec; 0.017 sec/batch)
2018-01-30 21:13:26.577566: step 132800, loss = 2.07 (8236.1 examples/sec; 0.016 sec/batch)
2018-01-30 21:13:29.623667: step 133000, loss = 2.00 (8404.2 examples/sec; 0.015 sec/batch)
2018-01-30 21:13:33.820830: step 133200, loss = 2.08 (6099.4 examples/sec; 0.021 sec/batch)
2018-01-30 21:13:39.354547: step 133400, loss = 2.08 (4626.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:13:45.272286: step 133600, loss = 2.10 (4326.0 examples/sec; 0.030 sec/batch)
2018-01-30 21:13:50.195379: step 133800, loss = 2.10 (5200.0 examples/sec; 0.025 sec/batch)
2018-01-30 21:13:54.949768: step 134000, loss = 2.03 (5384.5 examples/sec; 0.024 sec/batch)
2018-01-30 21:13:58.084104: step 134200, loss = 1.98 (8167.6 examples/sec; 0.016 sec/batch)
2018-01-30 21:14:02.187016: step 134400, loss = 2.09 (6239.5 examples/sec; 0.021 sec/batch)
2018-01-30 21:14:07.674611: step 134600, loss = 2.05 (4665.1 examples/sec; 0.027 sec/batch)
2018-01-30 21:14:13.341682: step 134800, loss = 2.07 (4517.3 examples/sec; 0.028 sec/batch)
2018-01-30 21:14:18.692914: step 135000, loss = 2.07 (4783.9 examples/sec; 0.027 sec/batch)
2018-01-30 21:14:21.740018: step 135200, loss = 2.06 (8401.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:14:24.853298: step 135400, loss = 2.13 (8222.8 examples/sec; 0.016 sec/batch)
2018-01-30 21:14:27.955549: step 135600, loss = 1.95 (8252.1 examples/sec; 0.016 sec/batch)
2018-01-30 21:14:32.894685: step 135800, loss = 2.13 (5183.1 examples/sec; 0.025 sec/batch)
2018-01-30 21:14:38.428402: step 136000, loss = 2.00 (4626.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:14:43.855838: step 136200, loss = 2.11 (4716.8 examples/sec; 0.027 sec/batch)
2018-01-30 21:14:48.457074: step 136400, loss = 2.12 (5563.7 examples/sec; 0.023 sec/batch)
2018-01-30 21:14:51.537266: step 136600, loss = 2.06 (8311.2 examples/sec; 0.015 sec/batch)
2018-01-30 21:14:56.284507: step 136800, loss = 2.01 (5392.6 examples/sec; 0.024 sec/batch)
2018-01-30 21:15:00.821574: step 137000, loss = 2.11 (5642.4 examples/sec; 0.023 sec/batch)
2018-01-30 21:15:06.357296: step 137200, loss = 2.08 (4624.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:15:11.964209: step 137400, loss = 2.04 (4565.8 examples/sec; 0.028 sec/batch)
2018-01-30 21:15:16.840177: step 137600, loss = 2.11 (5250.2 examples/sec; 0.024 sec/batch)
2018-01-30 21:15:19.925382: step 137800, loss = 2.12 (8297.7 examples/sec; 0.015 sec/batch)
2018-01-30 21:15:23.004571: step 138000, loss = 2.09 (8313.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:15:26.051675: step 138200, loss = 1.99 (8401.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:15:31.247494: step 138400, loss = 2.04 (4927.0 examples/sec; 0.026 sec/batch)
2018-01-30 21:15:36.781212: step 138600, loss = 2.19 (4626.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:15:42.228699: step 138800, loss = 2.19 (4699.4 examples/sec; 0.027 sec/batch)
2018-01-30 21:15:46.523121: step 139000, loss = 2.09 (5961.2 examples/sec; 0.021 sec/batch)
2018-01-30 21:15:49.631387: step 139200, loss = 1.97 (8236.1 examples/sec; 0.016 sec/batch)
2018-01-30 21:15:52.700550: step 139400, loss = 2.07 (8341.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:15:58.762848: step 139600, loss = 2.12 (4222.8 examples/sec; 0.030 sec/batch)
2018-01-30 21:16:04.456992: step 139800, loss = 2.04 (4495.8 examples/sec; 0.028 sec/batch)
2018-01-30 21:16:10.036832: step 140000, loss = 2.09 (4587.9 examples/sec; 0.028 sec/batch)
2018-01-30 21:16:14.874699: step 140200, loss = 2.07 (5291.6 examples/sec; 0.024 sec/batch)
2018-01-30 21:16:17.980960: step 140400, loss = 2.07 (8241.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:16:21.020043: step 140600, loss = 2.06 (8423.6 examples/sec; 0.015 sec/batch)
2018-01-30 21:16:24.128309: step 140800, loss = 2.13 (8236.1 examples/sec; 0.016 sec/batch)
2018-01-30 21:16:29.287029: step 141000, loss = 1.98 (4962.5 examples/sec; 0.026 sec/batch)
2018-01-30 21:16:34.956107: step 141200, loss = 1.99 (4515.7 examples/sec; 0.028 sec/batch)
2018-01-30 21:16:40.531936: step 141400, loss = 2.05 (4591.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:16:44.598752: step 141600, loss = 2.04 (6294.9 examples/sec; 0.020 sec/batch)
2018-01-30 21:16:47.711029: step 141800, loss = 2.00 (8225.5 examples/sec; 0.016 sec/batch)
2018-01-30 21:16:50.851382: step 142000, loss = 2.06 (8152.0 examples/sec; 0.016 sec/batch)
2018-01-30 21:17:04.195872: step 142200, loss = 2.10 (1918.4 examples/sec; 0.067 sec/batch)
2018-01-30 21:17:07.358283: step 142400, loss = 1.98 (8095.1 examples/sec; 0.016 sec/batch)
2018-01-30 21:17:10.442485: step 142600, loss = 2.11 (8300.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:17:13.527691: step 142800, loss = 2.11 (8297.7 examples/sec; 0.015 sec/batch)
2018-01-30 21:17:17.954464: step 143000, loss = 2.05 (5783.0 examples/sec; 0.022 sec/batch)
2018-01-30 21:17:23.084107: step 143200, loss = 2.06 (4990.6 examples/sec; 0.026 sec/batch)
2018-01-30 21:17:28.707061: step 143400, loss = 2.00 (4552.8 examples/sec; 0.028 sec/batch)
2018-01-30 21:17:34.062304: step 143600, loss = 2.12 (4780.4 examples/sec; 0.027 sec/batch)
2018-01-30 21:17:37.104395: step 143800, loss = 2.11 (8415.3 examples/sec; 0.015 sec/batch)
2018-01-30 21:17:40.232715: step 144000, loss = 2.10 (8183.3 examples/sec; 0.016 sec/batch)
2018-01-30 21:17:43.339979: step 144200, loss = 2.14 (8238.8 examples/sec; 0.016 sec/batch)
2018-01-30 21:17:47.929184: step 144400, loss = 2.01 (5578.3 examples/sec; 0.023 sec/batch)
2018-01-30 21:17:59.509987: step 144600, loss = 2.11 (2210.6 examples/sec; 0.058 sec/batch)
2018-01-30 21:18:02.573107: step 144800, loss = 2.02 (8357.5 examples/sec; 0.015 sec/batch)
2018-01-30 21:18:05.639262: step 145000, loss = 1.95 (8349.2 examples/sec; 0.015 sec/batch)
2018-01-30 21:18:08.660296: step 145200, loss = 2.13 (8473.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:18:14.070686: step 145400, loss = 1.97 (4731.6 examples/sec; 0.027 sec/batch)
2018-01-30 21:18:19.837022: step 145600, loss = 2.11 (4439.6 examples/sec; 0.029 sec/batch)
2018-01-30 21:18:25.442932: step 145800, loss = 2.09 (4566.6 examples/sec; 0.028 sec/batch)
2018-01-30 21:18:29.347315: step 146000, loss = 2.01 (6556.7 examples/sec; 0.020 sec/batch)
2018-01-30 21:18:32.436531: step 146200, loss = 2.09 (8286.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:18:35.505694: step 146400, loss = 2.13 (8341.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:18:39.108276: step 146600, loss = 2.09 (7106.0 examples/sec; 0.018 sec/batch)
2018-01-30 21:18:44.762313: step 146800, loss = 2.08 (4527.7 examples/sec; 0.028 sec/batch)
2018-01-30 21:18:50.242889: step 147000, loss = 2.05 (4671.0 examples/sec; 0.027 sec/batch)
2018-01-30 21:18:57.689613: step 147200, loss = 2.10 (3437.8 examples/sec; 0.037 sec/batch)
2018-01-30 21:19:00.736717: step 147400, loss = 2.06 (8401.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:19:03.830946: step 147600, loss = 2.02 (8273.5 examples/sec; 0.015 sec/batch)
2018-01-30 21:19:08.187533: step 147800, loss = 2.18 (5876.2 examples/sec; 0.022 sec/batch)
2018-01-30 21:19:13.798455: step 148000, loss = 2.14 (4562.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:19:19.705166: step 148200, loss = 2.05 (4334.1 examples/sec; 0.030 sec/batch)
2018-01-30 21:19:24.517965: step 148400, loss = 1.98 (5319.1 examples/sec; 0.024 sec/batch)
2018-01-30 21:19:27.614199: step 148600, loss = 2.03 (8268.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:19:30.717453: step 148800, loss = 2.06 (8249.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:19:33.762551: step 149000, loss = 1.99 (8407.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:19:38.955362: step 149200, loss = 2.08 (4929.9 examples/sec; 0.026 sec/batch)
2018-01-30 21:19:44.552247: step 149400, loss = 2.04 (4574.0 examples/sec; 0.028 sec/batch)
2018-01-30 21:19:50.212301: step 149600, loss = 2.07 (4522.9 examples/sec; 0.028 sec/batch)
2018-01-30 21:19:55.928409: step 149800, loss = 2.04 (4478.6 examples/sec; 0.029 sec/batch)
2018-01-30 21:19:58.987545: step 150000, loss = 2.06 (8368.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:20:02.063726: step 150200, loss = 2.10 (8322.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:20:06.892568: step 150400, loss = 2.01 (5301.5 examples/sec; 0.024 sec/batch)
2018-01-30 21:20:12.384174: step 150600, loss = 2.07 (4661.7 examples/sec; 0.027 sec/batch)
2018-01-30 21:20:18.291886: step 150800, loss = 2.05 (4333.3 examples/sec; 0.030 sec/batch)
2018-01-30 21:20:22.571268: step 151000, loss = 1.93 (5982.2 examples/sec; 0.021 sec/batch)
2018-01-30 21:20:25.673518: step 151200, loss = 2.05 (8252.1 examples/sec; 0.016 sec/batch)
2018-01-30 21:20:28.705582: step 151400, loss = 2.11 (8443.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:20:31.777753: step 151600, loss = 2.11 (8332.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:20:37.411737: step 151800, loss = 1.97 (4543.9 examples/sec; 0.028 sec/batch)
2018-01-30 21:20:43.136964: step 152000, loss = 2.13 (4471.4 examples/sec; 0.029 sec/batch)
2018-01-30 21:20:48.802031: step 152200, loss = 2.27 (4518.9 examples/sec; 0.028 sec/batch)
2018-01-30 21:20:52.287299: step 152400, loss = 2.10 (7345.2 examples/sec; 0.017 sec/batch)
2018-01-30 21:20:57.091125: step 152600, loss = 2.04 (5329.1 examples/sec; 0.024 sec/batch)
2018-01-30 21:21:00.214431: step 152800, loss = 2.09 (8196.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:21:05.794272: step 153000, loss = 2.14 (4587.9 examples/sec; 0.028 sec/batch)
2018-01-30 21:21:11.673909: step 153200, loss = 2.11 (4354.0 examples/sec; 0.029 sec/batch)
2018-01-30 21:21:17.209631: step 153400, loss = 2.13 (4624.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:21:20.756063: step 153600, loss = 2.09 (7218.5 examples/sec; 0.018 sec/batch)
2018-01-30 21:21:23.845279: step 153800, loss = 2.08 (8286.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:21:26.860298: step 154000, loss = 2.03 (8490.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:21:30.943157: step 154200, loss = 2.09 (6270.1 examples/sec; 0.020 sec/batch)
2018-01-30 21:21:36.692448: step 154400, loss = 2.02 (4452.7 examples/sec; 0.029 sec/batch)
2018-01-30 21:21:42.193077: step 154600, loss = 2.02 (4654.0 examples/sec; 0.028 sec/batch)
2018-01-30 21:21:47.511221: step 154800, loss = 2.11 (4813.7 examples/sec; 0.027 sec/batch)
2018-01-30 21:21:50.588405: step 155000, loss = 1.99 (8319.3 examples/sec; 0.015 sec/batch)
2018-01-30 21:21:55.399067: step 155200, loss = 2.16 (5321.5 examples/sec; 0.024 sec/batch)
2018-01-30 21:21:58.905392: step 155400, loss = 2.01 (7301.1 examples/sec; 0.018 sec/batch)
2018-01-30 21:22:04.369927: step 155600, loss = 2.03 (4685.6 examples/sec; 0.027 sec/batch)
2018-01-30 21:22:09.955782: step 155800, loss = 2.04 (4582.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:22:15.586759: step 156000, loss = 2.03 (4546.3 examples/sec; 0.028 sec/batch)
2018-01-30 21:22:18.925638: step 156200, loss = 2.15 (7667.2 examples/sec; 0.017 sec/batch)
2018-01-30 21:22:21.965723: step 156400, loss = 2.13 (8420.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:22:25.080006: step 156600, loss = 2.00 (8220.2 examples/sec; 0.016 sec/batch)
2018-01-30 21:22:29.101702: step 156800, loss = 2.02 (6365.5 examples/sec; 0.020 sec/batch)
2018-01-30 21:22:35.007408: step 157000, loss = 2.15 (4334.8 examples/sec; 0.030 sec/batch)
2018-01-30 21:22:40.583238: step 157200, loss = 2.05 (4591.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:22:45.657734: step 157400, loss = 1.93 (5044.8 examples/sec; 0.025 sec/batch)
2018-01-30 21:22:48.771014: step 157600, loss = 1.99 (8222.8 examples/sec; 0.016 sec/batch)
2018-01-30 21:22:51.854214: step 157800, loss = 2.07 (8303.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:22:57.998396: step 158000, loss = 2.05 (4166.5 examples/sec; 0.031 sec/batch)
2018-01-30 21:23:03.685521: step 158200, loss = 2.02 (4501.4 examples/sec; 0.028 sec/batch)
2018-01-30 21:23:09.390695: step 158400, loss = 2.14 (4487.2 examples/sec; 0.029 sec/batch)
2018-01-30 21:23:14.133308: step 158600, loss = 1.99 (5397.9 examples/sec; 0.024 sec/batch)
2018-01-30 21:23:17.157351: step 158800, loss = 2.03 (8465.5 examples/sec; 0.015 sec/batch)
2018-01-30 21:23:20.263613: step 159000, loss = 1.97 (8241.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:23:23.365863: step 159200, loss = 2.04 (8252.1 examples/sec; 0.016 sec/batch)
2018-01-30 21:23:28.409276: step 159400, loss = 2.04 (5075.9 examples/sec; 0.025 sec/batch)
2018-01-30 21:23:33.796604: step 159600, loss = 2.05 (4751.9 examples/sec; 0.027 sec/batch)
2018-01-30 21:23:39.504785: step 159800, loss = 2.14 (4484.8 examples/sec; 0.029 sec/batch)
2018-01-30 21:23:43.813244: step 160000, loss = 2.10 (5941.8 examples/sec; 0.022 sec/batch)
2018-01-30 21:23:46.917500: step 160200, loss = 2.06 (8246.7 examples/sec; 0.016 sec/batch)
2018-01-30 21:23:49.996689: step 160400, loss = 2.03 (8313.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:23:53.226279: step 160600, loss = 2.11 (7926.7 examples/sec; 0.016 sec/batch)
2018-01-30 21:24:06.226855: step 160800, loss = 2.07 (1969.1 examples/sec; 0.065 sec/batch)
2018-01-30 21:24:09.310055: step 161000, loss = 2.06 (8303.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:24:12.360167: step 161200, loss = 2.07 (8393.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:24:15.424316: step 161400, loss = 2.09 (8354.7 examples/sec; 0.015 sec/batch)
2018-01-30 21:24:20.996135: step 161600, loss = 2.10 (4594.6 examples/sec; 0.028 sec/batch)
2018-01-30 21:24:26.873767: step 161800, loss = 2.13 (4355.5 examples/sec; 0.029 sec/batch)
2018-01-30 21:24:32.319249: step 162000, loss = 2.08 (4701.1 examples/sec; 0.027 sec/batch)
2018-01-30 21:24:36.033127: step 162200, loss = 2.06 (6893.1 examples/sec; 0.019 sec/batch)
2018-01-30 21:24:39.126353: step 162400, loss = 2.06 (8276.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:24:42.246652: step 162600, loss = 2.01 (8204.3 examples/sec; 0.016 sec/batch)
2018-01-30 21:24:45.971559: step 162800, loss = 2.07 (6872.7 examples/sec; 0.019 sec/batch)
2018-01-30 21:24:51.489233: step 163000, loss = 2.08 (4639.6 examples/sec; 0.028 sec/batch)
2018-01-30 21:25:01.629201: step 163200, loss = 2.05 (2524.7 examples/sec; 0.051 sec/batch)
2018-01-30 21:25:04.684327: step 163400, loss = 2.01 (8379.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:25:07.769532: step 163600, loss = 2.03 (8297.7 examples/sec; 0.015 sec/batch)
2018-01-30 21:25:11.902524: step 163800, loss = 2.09 (6194.1 examples/sec; 0.021 sec/batch)
2018-01-30 21:25:17.490385: step 164000, loss = 1.99 (4581.4 examples/sec; 0.028 sec/batch)
2018-01-30 21:25:23.174503: step 164200, loss = 2.07 (4503.8 examples/sec; 0.028 sec/batch)
2018-01-30 21:25:28.392380: step 164400, loss = 2.08 (4906.2 examples/sec; 0.026 sec/batch)
2018-01-30 21:25:31.512679: step 164600, loss = 2.09 (8204.3 examples/sec; 0.016 sec/batch)
2018-01-30 21:25:34.571815: step 164800, loss = 2.13 (8368.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:25:37.651004: step 165000, loss = 2.10 (8313.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:25:42.227175: step 165200, loss = 2.09 (5594.2 examples/sec; 0.023 sec/batch)
2018-01-30 21:25:47.811025: step 165400, loss = 2.17 (4584.6 examples/sec; 0.028 sec/batch)
2018-01-30 21:25:53.069009: step 165600, loss = 2.05 (4868.8 examples/sec; 0.026 sec/batch)
2018-01-30 21:25:59.710132: step 165800, loss = 2.01 (3854.8 examples/sec; 0.033 sec/batch)
2018-01-30 21:26:02.822409: step 166000, loss = 1.99 (8225.5 examples/sec; 0.016 sec/batch)
2018-01-30 21:26:05.917641: step 166200, loss = 2.05 (8270.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:26:11.379167: step 166400, loss = 1.99 (4687.3 examples/sec; 0.027 sec/batch)
2018-01-30 21:26:17.140490: step 166600, loss = 2.09 (4443.4 examples/sec; 0.029 sec/batch)
2018-01-30 21:26:22.605023: step 166800, loss = 2.03 (4684.8 examples/sec; 0.027 sec/batch)
2018-01-30 21:26:26.434207: step 167000, loss = 2.04 (6685.5 examples/sec; 0.019 sec/batch)
2018-01-30 21:26:29.499359: step 167200, loss = 2.08 (8352.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:26:32.599604: step 167400, loss = 2.02 (8257.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:26:36.371636: step 167600, loss = 1.91 (6786.8 examples/sec; 0.019 sec/batch)
2018-01-30 21:26:41.822133: step 167800, loss = 2.08 (4696.8 examples/sec; 0.027 sec/batch)
2018-01-30 21:26:47.667679: step 168000, loss = 2.07 (4379.4 examples/sec; 0.029 sec/batch)
2018-01-30 21:26:53.149258: step 168200, loss = 2.06 (4670.2 examples/sec; 0.027 sec/batch)
2018-01-30 21:26:57.997819: step 168400, loss = 2.13 (5279.9 examples/sec; 0.024 sec/batch)
2018-01-30 21:27:01.080016: step 168600, loss = 2.03 (8305.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:27:04.566288: step 168800, loss = 2.13 (7343.1 examples/sec; 0.017 sec/batch)
2018-01-30 21:27:10.053882: step 169000, loss = 2.02 (4665.1 examples/sec; 0.027 sec/batch)
2018-01-30 21:27:15.637733: step 169200, loss = 2.04 (4584.6 examples/sec; 0.028 sec/batch)
2018-01-30 21:27:21.300795: step 169400, loss = 2.02 (4520.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:27:24.716880: step 169600, loss = 2.11 (7494.0 examples/sec; 0.017 sec/batch)
2018-01-30 21:27:27.776016: step 169800, loss = 2.01 (8368.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:27:30.844176: step 170000, loss = 1.99 (8343.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:27:35.075429: step 170200, loss = 2.10 (6050.2 examples/sec; 0.021 sec/batch)
2018-01-30 21:27:40.605136: step 170400, loss = 2.11 (4629.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:27:46.271206: step 170600, loss = 2.14 (4518.1 examples/sec; 0.028 sec/batch)
2018-01-30 21:27:51.258469: step 170800, loss = 2.17 (5133.1 examples/sec; 0.025 sec/batch)
2018-01-30 21:27:56.016243: step 171000, loss = 2.00 (5380.7 examples/sec; 0.024 sec/batch)
2018-01-30 21:27:59.099442: step 171200, loss = 2.01 (8303.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:28:02.851422: step 171400, loss = 2.06 (6823.1 examples/sec; 0.019 sec/batch)
2018-01-30 21:28:08.427251: step 171600, loss = 2.01 (4591.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:28:14.055219: step 171800, loss = 2.08 (4548.7 examples/sec; 0.028 sec/batch)
2018-01-30 21:28:19.634058: step 172000, loss = 2.07 (4588.8 examples/sec; 0.028 sec/batch)
2018-01-30 21:28:22.733299: step 172200, loss = 2.01 (8260.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:28:25.795442: step 172400, loss = 2.07 (8360.2 examples/sec; 0.015 sec/batch)
2018-01-30 21:28:28.916744: step 172600, loss = 1.98 (8201.7 examples/sec; 0.016 sec/batch)
2018-01-30 21:28:33.428744: step 172800, loss = 1.98 (5673.8 examples/sec; 0.023 sec/batch)
2018-01-30 21:28:39.102834: step 173000, loss = 2.08 (4511.7 examples/sec; 0.028 sec/batch)
2018-01-30 21:28:44.607538: step 173200, loss = 2.07 (4650.6 examples/sec; 0.028 sec/batch)
2018-01-30 21:28:49.502494: step 173400, loss = 2.13 (5229.9 examples/sec; 0.024 sec/batch)
2018-01-30 21:28:52.567645: step 173600, loss = 2.04 (8352.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:28:57.291604: step 173800, loss = 2.14 (5419.2 examples/sec; 0.024 sec/batch)
2018-01-30 21:29:01.387497: step 174000, loss = 1.98 (6250.2 examples/sec; 0.020 sec/batch)
2018-01-30 21:29:06.881108: step 174200, loss = 2.03 (4660.0 examples/sec; 0.027 sec/batch)
2018-01-30 21:29:12.402793: step 174400, loss = 2.11 (4636.3 examples/sec; 0.028 sec/batch)
2018-01-30 21:29:17.826217: step 174600, loss = 2.04 (4720.3 examples/sec; 0.027 sec/batch)
2018-01-30 21:29:20.919444: step 174800, loss = 2.05 (8276.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:29:23.993620: step 175000, loss = 2.12 (8327.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:29:27.060778: step 175200, loss = 2.08 (8346.5 examples/sec; 0.015 sec/batch)
2018-01-30 21:29:31.704126: step 175400, loss = 2.10 (5513.3 examples/sec; 0.023 sec/batch)
2018-01-30 21:29:37.302015: step 175600, loss = 2.02 (4573.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:29:42.888873: step 175800, loss = 1.99 (4582.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:29:47.631486: step 176000, loss = 2.12 (5397.9 examples/sec; 0.024 sec/batch)
2018-01-30 21:29:50.853055: step 176200, loss = 2.20 (7946.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:29:55.946893: step 176400, loss = 2.13 (5025.7 examples/sec; 0.025 sec/batch)
2018-01-30 21:30:00.312503: step 176600, loss = 2.08 (5864.0 examples/sec; 0.022 sec/batch)
2018-01-30 21:30:05.879309: step 176800, loss = 2.18 (4598.7 examples/sec; 0.028 sec/batch)
2018-01-30 21:30:11.370914: step 177000, loss = 2.08 (4661.7 examples/sec; 0.027 sec/batch)
2018-01-30 21:30:16.461452: step 177200, loss = 2.09 (5028.9 examples/sec; 0.025 sec/batch)
2018-01-30 21:30:19.543650: step 177400, loss = 2.07 (8305.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:30:22.590754: step 177600, loss = 2.07 (8401.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:30:25.690999: step 177800, loss = 2.08 (8257.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:30:30.618103: step 178000, loss = 2.05 (5195.7 examples/sec; 0.025 sec/batch)
2018-01-30 21:30:36.527821: step 178200, loss = 2.05 (4331.8 examples/sec; 0.030 sec/batch)
2018-01-30 21:30:42.168823: step 178400, loss = 1.96 (4538.2 examples/sec; 0.028 sec/batch)
2018-01-30 21:30:46.529421: step 178600, loss = 2.07 (5870.8 examples/sec; 0.022 sec/batch)
2018-01-30 21:30:49.597581: step 178800, loss = 2.11 (8343.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:30:52.660727: step 179000, loss = 2.04 (8357.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:31:00.163648: step 179200, loss = 2.11 (3412.0 examples/sec; 0.038 sec/batch)
2018-01-30 21:31:05.816683: step 179400, loss = 2.16 (4528.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:31:11.340373: step 179600, loss = 2.01 (4634.6 examples/sec; 0.028 sec/batch)
2018-01-30 21:31:15.001110: step 179800, loss = 2.12 (6993.1 examples/sec; 0.018 sec/batch)
2018-01-30 21:31:18.104363: step 180000, loss = 2.04 (8249.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:31:21.150465: step 180200, loss = 2.02 (8404.2 examples/sec; 0.015 sec/batch)
2018-01-30 21:31:25.335595: step 180400, loss = 2.02 (6116.9 examples/sec; 0.021 sec/batch)
2018-01-30 21:31:30.821184: step 180600, loss = 2.07 (4666.8 examples/sec; 0.027 sec/batch)
2018-01-30 21:31:36.534379: step 180800, loss = 2.07 (4480.9 examples/sec; 0.029 sec/batch)
2018-01-30 21:31:41.700117: step 181000, loss = 2.07 (4955.7 examples/sec; 0.026 sec/batch)
2018-01-30 21:31:44.791339: step 181200, loss = 2.10 (8281.5 examples/sec; 0.015 sec/batch)
2018-01-30 21:31:47.856491: step 181400, loss = 2.09 (8352.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:31:50.938688: step 181600, loss = 2.13 (8305.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:32:04.121749: step 181800, loss = 2.07 (1941.9 examples/sec; 0.066 sec/batch)
2018-01-30 21:32:07.226005: step 182000, loss = 2.06 (8246.7 examples/sec; 0.016 sec/batch)
2018-01-30 21:32:10.311211: step 182200, loss = 2.07 (8297.7 examples/sec; 0.015 sec/batch)
2018-01-30 21:32:13.347285: step 182400, loss = 2.13 (8431.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:32:17.607616: step 182600, loss = 2.13 (6008.9 examples/sec; 0.021 sec/batch)
2018-01-30 21:32:23.091200: step 182800, loss = 2.16 (4668.5 examples/sec; 0.027 sec/batch)
2018-01-30 21:32:28.684075: step 183000, loss = 2.04 (4577.3 examples/sec; 0.028 sec/batch)
2018-01-30 21:32:33.721472: step 183200, loss = 2.11 (5082.0 examples/sec; 0.025 sec/batch)
2018-01-30 21:32:36.821717: step 183400, loss = 2.02 (8257.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:32:39.901909: step 183600, loss = 2.11 (8311.2 examples/sec; 0.015 sec/batch)
2018-01-30 21:32:42.988117: step 183800, loss = 2.01 (8295.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:32:48.066624: step 184000, loss = 2.05 (5040.9 examples/sec; 0.025 sec/batch)
2018-01-30 21:32:59.262854: step 184200, loss = 2.08 (2286.5 examples/sec; 0.056 sec/batch)
2018-01-30 21:33:02.296923: step 184400, loss = 2.02 (8437.5 examples/sec; 0.015 sec/batch)
2018-01-30 21:33:05.390150: step 184600, loss = 2.12 (8276.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:33:08.466331: step 184800, loss = 1.95 (8322.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:33:13.570908: step 185000, loss = 2.05 (5015.1 examples/sec; 0.026 sec/batch)
2018-01-30 21:33:19.111643: step 185200, loss = 2.11 (4620.3 examples/sec; 0.028 sec/batch)
2018-01-30 21:33:24.621297: step 185400, loss = 2.16 (4646.4 examples/sec; 0.028 sec/batch)
2018-01-30 21:33:28.966854: step 185600, loss = 1.95 (5891.1 examples/sec; 0.022 sec/batch)
2018-01-30 21:33:32.023984: step 185800, loss = 1.93 (8373.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:33:35.083120: step 186000, loss = 2.02 (8368.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:33:38.436038: step 186200, loss = 2.20 (7635.1 examples/sec; 0.017 sec/batch)
2018-01-30 21:33:44.211398: step 186400, loss = 2.05 (4432.6 examples/sec; 0.029 sec/batch)
2018-01-30 21:33:49.794246: step 186600, loss = 2.11 (4585.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:33:57.300226: step 186800, loss = 2.11 (3410.6 examples/sec; 0.038 sec/batch)
2018-01-30 21:34:00.360366: step 187000, loss = 2.04 (8365.6 examples/sec; 0.015 sec/batch)
2018-01-30 21:34:03.413485: step 187200, loss = 2.10 (8384.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:34:07.174488: step 187400, loss = 2.10 (6806.7 examples/sec; 0.019 sec/batch)
2018-01-30 21:34:13.033070: step 187600, loss = 2.07 (4370.4 examples/sec; 0.029 sec/batch)
2018-01-30 21:34:18.781358: step 187800, loss = 2.06 (4452.7 examples/sec; 0.029 sec/batch)
2018-01-30 21:34:23.856856: step 188000, loss = 2.10 (5043.8 examples/sec; 0.025 sec/batch)
2018-01-30 21:34:26.957101: step 188200, loss = 2.06 (8257.4 examples/sec; 0.016 sec/batch)
2018-01-30 21:34:30.039298: step 188400, loss = 1.94 (8305.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:34:33.140546: step 188600, loss = 2.01 (8254.7 examples/sec; 0.016 sec/batch)
2018-01-30 21:34:38.177944: step 188800, loss = 2.09 (5082.0 examples/sec; 0.025 sec/batch)
2018-01-30 21:34:44.004440: step 189000, loss = 1.92 (4393.7 examples/sec; 0.029 sec/batch)
2018-01-30 21:34:49.475992: step 189200, loss = 2.20 (4678.7 examples/sec; 0.027 sec/batch)
2018-01-30 21:34:55.294072: step 189400, loss = 2.00 (4400.1 examples/sec; 0.029 sec/batch)
2018-01-30 21:34:58.409356: step 189600, loss = 1.99 (8217.5 examples/sec; 0.016 sec/batch)
2018-01-30 21:35:01.473506: step 189800, loss = 2.04 (8354.7 examples/sec; 0.015 sec/batch)
2018-01-30 21:35:06.707426: step 190000, loss = 2.03 (4891.2 examples/sec; 0.026 sec/batch)
2018-01-30 21:35:12.171959: step 190200, loss = 2.15 (4684.8 examples/sec; 0.027 sec/batch)
2018-01-30 21:35:17.624461: step 190400, loss = 2.03 (4695.1 examples/sec; 0.027 sec/batch)
2018-01-30 21:35:21.933922: step 190600, loss = 2.06 (5940.4 examples/sec; 0.022 sec/batch)
2018-01-30 21:35:25.025144: step 190800, loss = 2.14 (8281.5 examples/sec; 0.015 sec/batch)
2018-01-30 21:35:28.081271: step 191000, loss = 2.07 (8376.6 examples/sec; 0.015 sec/batch)
2018-01-30 21:35:31.153442: step 191200, loss = 2.07 (8332.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:35:36.785421: step 191400, loss = 2.12 (4545.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:35:42.457506: step 191600, loss = 1.99 (4513.3 examples/sec; 0.028 sec/batch)
2018-01-30 21:35:47.996237: step 191800, loss = 2.07 (4622.0 examples/sec; 0.028 sec/batch)
2018-01-30 21:35:51.740194: step 192000, loss = 1.94 (6837.7 examples/sec; 0.019 sec/batch)
2018-01-30 21:35:56.480189: step 192200, loss = 2.01 (5400.9 examples/sec; 0.024 sec/batch)
2018-01-30 21:35:59.531303: step 192400, loss = 2.09 (8390.4 examples/sec; 0.015 sec/batch)
2018-01-30 21:36:04.465426: step 192600, loss = 2.07 (5188.4 examples/sec; 0.025 sec/batch)
2018-01-30 21:36:09.723410: step 192800, loss = 2.07 (4868.8 examples/sec; 0.026 sec/batch)
2018-01-30 21:36:15.396498: step 193000, loss = 2.00 (4512.5 examples/sec; 0.028 sec/batch)
2018-01-30 21:36:20.005756: step 193200, loss = 2.05 (5554.0 examples/sec; 0.023 sec/batch)
2018-01-30 21:36:23.091964: step 193400, loss = 2.06 (8295.0 examples/sec; 0.015 sec/batch)
2018-01-30 21:36:26.114002: step 193600, loss = 2.09 (8471.1 examples/sec; 0.015 sec/batch)
2018-01-30 21:36:29.186173: step 193800, loss = 2.10 (8332.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:36:34.718888: step 194000, loss = 2.12 (4627.0 examples/sec; 0.028 sec/batch)
2018-01-30 21:36:40.202471: step 194200, loss = 2.06 (4668.5 examples/sec; 0.027 sec/batch)
2018-01-30 21:36:45.790332: step 194400, loss = 2.01 (4581.4 examples/sec; 0.028 sec/batch)
2018-01-30 21:36:49.708754: step 194600, loss = 2.14 (6533.2 examples/sec; 0.020 sec/batch)
2018-01-30 21:36:52.790952: step 194800, loss = 2.12 (8305.8 examples/sec; 0.015 sec/batch)
2018-01-30 21:36:57.652622: step 195000, loss = 2.12 (5265.7 examples/sec; 0.024 sec/batch)
2018-01-30 21:37:02.764217: step 195200, loss = 2.09 (5008.2 examples/sec; 0.026 sec/batch)
2018-01-30 21:37:08.327012: step 195400, loss = 2.08 (4602.0 examples/sec; 0.028 sec/batch)
2018-01-30 21:37:13.763470: step 195600, loss = 2.07 (4708.9 examples/sec; 0.027 sec/batch)
2018-01-30 21:37:18.212302: step 195800, loss = 2.00 (5754.3 examples/sec; 0.022 sec/batch)
2018-01-30 21:37:21.248377: step 196000, loss = 2.13 (8431.9 examples/sec; 0.015 sec/batch)
2018-01-30 21:37:24.300494: step 196200, loss = 2.06 (8387.6 examples/sec; 0.015 sec/batch)
2018-01-30 21:37:27.596260: step 196400, loss = 2.09 (7767.5 examples/sec; 0.016 sec/batch)
2018-01-30 21:37:33.066809: step 196600, loss = 2.17 (4679.6 examples/sec; 0.027 sec/batch)
2018-01-30 21:37:38.718841: step 196800, loss = 1.95 (4529.3 examples/sec; 0.028 sec/batch)
2018-01-30 21:37:44.145273: step 197000, loss = 2.08 (4717.6 examples/sec; 0.027 sec/batch)
2018-01-30 21:37:47.862158: step 197200, loss = 1.95 (6887.5 examples/sec; 0.019 sec/batch)
2018-01-30 21:37:50.969422: step 197400, loss = 2.18 (8238.8 examples/sec; 0.016 sec/batch)
2018-01-30 21:37:55.718190: step 197600, loss = 2.13 (5390.9 examples/sec; 0.024 sec/batch)
2018-01-30 21:38:01.004248: step 197800, loss = 2.07 (4842.9 examples/sec; 0.026 sec/batch)
2018-01-30 21:38:06.274264: step 198000, loss = 2.05 (4857.7 examples/sec; 0.026 sec/batch)
2018-01-30 21:38:11.744814: step 198200, loss = 2.05 (4679.6 examples/sec; 0.027 sec/batch)
2018-01-30 21:38:16.143513: step 198400, loss = 2.10 (5819.9 examples/sec; 0.022 sec/batch)
2018-01-30 21:38:19.254787: step 198600, loss = 2.15 (8228.1 examples/sec; 0.016 sec/batch)
2018-01-30 21:38:22.343000: step 198800, loss = 2.11 (8289.6 examples/sec; 0.015 sec/batch)
2018-01-30 21:38:25.744046: step 199000, loss = 1.99 (7527.1 examples/sec; 0.017 sec/batch)
2018-01-30 21:38:31.645742: step 199200, loss = 2.10 (4337.7 examples/sec; 0.030 sec/batch)
2018-01-30 21:38:37.108270: step 199400, loss = 2.13 (4686.5 examples/sec; 0.027 sec/batch)
2018-01-30 21:38:42.389316: step 199600, loss = 2.06 (4847.5 examples/sec; 0.026 sec/batch)
2018-01-30 21:38:45.940760: step 199800, loss = 1.98 (7208.3 examples/sec; 0.018 sec/batch)