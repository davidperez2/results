Images -> gris
f=tf.Variable(initial_value=tf.range(-10,10,20/576,dtype=tf.float32),trainable=False)
f fixé
pas de distored_inputs


EVALUATION

2018-02-02 10:34:55.588996: precision @ 1 = 0.088
2018-02-02 10:35:45.715769: precision @ 1 = 0.193
2018-02-02 10:36:31.460647: precision @ 1 = 0.190
2018-02-02 10:37:21.604436: precision @ 1 = 0.190
2018-02-02 10:38:10.396138: precision @ 1 = 0.194
2018-02-02 10:38:56.261339: precision @ 1 = 0.192
2018-02-02 10:39:45.969817: precision @ 1 = 0.194
2018-02-02 10:40:31.315525: precision @ 1 = 0.195
2018-02-02 10:41:21.639279: precision @ 1 = 0.195
2018-02-02 10:42:07.953207: precision @ 1 = 0.193
2018-02-02 10:42:54.988022: precision @ 1 = 0.194
2018-02-02 10:43:46.216712: precision @ 1 = 0.195
2018-02-02 10:44:31.043919: precision @ 1 = 0.194
2018-02-02 10:45:21.307618: precision @ 1 = 0.196
2018-02-02 10:46:06.342274: precision @ 1 = 0.195
2018-02-02 10:46:54.267599: precision @ 1 = 0.193
2018-02-02 10:47:44.217501: precision @ 1 = 0.192
2018-02-02 10:48:29.653981: precision @ 1 = 0.193
2018-02-02 10:49:20.678162: precision @ 1 = 0.195
2018-02-02 10:50:07.660772: precision @ 1 = 0.195
2018-02-02 10:50:54.637611: precision @ 1 = 0.196
2018-02-02 10:51:45.104341: precision @ 1 = 0.194
2018-02-02 10:52:33.673510: precision @ 1 = 0.194
2018-02-02 10:53:23.353187: precision @ 1 = 0.191
2018-02-02 10:54:13.380026: precision @ 1 = 0.189
2018-02-02 10:55:00.939335: precision @ 1 = 0.192
2018-02-02 10:55:51.920434: precision @ 1 = 0.193
2018-02-02 10:56:39.157292: precision @ 1 = 0.193
2018-02-02 10:57:26.196059: precision @ 1 = 0.192
2018-02-02 10:58:16.922439: precision @ 1 = 0.193
2018-02-02 10:59:04.599129: precision @ 1 = 0.192
2018-02-02 10:59:53.804563: precision @ 1 = 0.191
2018-02-02 11:00:44.177589: precision @ 1 = 0.192
2018-02-02 11:01:29.163001: precision @ 1 = 0.193




LOSS (Train)




2018-02-02 10:34:21.980860: step 0, loss = 2.29 (3136.7 examples/sec; 0.041 sec/batch)
2018-02-02 10:34:23.856061: step 100, loss = 28.41 (6825.9 examples/sec; 0.019 sec/batch)
2018-02-02 10:34:25.153074: step 200, loss = 43.54 (9868.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:34:26.433226: step 300, loss = 55.11 (9998.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:34:27.761492: step 400, loss = 27.24 (9636.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:34:29.030332: step 500, loss = 62.72 (10088.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:34:30.271293: step 600, loss = 50.03 (10314.6 examples/sec; 0.012 sec/batch)
2018-02-02 10:34:31.521426: step 700, loss = 34.57 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:34:32.787187: step 800, loss = 32.47 (10112.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:34:34.021693: step 900, loss = 37.26 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:34:35.268651: step 1000, loss = 35.87 (10265.0 examples/sec; 0.012 sec/batch)
2018-02-02 10:34:36.565664: step 1100, loss = 34.46 (9868.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:34:37.847051: step 1200, loss = 55.57 (9989.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:34:39.128437: step 1300, loss = 31.30 (9989.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:34:40.378571: step 1400, loss = 35.11 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:34:42.566304: step 1500, loss = 35.27 (5850.8 examples/sec; 0.022 sec/batch)
2018-02-02 10:34:44.691530: step 1600, loss = 44.07 (6022.9 examples/sec; 0.021 sec/batch)
2018-02-02 10:34:46.629238: step 1700, loss = 28.40 (6605.7 examples/sec; 0.019 sec/batch)
2018-02-02 10:34:48.941984: step 1800, loss = 27.89 (5534.5 examples/sec; 0.023 sec/batch)
2018-02-02 10:34:51.160971: step 1900, loss = 54.25 (5768.4 examples/sec; 0.022 sec/batch)
2018-02-02 10:34:56.870383: step 2000, loss = 41.39 (2241.9 examples/sec; 0.057 sec/batch)
2018-02-02 10:34:58.073636: step 2100, loss = 53.03 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:34:59.276889: step 2200, loss = 32.69 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:00.464516: step 2300, loss = 27.15 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:01.683396: step 2400, loss = 39.94 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:02.886650: step 2500, loss = 42.48 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:04.074276: step 2600, loss = 27.01 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:05.277529: step 2700, loss = 31.90 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:06.465156: step 2800, loss = 41.61 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:07.652783: step 2900, loss = 30.38 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:08.849395: step 3000, loss = 30.94 (10696.9 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:10.052649: step 3100, loss = 38.10 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:11.255902: step 3200, loss = 29.10 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:12.521662: step 3300, loss = 42.50 (10112.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:35:13.756169: step 3400, loss = 40.35 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:15.025640: step 3500, loss = 34.97 (10082.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:35:16.228894: step 3600, loss = 45.63 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:17.447774: step 3700, loss = 37.29 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:18.697906: step 3800, loss = 28.03 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:35:19.948041: step 3900, loss = 31.78 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:35:21.168490: step 4000, loss = 28.16 (10487.9 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:22.934303: step 4100, loss = 56.99 (7248.8 examples/sec; 0.018 sec/batch)
2018-02-02 10:35:24.121930: step 4200, loss = 32.34 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:25.325183: step 4300, loss = 32.01 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:26.575317: step 4400, loss = 42.92 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:35:28.278624: step 4500, loss = 39.47 (7514.8 examples/sec; 0.017 sec/batch)
2018-02-02 10:35:30.575743: step 4600, loss = 42.19 (5572.2 examples/sec; 0.023 sec/batch)
2018-02-02 10:35:32.747850: step 4700, loss = 50.90 (5892.9 examples/sec; 0.022 sec/batch)
2018-02-02 10:35:34.870863: step 4800, loss = 28.37 (6029.2 examples/sec; 0.021 sec/batch)
2018-02-02 10:35:37.480517: step 4900, loss = 35.92 (4904.9 examples/sec; 0.026 sec/batch)
2018-02-02 10:35:39.418224: step 5000, loss = 51.80 (6605.7 examples/sec; 0.019 sec/batch)
2018-02-02 10:35:41.652836: step 5100, loss = 56.09 (5728.1 examples/sec; 0.022 sec/batch)
2018-02-02 10:35:44.106223: step 5200, loss = 26.73 (5217.3 examples/sec; 0.025 sec/batch)
2018-02-02 10:35:46.137691: step 5300, loss = 33.55 (6300.9 examples/sec; 0.020 sec/batch)
2018-02-02 10:35:47.360305: step 5400, loss = 40.51 (10469.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:48.579185: step 5500, loss = 35.96 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:49.790224: step 5600, loss = 32.01 (10569.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:51.009103: step 5700, loss = 42.29 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:52.875446: step 5800, loss = 36.21 (6858.3 examples/sec; 0.019 sec/batch)
2018-02-02 10:35:54.109951: step 5900, loss = 41.96 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:55.362725: step 6000, loss = 46.49 (10217.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:35:56.581605: step 6100, loss = 33.19 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:57.800486: step 6200, loss = 25.56 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:35:59.034992: step 6300, loss = 35.81 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:00.269499: step 6400, loss = 43.50 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:01.472752: step 6500, loss = 42.67 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:02.676005: step 6600, loss = 41.72 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:03.863632: step 6700, loss = 27.49 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:05.082512: step 6800, loss = 37.76 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:06.285765: step 6900, loss = 38.34 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:07.473392: step 7000, loss = 33.42 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:08.676646: step 7100, loss = 39.25 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:09.895525: step 7200, loss = 27.82 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:11.145659: step 7300, loss = 57.44 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:36:12.348912: step 7400, loss = 35.39 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:13.583419: step 7500, loss = 38.41 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:14.786080: step 7600, loss = 27.49 (10643.1 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:15.989332: step 7700, loss = 47.58 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:17.255093: step 7800, loss = 30.60 (10112.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:36:19.489706: step 7900, loss = 30.71 (5728.1 examples/sec; 0.022 sec/batch)
2018-02-02 10:36:26.955957: step 8000, loss = 48.01 (1714.4 examples/sec; 0.075 sec/batch)
2018-02-02 10:36:29.054139: step 8100, loss = 45.81 (6100.5 examples/sec; 0.021 sec/batch)
2018-02-02 10:36:31.054354: step 8200, loss = 35.41 (6399.3 examples/sec; 0.020 sec/batch)
2018-02-02 10:36:32.507636: step 8300, loss = 34.42 (8807.7 examples/sec; 0.015 sec/batch)
2018-02-02 10:36:33.710887: step 8400, loss = 30.23 (10637.9 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:34.909131: step 8500, loss = 41.78 (10682.3 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:36.112385: step 8600, loss = 27.90 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:37.331264: step 8700, loss = 47.38 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:38.518892: step 8800, loss = 56.38 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:39.722144: step 8900, loss = 49.06 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:40.941025: step 9000, loss = 33.01 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:42.128651: step 9100, loss = 51.56 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:43.331904: step 9200, loss = 24.80 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:44.550785: step 9300, loss = 50.74 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:45.754038: step 9400, loss = 32.77 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:46.972917: step 9500, loss = 22.50 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:48.191797: step 9600, loss = 35.41 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:49.379424: step 9700, loss = 37.12 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:50.582678: step 9800, loss = 37.05 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:52.432560: step 9900, loss = 26.70 (6919.4 examples/sec; 0.018 sec/batch)
2018-02-02 10:36:53.635813: step 10000, loss = 49.80 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:54.855977: step 10100, loss = 42.95 (10490.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:56.043604: step 10200, loss = 31.24 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:57.246858: step 10300, loss = 42.47 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:58.434485: step 10400, loss = 30.84 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:36:59.653364: step 10500, loss = 59.77 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:00.840991: step 10600, loss = 25.66 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:02.059871: step 10700, loss = 39.85 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:03.388138: step 10800, loss = 36.04 (9636.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:37:05.710898: step 10900, loss = 32.85 (5510.7 examples/sec; 0.023 sec/batch)
2018-02-02 10:37:08.070525: step 11000, loss = 33.34 (5424.6 examples/sec; 0.024 sec/batch)
2018-02-02 10:37:10.492658: step 11100, loss = 33.86 (5284.6 examples/sec; 0.024 sec/batch)
2018-02-02 10:37:12.961671: step 11200, loss = 33.68 (5184.3 examples/sec; 0.025 sec/batch)
2018-02-02 10:37:15.027871: step 11300, loss = 30.81 (6194.9 examples/sec; 0.021 sec/batch)
2018-02-02 10:37:17.387498: step 11400, loss = 30.95 (5424.6 examples/sec; 0.024 sec/batch)
2018-02-02 10:37:19.340830: step 11500, loss = 49.45 (6552.9 examples/sec; 0.020 sec/batch)
2018-02-02 10:37:22.255051: step 11600, loss = 29.07 (4392.3 examples/sec; 0.029 sec/batch)
2018-02-02 10:37:23.456045: step 11700, loss = 24.16 (10657.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:24.643672: step 11800, loss = 29.90 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:25.846926: step 11900, loss = 46.90 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:27.050179: step 12000, loss = 30.01 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:28.253432: step 12100, loss = 32.37 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:29.441058: step 12200, loss = 41.15 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:30.628685: step 12300, loss = 41.01 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:31.831939: step 12400, loss = 28.92 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:33.019565: step 12500, loss = 32.82 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:34.222818: step 12600, loss = 25.71 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:35.430882: step 12700, loss = 31.54 (10595.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:36.618509: step 12800, loss = 28.03 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:37.806136: step 12900, loss = 46.05 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:39.009388: step 13000, loss = 40.19 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:40.242977: step 13100, loss = 35.86 (10376.2 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:41.430604: step 13200, loss = 29.38 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:42.618230: step 13300, loss = 38.43 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:43.837110: step 13400, loss = 26.79 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:45.049904: step 13500, loss = 41.04 (10554.1 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:46.233382: step 13600, loss = 34.03 (10815.6 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:47.436635: step 13700, loss = 25.10 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:48.639889: step 13800, loss = 29.65 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:49.811889: step 13900, loss = 60.02 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:51.030768: step 14000, loss = 43.63 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:37:54.046715: step 14100, loss = 43.74 (4244.1 examples/sec; 0.030 sec/batch)
2018-02-02 10:37:55.957099: step 14200, loss = 52.96 (6700.2 examples/sec; 0.019 sec/batch)
2018-02-02 10:37:58.191712: step 14300, loss = 33.99 (5728.1 examples/sec; 0.022 sec/batch)
2018-02-02 10:38:00.348190: step 14400, loss = 41.42 (5935.6 examples/sec; 0.022 sec/batch)
2018-02-02 10:38:02.520299: step 14500, loss = 32.73 (5892.9 examples/sec; 0.022 sec/batch)
2018-02-02 10:38:04.661151: step 14600, loss = 38.94 (5978.9 examples/sec; 0.021 sec/batch)
2018-02-02 10:38:07.005152: step 14700, loss = 34.54 (5460.7 examples/sec; 0.023 sec/batch)
2018-02-02 10:38:09.130378: step 14800, loss = 34.66 (6022.9 examples/sec; 0.021 sec/batch)
2018-02-02 10:38:10.864938: step 14900, loss = 48.32 (7379.4 examples/sec; 0.017 sec/batch)
2018-02-02 10:38:12.068191: step 15000, loss = 48.95 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:13.240191: step 15100, loss = 51.46 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:14.471127: step 15200, loss = 31.09 (10398.6 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:15.674381: step 15300, loss = 37.97 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:16.893261: step 15400, loss = 33.41 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:18.096514: step 15500, loss = 26.84 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:19.299767: step 15600, loss = 32.55 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:20.490423: step 15700, loss = 37.91 (10750.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:22.271863: step 15800, loss = 45.26 (7185.2 examples/sec; 0.018 sec/batch)
2018-02-02 10:38:23.478808: step 15900, loss = 24.15 (10605.3 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:24.666434: step 16000, loss = 26.05 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:25.863172: step 16100, loss = 46.02 (10695.7 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:27.066426: step 16200, loss = 43.95 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:28.260295: step 16300, loss = 47.22 (10721.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:29.463549: step 16400, loss = 47.87 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:30.666803: step 16500, loss = 31.72 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:31.854429: step 16600, loss = 35.38 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:33.088936: step 16700, loss = 49.03 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:34.276562: step 16800, loss = 28.90 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:35.453280: step 16900, loss = 33.08 (10877.7 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:36.672160: step 17000, loss = 31.18 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:37.859788: step 17100, loss = 46.54 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:39.109921: step 17200, loss = 25.46 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:38:40.313174: step 17300, loss = 31.71 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:41.532054: step 17400, loss = 58.50 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:43.376001: step 17500, loss = 54.25 (6941.6 examples/sec; 0.018 sec/batch)
2018-02-02 10:38:45.407468: step 17600, loss = 31.23 (6300.9 examples/sec; 0.020 sec/batch)
2018-02-02 10:38:47.563948: step 17700, loss = 24.60 (5935.6 examples/sec; 0.022 sec/batch)
2018-02-02 10:38:49.876694: step 17800, loss = 56.76 (5534.5 examples/sec; 0.023 sec/batch)
2018-02-02 10:38:56.730141: step 17900, loss = 49.61 (1867.7 examples/sec; 0.069 sec/batch)
2018-02-02 10:38:57.917766: step 18000, loss = 32.22 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:38:59.136647: step 18100, loss = 33.82 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:00.324274: step 18200, loss = 35.81 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:01.527527: step 18300, loss = 27.21 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:02.740263: step 18400, loss = 41.49 (10554.6 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:03.927891: step 18500, loss = 31.46 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:05.122456: step 18600, loss = 43.58 (10715.2 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:06.341336: step 18700, loss = 27.43 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:07.544589: step 18800, loss = 63.29 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:08.716589: step 18900, loss = 52.83 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:09.919843: step 19000, loss = 38.13 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:11.107469: step 19100, loss = 32.52 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:12.295096: step 19200, loss = 42.81 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:13.513976: step 19300, loss = 28.17 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:14.692571: step 19400, loss = 51.78 (10860.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:15.880198: step 19500, loss = 29.88 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:17.114704: step 19600, loss = 46.65 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:18.302331: step 19700, loss = 28.74 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:19.505585: step 19800, loss = 32.56 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:20.723035: step 19900, loss = 49.91 (10513.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:22.545988: step 20000, loss = 23.49 (7021.6 examples/sec; 0.018 sec/batch)
2018-02-02 10:39:23.749242: step 20100, loss = 54.53 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:24.952495: step 20200, loss = 55.51 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:26.155571: step 20300, loss = 29.20 (10639.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:27.358825: step 20400, loss = 43.91 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:29.140264: step 20500, loss = 36.89 (7185.2 examples/sec; 0.018 sec/batch)
2018-02-02 10:39:31.524689: step 20600, loss = 38.70 (5368.2 examples/sec; 0.024 sec/batch)
2018-02-02 10:39:33.853064: step 20700, loss = 29.09 (5497.4 examples/sec; 0.023 sec/batch)
2018-02-02 10:39:36.213840: step 20800, loss = 56.62 (5421.9 examples/sec; 0.024 sec/batch)
2018-02-02 10:39:38.276560: step 20900, loss = 53.92 (6205.4 examples/sec; 0.021 sec/batch)
2018-02-02 10:39:40.478735: step 21000, loss = 45.27 (5812.4 examples/sec; 0.022 sec/batch)
2018-02-02 10:39:42.828858: step 21100, loss = 33.58 (5446.5 examples/sec; 0.024 sec/batch)
2018-02-02 10:39:45.047844: step 21200, loss = 39.11 (5768.4 examples/sec; 0.022 sec/batch)
2018-02-02 10:39:46.813657: step 21300, loss = 28.94 (7248.8 examples/sec; 0.018 sec/batch)
2018-02-02 10:39:48.016910: step 21400, loss = 48.12 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:49.204537: step 21500, loss = 38.53 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:50.423417: step 21600, loss = 23.24 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:52.251737: step 21700, loss = 38.33 (7001.0 examples/sec; 0.018 sec/batch)
2018-02-02 10:39:53.454990: step 21800, loss = 36.23 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:54.650046: step 21900, loss = 52.24 (10710.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:55.837673: step 22000, loss = 33.36 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:57.025300: step 22100, loss = 42.31 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:58.212926: step 22200, loss = 40.12 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:39:59.396815: step 22300, loss = 30.93 (10811.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:00.600068: step 22400, loss = 26.97 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:01.772068: step 22500, loss = 48.98 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:02.975321: step 22600, loss = 40.43 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:04.162948: step 22700, loss = 41.95 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:05.350575: step 22800, loss = 38.16 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:06.538202: step 22900, loss = 46.58 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:07.741455: step 23000, loss = 45.96 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:08.929082: step 23100, loss = 52.53 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:10.163588: step 23200, loss = 30.33 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:11.382468: step 23300, loss = 31.08 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:12.570094: step 23400, loss = 43.58 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:13.757722: step 23500, loss = 49.24 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:14.961915: step 23600, loss = 35.39 (10629.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:16.165168: step 23700, loss = 34.46 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:17.384048: step 23800, loss = 29.05 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:19.290501: step 23900, loss = 40.83 (6714.0 examples/sec; 0.019 sec/batch)
2018-02-02 10:40:27.143210: step 24000, loss = 29.18 (1630.0 examples/sec; 0.079 sec/batch)
2018-02-02 10:40:29.455952: step 24100, loss = 50.63 (5534.6 examples/sec; 0.023 sec/batch)
2018-02-02 10:40:31.549926: step 24200, loss = 33.09 (6112.8 examples/sec; 0.021 sec/batch)
2018-02-02 10:40:32.800059: step 24300, loss = 38.78 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:40:34.065819: step 24400, loss = 34.99 (10112.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:40:35.307300: step 24500, loss = 23.61 (10310.3 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:36.494927: step 24600, loss = 38.03 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:37.729433: step 24700, loss = 36.61 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:38.948314: step 24800, loss = 32.60 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:40.167194: step 24900, loss = 40.60 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:41.401700: step 25000, loss = 31.35 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:42.620580: step 25100, loss = 30.09 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:43.839460: step 25200, loss = 35.24 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:45.089594: step 25300, loss = 47.21 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:40:46.292847: step 25400, loss = 30.04 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:47.511727: step 25500, loss = 25.19 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:48.714985: step 25600, loss = 37.54 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:49.933861: step 25700, loss = 41.07 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:51.168367: step 25800, loss = 40.53 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:52.996687: step 25900, loss = 32.42 (7001.0 examples/sec; 0.018 sec/batch)
2018-02-02 10:40:54.184313: step 26000, loss = 25.78 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:55.401722: step 26100, loss = 50.33 (10514.1 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:56.636229: step 26200, loss = 23.51 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:57.823856: step 26300, loss = 35.22 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:40:59.023668: step 26400, loss = 52.85 (10668.3 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:00.226920: step 26500, loss = 46.21 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:01.445802: step 26600, loss = 26.23 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:02.678101: step 26700, loss = 29.56 (10387.1 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:04.577309: step 26800, loss = 28.92 (6739.7 examples/sec; 0.019 sec/batch)
2018-02-02 10:41:06.530642: step 26900, loss = 39.38 (6552.9 examples/sec; 0.020 sec/batch)
2018-02-02 10:41:08.640243: step 27000, loss = 45.86 (6067.5 examples/sec; 0.021 sec/batch)
2018-02-02 10:41:10.562323: step 27100, loss = 37.62 (6659.5 examples/sec; 0.019 sec/batch)
2018-02-02 10:41:13.281362: step 27200, loss = 39.47 (4707.5 examples/sec; 0.027 sec/batch)
2018-02-02 10:41:15.429073: step 27300, loss = 32.16 (5959.8 examples/sec; 0.021 sec/batch)
2018-02-02 10:41:17.648060: step 27400, loss = 33.22 (5768.4 examples/sec; 0.022 sec/batch)
2018-02-02 10:41:20.054566: step 27500, loss = 27.12 (5318.9 examples/sec; 0.024 sec/batch)
2018-02-02 10:41:22.639385: step 27600, loss = 43.89 (4952.0 examples/sec; 0.026 sec/batch)
2018-02-02 10:41:23.842639: step 27700, loss = 31.52 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:25.030265: step 27800, loss = 34.81 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:26.233518: step 27900, loss = 37.28 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:27.452398: step 28000, loss = 33.83 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:28.655652: step 28100, loss = 26.18 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:29.843279: step 28200, loss = 26.68 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:31.030905: step 28300, loss = 47.33 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:32.249785: step 28400, loss = 31.82 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:33.479378: step 28500, loss = 41.70 (10409.9 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:34.683197: step 28600, loss = 39.84 (10632.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:35.886451: step 28700, loss = 34.00 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:37.084065: step 28800, loss = 54.54 (10687.9 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:38.302944: step 28900, loss = 36.47 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:39.507668: step 29000, loss = 34.08 (10624.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:40.695295: step 29100, loss = 27.13 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:41.882921: step 29200, loss = 34.58 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:43.070548: step 29300, loss = 47.21 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:44.273802: step 29400, loss = 45.34 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:45.477055: step 29500, loss = 27.29 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:46.695935: step 29600, loss = 59.33 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:47.899188: step 29700, loss = 37.66 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:49.086815: step 29800, loss = 24.63 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:50.305694: step 29900, loss = 48.84 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:41:54.134228: step 30000, loss = 60.76 (3343.3 examples/sec; 0.038 sec/batch)
2018-02-02 10:41:56.563024: step 30100, loss = 37.03 (5270.1 examples/sec; 0.024 sec/batch)
2018-02-02 10:41:58.874114: step 30200, loss = 33.46 (5538.5 examples/sec; 0.023 sec/batch)
2018-02-02 10:42:01.483767: step 30300, loss = 41.61 (4904.9 examples/sec; 0.026 sec/batch)
2018-02-02 10:42:03.624620: step 30400, loss = 32.97 (5978.9 examples/sec; 0.021 sec/batch)
2018-02-02 10:42:05.734220: step 30500, loss = 32.09 (6067.5 examples/sec; 0.021 sec/batch)
2018-02-02 10:42:07.890701: step 30600, loss = 28.77 (5935.6 examples/sec; 0.022 sec/batch)
2018-02-02 10:42:09.140834: step 30700, loss = 42.85 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:42:10.344087: step 30800, loss = 35.92 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:11.547340: step 30900, loss = 49.61 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:12.750594: step 31000, loss = 32.38 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:13.938220: step 31100, loss = 40.32 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:15.159490: step 31200, loss = 30.60 (10480.9 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:16.365921: step 31300, loss = 30.79 (10609.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:17.572721: step 31400, loss = 36.18 (10606.6 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:18.760347: step 31500, loss = 37.88 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:19.963601: step 31600, loss = 27.23 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:21.167686: step 31700, loss = 42.38 (10630.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:23.011632: step 31800, loss = 34.23 (6941.6 examples/sec; 0.018 sec/batch)
2018-02-02 10:42:24.246139: step 31900, loss = 47.48 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:25.449392: step 32000, loss = 31.90 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:26.668272: step 32100, loss = 40.67 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:27.855898: step 32200, loss = 43.64 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:29.059152: step 32300, loss = 42.59 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:30.309286: step 32400, loss = 24.27 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:42:31.512538: step 32500, loss = 42.83 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:32.715792: step 32600, loss = 37.39 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:33.903419: step 32700, loss = 26.19 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:35.137624: step 32800, loss = 26.22 (10371.0 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:36.325250: step 32900, loss = 41.13 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:37.497250: step 33000, loss = 36.66 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:38.716130: step 33100, loss = 43.21 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:39.981891: step 33200, loss = 60.52 (10112.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:42:42.279010: step 33300, loss = 52.50 (5572.2 examples/sec; 0.023 sec/batch)
2018-02-02 10:42:44.576130: step 33400, loss = 56.46 (5572.2 examples/sec; 0.023 sec/batch)
2018-02-02 10:42:46.873250: step 33500, loss = 37.49 (5572.2 examples/sec; 0.023 sec/batch)
2018-02-02 10:42:49.014103: step 33600, loss = 25.98 (5978.9 examples/sec; 0.021 sec/batch)
2018-02-02 10:42:51.170583: step 33700, loss = 40.53 (5935.6 examples/sec; 0.022 sec/batch)
2018-02-02 10:42:56.253782: step 33800, loss = 36.91 (2518.1 examples/sec; 0.051 sec/batch)
2018-02-02 10:42:57.519542: step 33900, loss = 47.17 (10112.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:42:58.738422: step 34000, loss = 58.93 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:42:59.941675: step 34100, loss = 37.93 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:01.129302: step 34200, loss = 37.71 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:02.348182: step 34300, loss = 55.54 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:03.535808: step 34400, loss = 33.46 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:04.723435: step 34500, loss = 34.11 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:05.926688: step 34600, loss = 38.37 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:07.114315: step 34700, loss = 38.23 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:08.299154: step 34800, loss = 45.55 (10803.2 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:09.533661: step 34900, loss = 33.78 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:10.721288: step 35000, loss = 42.91 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:11.893287: step 35100, loss = 38.94 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:13.096541: step 35200, loss = 34.46 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:14.299794: step 35300, loss = 33.49 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:15.495738: step 35400, loss = 39.66 (10702.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:16.698992: step 35500, loss = 41.72 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:17.886619: step 35600, loss = 33.03 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:19.089872: step 35700, loss = 38.27 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:20.277498: step 35800, loss = 33.26 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:21.494759: step 35900, loss = 40.12 (10515.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:23.276199: step 36000, loss = 47.08 (7185.2 examples/sec; 0.018 sec/batch)
2018-02-02 10:43:24.479452: step 36100, loss = 42.08 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:25.698333: step 36200, loss = 47.49 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:26.917213: step 36300, loss = 46.91 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:28.995560: step 36400, loss = 40.76 (6158.7 examples/sec; 0.021 sec/batch)
2018-02-02 10:43:31.386439: step 36500, loss = 44.86 (5353.7 examples/sec; 0.024 sec/batch)
2018-02-02 10:43:33.761692: step 36600, loss = 32.01 (5388.9 examples/sec; 0.024 sec/batch)
2018-02-02 10:43:36.200019: step 36700, loss = 37.70 (5249.5 examples/sec; 0.024 sec/batch)
2018-02-02 10:43:38.137725: step 36800, loss = 33.32 (6605.8 examples/sec; 0.019 sec/batch)
2018-02-02 10:43:40.309833: step 36900, loss = 43.71 (5892.9 examples/sec; 0.022 sec/batch)
2018-02-02 10:43:42.403805: step 37000, loss = 35.15 (6112.8 examples/sec; 0.021 sec/batch)
2018-02-02 10:43:44.388393: step 37100, loss = 35.53 (6449.7 examples/sec; 0.020 sec/batch)
2018-02-02 10:43:46.435485: step 37200, loss = 43.49 (6252.8 examples/sec; 0.020 sec/batch)
2018-02-02 10:43:47.685619: step 37300, loss = 41.97 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:43:48.873245: step 37400, loss = 26.77 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:50.060872: step 37500, loss = 27.10 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:51.264125: step 37600, loss = 26.85 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:53.092445: step 37700, loss = 33.77 (7001.0 examples/sec; 0.018 sec/batch)
2018-02-02 10:43:54.295699: step 37800, loss = 26.94 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:55.507854: step 37900, loss = 32.73 (10559.7 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:56.695479: step 38000, loss = 46.59 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:57.914360: step 38100, loss = 36.00 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:43:59.117613: step 38200, loss = 41.76 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:00.320866: step 38300, loss = 36.41 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:01.524119: step 38400, loss = 37.78 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:02.727373: step 38500, loss = 33.71 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:03.930626: step 38600, loss = 40.48 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:05.133880: step 38700, loss = 28.51 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:06.321507: step 38800, loss = 30.97 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:07.509133: step 38900, loss = 37.09 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:08.712386: step 39000, loss = 29.26 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:09.884387: step 39100, loss = 47.42 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:11.086427: step 39200, loss = 35.75 (10648.6 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:12.269140: step 39300, loss = 27.16 (10822.6 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:13.483154: step 39400, loss = 46.45 (10543.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:14.678699: step 39500, loss = 33.32 (10706.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:15.866326: step 39600, loss = 54.72 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:17.100841: step 39700, loss = 35.44 (10368.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:18.960406: step 39800, loss = 52.11 (6883.3 examples/sec; 0.019 sec/batch)
2018-02-02 10:44:26.214425: step 39900, loss = 47.17 (1764.5 examples/sec; 0.073 sec/batch)
2018-02-02 10:44:28.745946: step 40000, loss = 36.03 (5056.2 examples/sec; 0.025 sec/batch)
2018-02-02 10:44:31.075172: step 40100, loss = 41.97 (5495.4 examples/sec; 0.023 sec/batch)
2018-02-02 10:44:32.305193: step 40200, loss = 36.54 (10406.3 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:33.492820: step 40300, loss = 34.78 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:34.690522: step 40400, loss = 29.84 (10687.1 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:35.909402: step 40500, loss = 53.14 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:37.097028: step 40600, loss = 36.88 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:38.300282: step 40700, loss = 36.79 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:39.503535: step 40800, loss = 35.52 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:40.691162: step 40900, loss = 29.01 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:41.910889: step 41000, loss = 33.40 (10494.2 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:43.114008: step 41100, loss = 37.56 (10639.0 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:44.301634: step 41200, loss = 26.10 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:45.504888: step 41300, loss = 42.44 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:46.723767: step 41400, loss = 42.70 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:47.942647: step 41500, loss = 28.17 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:49.130274: step 41600, loss = 52.39 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:50.317901: step 41700, loss = 34.06 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:51.530195: step 41800, loss = 38.67 (10558.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:53.374141: step 41900, loss = 36.91 (6941.6 examples/sec; 0.018 sec/batch)
2018-02-02 10:44:54.546142: step 42000, loss = 28.33 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:55.743549: step 42100, loss = 36.74 (10689.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:56.915549: step 42200, loss = 32.66 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:58.087549: step 42300, loss = 41.99 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:44:59.275176: step 42400, loss = 42.93 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:00.478429: step 42500, loss = 32.74 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:01.681682: step 42600, loss = 41.59 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:02.916189: step 42700, loss = 63.44 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:05.228936: step 42800, loss = 38.30 (5534.5 examples/sec; 0.023 sec/batch)
2018-02-02 10:45:07.588563: step 42900, loss = 35.79 (5424.6 examples/sec; 0.024 sec/batch)
2018-02-02 10:45:09.620029: step 43000, loss = 34.81 (6300.9 examples/sec; 0.020 sec/batch)
2018-02-02 10:45:11.793824: step 43100, loss = 44.33 (5888.3 examples/sec; 0.022 sec/batch)
2018-02-02 10:45:13.887798: step 43200, loss = 35.67 (6112.8 examples/sec; 0.021 sec/batch)
2018-02-02 10:45:16.099518: step 43300, loss = 43.70 (5787.4 examples/sec; 0.022 sec/batch)
2018-02-02 10:45:18.548335: step 43400, loss = 37.72 (5227.0 examples/sec; 0.024 sec/batch)
2018-02-02 10:45:20.901326: step 43500, loss = 33.38 (5439.9 examples/sec; 0.024 sec/batch)
2018-02-02 10:45:23.037607: step 43600, loss = 34.50 (5991.7 examples/sec; 0.021 sec/batch)
2018-02-02 10:45:24.397127: step 43700, loss = 43.32 (9415.1 examples/sec; 0.014 sec/batch)
2018-02-02 10:45:25.720010: step 43800, loss = 32.71 (9675.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:45:27.017025: step 43900, loss = 30.82 (9868.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:45:28.235904: step 44000, loss = 34.49 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:29.439157: step 44100, loss = 32.45 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:30.650435: step 44200, loss = 34.29 (10567.3 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:31.869315: step 44300, loss = 41.05 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:33.075744: step 44400, loss = 32.64 (10609.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:34.310252: step 44500, loss = 25.14 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:35.529132: step 44600, loss = 45.63 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:36.728886: step 44700, loss = 40.78 (10668.9 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:37.932140: step 44800, loss = 52.72 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:39.119767: step 44900, loss = 42.16 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:40.323021: step 45000, loss = 43.51 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:41.526273: step 45100, loss = 33.92 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:42.723952: step 45200, loss = 49.27 (10687.3 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:43.927204: step 45300, loss = 28.54 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:45.130459: step 45400, loss = 22.16 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:46.333712: step 45500, loss = 45.94 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:47.568219: step 45600, loss = 35.38 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:48.740218: step 45700, loss = 24.09 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:49.927845: step 45800, loss = 40.05 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:51.131097: step 45900, loss = 29.80 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:45:56.888141: step 46000, loss = 35.18 (2223.4 examples/sec; 0.058 sec/batch)
2018-02-02 10:45:59.091501: step 46100, loss = 32.84 (5809.3 examples/sec; 0.022 sec/batch)
2018-02-02 10:46:01.388621: step 46200, loss = 47.21 (5572.2 examples/sec; 0.023 sec/batch)
2018-02-02 10:46:03.576355: step 46300, loss = 29.57 (5850.8 examples/sec; 0.022 sec/batch)
2018-02-02 10:46:06.076621: step 46400, loss = 37.81 (5119.5 examples/sec; 0.025 sec/batch)
2018-02-02 10:46:07.483021: step 46500, loss = 47.16 (9101.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:46:08.686274: step 46600, loss = 47.07 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:09.883508: step 46700, loss = 40.46 (10691.3 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:11.055508: step 46800, loss = 37.99 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:12.274388: step 46900, loss = 57.18 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:13.477641: step 47000, loss = 40.16 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:14.665269: step 47100, loss = 46.19 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:15.852894: step 47200, loss = 61.68 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:17.063900: step 47300, loss = 57.25 (10569.7 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:18.251527: step 47400, loss = 33.46 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:19.454780: step 47500, loss = 74.78 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:20.690884: step 47600, loss = 34.92 (10355.1 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:22.503578: step 47700, loss = 33.54 (7061.3 examples/sec; 0.018 sec/batch)
2018-02-02 10:46:23.722459: step 47800, loss = 37.71 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:24.956965: step 47900, loss = 33.57 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:26.128964: step 48000, loss = 33.11 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:27.316592: step 48100, loss = 36.33 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:28.504218: step 48200, loss = 34.20 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:29.691844: step 48300, loss = 47.89 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:30.926352: step 48400, loss = 31.35 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:32.129605: step 48500, loss = 23.04 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:33.442244: step 48600, loss = 50.54 (9751.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:46:34.708005: step 48700, loss = 44.96 (10112.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:46:36.032456: step 48800, loss = 39.66 (9664.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:46:37.282588: step 48900, loss = 26.84 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:46:38.860882: step 49000, loss = 32.16 (8110.0 examples/sec; 0.016 sec/batch)
2018-02-02 10:46:41.111122: step 49100, loss = 29.77 (5688.3 examples/sec; 0.023 sec/batch)
2018-02-02 10:46:43.314483: step 49200, loss = 37.66 (5809.3 examples/sec; 0.022 sec/batch)
2018-02-02 10:46:45.330322: step 49300, loss = 34.51 (6349.7 examples/sec; 0.020 sec/batch)
2018-02-02 10:46:47.627442: step 49400, loss = 34.40 (5572.2 examples/sec; 0.023 sec/batch)
2018-02-02 10:46:49.876505: step 49500, loss = 38.95 (5691.3 examples/sec; 0.022 sec/batch)
2018-02-02 10:46:54.892665: step 49600, loss = 41.77 (2551.8 examples/sec; 0.050 sec/batch)
2018-02-02 10:46:56.153999: step 49700, loss = 41.48 (10148.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:46:57.362498: step 49800, loss = 67.65 (10591.7 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:58.565752: step 49900, loss = 38.03 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:46:59.769005: step 50000, loss = 54.11 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:01.003511: step 50100, loss = 53.60 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:02.222391: step 50200, loss = 39.24 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:03.441272: step 50300, loss = 35.07 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:04.644525: step 50400, loss = 35.10 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:05.879031: step 50500, loss = 29.10 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:07.082285: step 50600, loss = 48.63 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:08.285539: step 50700, loss = 43.80 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:09.517621: step 50800, loss = 33.76 (10388.9 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:10.752128: step 50900, loss = 27.06 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:11.955382: step 51000, loss = 33.89 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:13.174262: step 51100, loss = 32.59 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:14.393142: step 51200, loss = 30.28 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:15.596395: step 51300, loss = 42.55 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:16.825666: step 51400, loss = 24.36 (10412.7 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:18.028919: step 51500, loss = 36.84 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:19.232173: step 51600, loss = 29.62 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:20.453803: step 51700, loss = 42.23 (10477.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:22.313367: step 51800, loss = 35.02 (6883.3 examples/sec; 0.019 sec/batch)
2018-02-02 10:47:23.532247: step 51900, loss = 47.22 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:24.782380: step 52000, loss = 45.12 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:47:26.126273: step 52100, loss = 36.64 (9524.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:47:28.309744: step 52200, loss = 31.62 (5862.2 examples/sec; 0.022 sec/batch)
2018-02-02 10:47:30.747502: step 52300, loss = 42.68 (5250.7 examples/sec; 0.024 sec/batch)
2018-02-02 10:47:33.028995: step 52400, loss = 42.65 (5610.4 examples/sec; 0.023 sec/batch)
2018-02-02 10:47:35.357369: step 52500, loss = 36.10 (5497.4 examples/sec; 0.023 sec/batch)
2018-02-02 10:47:37.701181: step 52600, loss = 45.46 (5461.2 examples/sec; 0.023 sec/batch)
2018-02-02 10:47:39.795154: step 52700, loss = 46.90 (6112.8 examples/sec; 0.021 sec/batch)
2018-02-02 10:47:41.998514: step 52800, loss = 29.98 (5809.3 examples/sec; 0.022 sec/batch)
2018-02-02 10:47:44.233127: step 52900, loss = 29.69 (5728.1 examples/sec; 0.022 sec/batch)
2018-02-02 10:47:45.467634: step 53000, loss = 32.35 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:46.653920: step 53100, loss = 29.21 (10790.0 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:47.872801: step 53200, loss = 43.25 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:49.091681: step 53300, loss = 35.80 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:50.294933: step 53400, loss = 32.55 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:51.513814: step 53500, loss = 34.76 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:53.310880: step 53600, loss = 31.30 (7122.7 examples/sec; 0.018 sec/batch)
2018-02-02 10:47:54.529761: step 53700, loss = 43.56 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:55.733014: step 53800, loss = 28.16 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:56.962417: step 53900, loss = 41.84 (10411.6 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:58.165670: step 54000, loss = 29.28 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:47:59.368923: step 54100, loss = 29.46 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:00.580872: step 54200, loss = 40.23 (10561.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:01.799752: step 54300, loss = 32.33 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:03.034259: step 54400, loss = 48.29 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:04.221885: step 54500, loss = 31.02 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:05.487645: step 54600, loss = 26.50 (10112.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:48:06.705465: step 54700, loss = 42.98 (10510.6 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:07.919875: step 54800, loss = 33.58 (10540.1 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:09.138755: step 54900, loss = 30.36 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:10.373261: step 55000, loss = 33.65 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:11.592141: step 55100, loss = 57.59 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:12.785240: step 55200, loss = 28.48 (10728.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:13.988493: step 55300, loss = 31.50 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:15.223000: step 55400, loss = 38.97 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:17.082363: step 55500, loss = 40.13 (6884.1 examples/sec; 0.019 sec/batch)
2018-02-02 10:48:19.363858: step 55600, loss = 37.60 (5610.4 examples/sec; 0.023 sec/batch)
2018-02-02 10:48:26.372381: step 55700, loss = 38.11 (1826.3 examples/sec; 0.070 sec/batch)
2018-02-02 10:48:28.763261: step 55800, loss = 27.89 (5353.7 examples/sec; 0.024 sec/batch)
2018-02-02 10:48:30.450940: step 55900, loss = 69.61 (7584.4 examples/sec; 0.017 sec/batch)
2018-02-02 10:48:31.654196: step 56000, loss = 30.92 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:32.846868: step 56100, loss = 39.21 (10732.2 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:34.050121: step 56200, loss = 39.93 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:35.253374: step 56300, loss = 29.39 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:36.462782: step 56400, loss = 33.58 (10583.7 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:37.697288: step 56500, loss = 28.05 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:38.900542: step 56600, loss = 37.01 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:40.088168: step 56700, loss = 34.15 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:41.291421: step 56800, loss = 31.75 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:42.494675: step 56900, loss = 34.75 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:43.729185: step 57000, loss = 37.51 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:44.932435: step 57100, loss = 43.26 (10637.9 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:46.133145: step 57200, loss = 34.50 (10660.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:47.320771: step 57300, loss = 34.32 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:48.524025: step 57400, loss = 29.89 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:49.711651: step 57500, loss = 48.55 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:50.899567: step 57600, loss = 36.90 (10775.2 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:52.712262: step 57700, loss = 47.37 (7061.3 examples/sec; 0.018 sec/batch)
2018-02-02 10:48:53.931141: step 57800, loss = 36.14 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:55.118769: step 57900, loss = 30.28 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:56.296704: step 58000, loss = 30.67 (10866.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:57.484330: step 58100, loss = 39.32 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:58.687583: step 58200, loss = 52.78 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:48:59.890837: step 58300, loss = 31.85 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:49:01.125344: step 58400, loss = 41.28 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:49:03.203691: step 58500, loss = 36.88 (6158.7 examples/sec; 0.021 sec/batch)
2018-02-02 10:49:05.438303: step 58600, loss = 26.44 (5728.1 examples/sec; 0.022 sec/batch)
2018-02-02 10:49:07.742687: step 58700, loss = 32.35 (5554.6 examples/sec; 0.023 sec/batch)
2018-02-02 10:49:09.789780: step 58800, loss = 45.66 (6252.8 examples/sec; 0.020 sec/batch)
2018-02-02 10:49:11.852501: step 58900, loss = 33.32 (6205.4 examples/sec; 0.021 sec/batch)
2018-02-02 10:49:13.774580: step 59000, loss = 38.56 (6659.5 examples/sec; 0.019 sec/batch)
2018-02-02 10:49:15.884180: step 59100, loss = 30.87 (6067.5 examples/sec; 0.021 sec/batch)
2018-02-02 10:49:18.341340: step 59200, loss = 32.89 (5209.3 examples/sec; 0.025 sec/batch)
2018-02-02 10:49:20.725044: step 59300, loss = 52.80 (5369.8 examples/sec; 0.024 sec/batch)
2018-02-02 10:49:22.523428: step 59400, loss = 31.45 (7117.5 examples/sec; 0.018 sec/batch)
2018-02-02 10:49:23.801546: step 59500, loss = 31.28 (10014.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:49:25.152569: step 59600, loss = 33.75 (9474.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:49:26.734654: step 59700, loss = 38.55 (8090.6 examples/sec; 0.016 sec/batch)
2018-02-02 10:49:28.117703: step 59800, loss = 35.90 (9254.9 examples/sec; 0.014 sec/batch)
2018-02-02 10:49:29.506957: step 59900, loss = 29.58 (9213.6 examples/sec; 0.014 sec/batch)
2018-02-02 10:49:30.924549: step 60000, loss = 25.64 (9029.4 examples/sec; 0.014 sec/batch)
2018-02-02 10:49:32.354912: step 60100, loss = 36.00 (8948.8 examples/sec; 0.014 sec/batch)
2018-02-02 10:49:33.743379: step 60200, loss = 36.29 (9218.8 examples/sec; 0.014 sec/batch)
2018-02-02 10:49:35.063765: step 60300, loss = 30.17 (9694.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:49:36.532986: step 60400, loss = 34.65 (8712.1 examples/sec; 0.015 sec/batch)
2018-02-02 10:49:37.899620: step 60500, loss = 40.63 (9366.1 examples/sec; 0.014 sec/batch)
2018-02-02 10:49:39.285305: step 60600, loss = 39.93 (9237.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:49:40.584761: step 60700, loss = 29.90 (9850.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:49:41.914297: step 60800, loss = 46.49 (9627.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:49:43.192697: step 60900, loss = 34.86 (10012.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:49:44.515215: step 61000, loss = 36.45 (9678.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:49:45.833722: step 61100, loss = 36.64 (9708.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:49:47.161252: step 61200, loss = 42.67 (9642.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:49:48.463716: step 61300, loss = 53.64 (9827.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:49:49.744121: step 61400, loss = 32.30 (9996.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:49:51.103737: step 61500, loss = 42.93 (9414.4 examples/sec; 0.014 sec/batch)
2018-02-02 10:49:57.276155: step 61600, loss = 38.65 (2073.7 examples/sec; 0.062 sec/batch)
2018-02-02 10:49:59.886095: step 61700, loss = 46.97 (4904.3 examples/sec; 0.026 sec/batch)
2018-02-02 10:50:02.380730: step 61800, loss = 31.86 (5131.0 examples/sec; 0.025 sec/batch)
2018-02-02 10:50:04.914481: step 61900, loss = 49.59 (5051.8 examples/sec; 0.025 sec/batch)
2018-02-02 10:50:07.299812: step 62000, loss = 40.45 (5366.1 examples/sec; 0.024 sec/batch)
2018-02-02 10:50:08.809829: step 62100, loss = 48.36 (8476.7 examples/sec; 0.015 sec/batch)
2018-02-02 10:50:10.130225: step 62200, loss = 30.67 (9694.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:11.379991: step 62300, loss = 32.35 (10241.9 examples/sec; 0.012 sec/batch)
2018-02-02 10:50:12.598871: step 62400, loss = 47.51 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:50:13.880267: step 62500, loss = 32.77 (9989.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:15.224151: step 62600, loss = 52.75 (9524.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:16.675936: step 62700, loss = 44.58 (8816.7 examples/sec; 0.015 sec/batch)
2018-02-02 10:50:18.078667: step 62800, loss = 40.02 (9125.1 examples/sec; 0.014 sec/batch)
2018-02-02 10:50:19.430262: step 62900, loss = 28.49 (9470.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:50:20.737738: step 63000, loss = 32.87 (9789.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:22.799237: step 63100, loss = 33.14 (6209.1 examples/sec; 0.021 sec/batch)
2018-02-02 10:50:24.126768: step 63200, loss = 47.47 (9642.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:25.446276: step 63300, loss = 31.03 (9700.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:26.731695: step 63400, loss = 42.26 (9957.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:28.011098: step 63500, loss = 47.39 (10004.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:29.302532: step 63600, loss = 35.80 (9911.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:30.564890: step 63700, loss = 28.95 (10139.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:31.886102: step 63800, loss = 40.59 (9688.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:33.212630: step 63900, loss = 45.35 (9649.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:34.513089: step 64000, loss = 38.36 (9842.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:35.783467: step 64100, loss = 33.98 (10075.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:37.078912: step 64200, loss = 66.38 (9880.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:38.369344: step 64300, loss = 27.90 (9919.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:40.488982: step 64400, loss = 37.64 (6038.8 examples/sec; 0.021 sec/batch)
2018-02-02 10:50:42.894379: step 64500, loss = 28.50 (5321.4 examples/sec; 0.024 sec/batch)
2018-02-02 10:50:45.473238: step 64600, loss = 46.77 (4963.4 examples/sec; 0.026 sec/batch)
2018-02-02 10:50:47.885654: step 64700, loss = 42.05 (5305.9 examples/sec; 0.024 sec/batch)
2018-02-02 10:50:50.036374: step 64800, loss = 37.08 (5951.5 examples/sec; 0.022 sec/batch)
2018-02-02 10:50:55.236203: step 64900, loss = 28.47 (2461.6 examples/sec; 0.052 sec/batch)
2018-02-02 10:50:56.540672: step 65000, loss = 34.50 (9812.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:57.828096: step 65100, loss = 33.03 (9942.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:50:59.104491: step 65200, loss = 48.10 (10028.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:00.387904: step 65300, loss = 51.55 (9973.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:01.708416: step 65400, loss = 33.63 (9693.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:02.986816: step 65500, loss = 35.42 (10012.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:04.271232: step 65600, loss = 36.32 (9965.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:05.542614: step 65700, loss = 29.84 (10067.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:06.808982: step 65800, loss = 50.16 (10107.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:08.086379: step 65900, loss = 26.21 (10020.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:09.353750: step 66000, loss = 33.78 (10099.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:10.638167: step 66100, loss = 47.04 (9965.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:11.997783: step 66200, loss = 51.95 (9414.4 examples/sec; 0.014 sec/batch)
2018-02-02 10:51:13.338347: step 66300, loss = 27.76 (9548.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:14.650838: step 66400, loss = 41.66 (9752.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:15.941270: step 66500, loss = 43.11 (9919.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:17.363051: step 66600, loss = 32.81 (9002.8 examples/sec; 0.014 sec/batch)
2018-02-02 10:51:18.677549: step 66700, loss = 34.43 (9737.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:20.023126: step 66800, loss = 29.23 (9512.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:21.300523: step 66900, loss = 38.67 (10020.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:23.218133: step 67000, loss = 39.95 (6675.0 examples/sec; 0.019 sec/batch)
2018-02-02 10:51:24.517588: step 67100, loss = 48.19 (9850.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:25.814036: step 67200, loss = 48.52 (9873.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:28.383871: step 67300, loss = 42.16 (4980.9 examples/sec; 0.026 sec/batch)
2018-02-02 10:51:30.761195: step 67400, loss = 29.07 (5384.2 examples/sec; 0.024 sec/batch)
2018-02-02 10:51:33.297941: step 67500, loss = 49.06 (5045.8 examples/sec; 0.025 sec/batch)
2018-02-02 10:51:35.740437: step 67600, loss = 32.48 (5240.5 examples/sec; 0.024 sec/batch)
2018-02-02 10:51:38.092693: step 67700, loss = 38.39 (5441.6 examples/sec; 0.024 sec/batch)
2018-02-02 10:51:40.484053: step 67800, loss = 45.10 (5352.6 examples/sec; 0.024 sec/batch)
2018-02-02 10:51:42.903488: step 67900, loss = 25.80 (5290.5 examples/sec; 0.024 sec/batch)
2018-02-02 10:51:45.224660: step 68000, loss = 61.22 (5514.5 examples/sec; 0.023 sec/batch)
2018-02-02 10:51:46.541162: step 68100, loss = 31.05 (9722.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:47.902784: step 68200, loss = 42.36 (9400.6 examples/sec; 0.014 sec/batch)
2018-02-02 10:51:49.298509: step 68300, loss = 24.50 (9170.9 examples/sec; 0.014 sec/batch)
2018-02-02 10:51:50.663125: step 68400, loss = 42.05 (9379.9 examples/sec; 0.014 sec/batch)
2018-02-02 10:51:52.716581: step 68500, loss = 34.23 (6233.4 examples/sec; 0.021 sec/batch)
2018-02-02 10:51:54.076197: step 68600, loss = 38.95 (9414.4 examples/sec; 0.014 sec/batch)
2018-02-02 10:51:55.383675: step 68700, loss = 34.05 (9789.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:56.689147: step 68800, loss = 32.59 (9804.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:57.954512: step 68900, loss = 39.49 (10115.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:51:59.229904: step 69000, loss = 42.90 (10036.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:00.587515: step 69100, loss = 35.56 (9428.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:52:01.873936: step 69200, loss = 26.49 (9950.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:03.184421: step 69300, loss = 30.43 (9767.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:04.495909: step 69400, loss = 43.08 (9759.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:05.809403: step 69500, loss = 28.63 (9745.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:07.128912: step 69600, loss = 30.48 (9700.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:08.455440: step 69700, loss = 52.83 (9649.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:09.791995: step 69800, loss = 31.92 (9576.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:11.133563: step 69900, loss = 34.69 (9541.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:12.444048: step 70000, loss = 36.12 (9767.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:13.795643: step 70100, loss = 34.29 (9470.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:52:15.144229: step 70200, loss = 38.93 (9491.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:16.596091: step 70300, loss = 37.70 (8816.3 examples/sec; 0.015 sec/batch)
2018-02-02 10:52:19.316325: step 70400, loss = 32.97 (4705.5 examples/sec; 0.027 sec/batch)
2018-02-02 10:52:24.685606: step 70500, loss = 38.77 (2383.9 examples/sec; 0.054 sec/batch)
2018-02-02 10:52:27.275495: step 70600, loss = 36.44 (4942.3 examples/sec; 0.026 sec/batch)
2018-02-02 10:52:30.003750: step 70700, loss = 55.50 (4691.6 examples/sec; 0.027 sec/batch)
2018-02-02 10:52:32.788155: step 70800, loss = 59.76 (4597.0 examples/sec; 0.028 sec/batch)
2018-02-02 10:52:34.522768: step 70900, loss = 40.80 (7379.2 examples/sec; 0.017 sec/batch)
2018-02-02 10:52:35.877371: step 71000, loss = 43.60 (9449.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:52:37.262054: step 71100, loss = 39.84 (9244.0 examples/sec; 0.014 sec/batch)
2018-02-02 10:52:38.684841: step 71200, loss = 31.45 (8996.4 examples/sec; 0.014 sec/batch)
2018-02-02 10:52:40.005349: step 71300, loss = 28.56 (9693.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:41.363963: step 71400, loss = 53.05 (9421.4 examples/sec; 0.014 sec/batch)
2018-02-02 10:52:42.688485: step 71500, loss = 38.54 (9663.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:43.973904: step 71600, loss = 27.20 (9957.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:45.254309: step 71700, loss = 37.57 (9996.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:46.599888: step 71800, loss = 28.40 (9512.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:47.950480: step 71900, loss = 28.08 (9477.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:52:49.286032: step 72000, loss = 50.98 (9584.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:50.590501: step 72100, loss = 48.38 (9812.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:52.515171: step 72200, loss = 39.57 (6650.5 examples/sec; 0.019 sec/batch)
2018-02-02 10:52:53.820643: step 72300, loss = 37.98 (9804.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:55.145166: step 72400, loss = 64.69 (9663.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:56.475704: step 72500, loss = 28.21 (9620.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:57.782179: step 72600, loss = 50.84 (9797.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:52:59.108706: step 72700, loss = 47.94 (9649.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:00.392120: step 72800, loss = 52.00 (9973.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:01.675533: step 72900, loss = 38.33 (9973.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:03.025123: step 73000, loss = 45.05 (9484.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:04.373709: step 73100, loss = 34.33 (9491.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:06.454242: step 73200, loss = 25.94 (6152.3 examples/sec; 0.021 sec/batch)
2018-02-02 10:53:08.768397: step 73300, loss = 33.84 (5531.2 examples/sec; 0.023 sec/batch)
2018-02-02 10:53:11.114637: step 73400, loss = 36.33 (5455.5 examples/sec; 0.023 sec/batch)
2018-02-02 10:53:13.464888: step 73500, loss = 35.89 (5446.2 examples/sec; 0.024 sec/batch)
2018-02-02 10:53:15.927437: step 73600, loss = 35.23 (5197.9 examples/sec; 0.025 sec/batch)
2018-02-02 10:53:18.286712: step 73700, loss = 40.21 (5425.4 examples/sec; 0.024 sec/batch)
2018-02-02 10:53:20.535693: step 73800, loss = 44.61 (5691.5 examples/sec; 0.022 sec/batch)
2018-02-02 10:53:24.359648: step 73900, loss = 50.46 (3347.3 examples/sec; 0.038 sec/batch)
2018-02-02 10:53:25.674144: step 74000, loss = 53.64 (9737.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:26.963573: step 74100, loss = 35.89 (9926.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:28.262026: step 74200, loss = 40.87 (9857.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:29.546442: step 74300, loss = 29.29 (9965.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:30.811808: step 74400, loss = 54.58 (10115.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:32.099232: step 74500, loss = 45.10 (9942.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:33.413728: step 74600, loss = 30.02 (9737.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:34.712181: step 74700, loss = 49.07 (9857.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:36.162037: step 74800, loss = 31.98 (8828.5 examples/sec; 0.014 sec/batch)
2018-02-02 10:53:37.444448: step 74900, loss = 28.03 (9981.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:38.768970: step 75000, loss = 34.28 (9663.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:40.079456: step 75100, loss = 35.59 (9767.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:41.379914: step 75200, loss = 49.99 (9842.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:42.672352: step 75300, loss = 30.89 (9903.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:44.006901: step 75400, loss = 35.31 (9591.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:45.331424: step 75500, loss = 57.73 (9663.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:46.656949: step 75600, loss = 22.89 (9656.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:48.030602: step 75700, loss = 26.58 (9318.2 examples/sec; 0.014 sec/batch)
2018-02-02 10:53:49.296970: step 75800, loss = 43.80 (10107.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:50.724768: step 75900, loss = 38.08 (8964.9 examples/sec; 0.014 sec/batch)
2018-02-02 10:53:52.801296: step 76000, loss = 53.18 (6164.1 examples/sec; 0.021 sec/batch)
2018-02-02 10:53:54.119802: step 76100, loss = 34.64 (9708.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:53:56.485099: step 76200, loss = 37.66 (5411.6 examples/sec; 0.024 sec/batch)
2018-02-02 10:53:59.032869: step 76300, loss = 59.37 (5024.0 examples/sec; 0.025 sec/batch)
2018-02-02 10:54:01.549563: step 76400, loss = 36.92 (5086.0 examples/sec; 0.025 sec/batch)
2018-02-02 10:54:03.916858: step 76500, loss = 33.40 (5407.0 examples/sec; 0.024 sec/batch)
2018-02-02 10:54:06.448592: step 76600, loss = 30.12 (5055.8 examples/sec; 0.025 sec/batch)
2018-02-02 10:54:08.916154: step 76700, loss = 37.25 (5189.4 examples/sec; 0.025 sec/batch)
2018-02-02 10:54:11.041808: step 76800, loss = 45.72 (6018.8 examples/sec; 0.021 sec/batch)
2018-02-02 10:54:13.500346: step 76900, loss = 41.00 (5206.3 examples/sec; 0.025 sec/batch)
2018-02-02 10:54:14.830884: step 77000, loss = 38.80 (9620.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:54:16.132346: step 77100, loss = 30.37 (9835.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:54:17.491962: step 77200, loss = 46.29 (9414.4 examples/sec; 0.014 sec/batch)
2018-02-02 10:54:18.806458: step 77300, loss = 35.75 (9737.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:54:20.114938: step 77400, loss = 31.90 (9782.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:54:21.490598: step 77500, loss = 62.41 (9304.6 examples/sec; 0.014 sec/batch)
2018-02-02 10:54:23.447243: step 77600, loss = 36.75 (6541.8 examples/sec; 0.020 sec/batch)
2018-02-02 10:54:24.776779: step 77700, loss = 36.38 (9627.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:54:26.113334: step 77800, loss = 34.34 (9576.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:54:27.388726: step 77900, loss = 34.84 (10036.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:54:28.660107: step 78000, loss = 41.99 (10067.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:54:29.952544: step 78100, loss = 46.08 (9903.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:54:31.315168: step 78200, loss = 37.98 (9393.6 examples/sec; 0.014 sec/batch)
2018-02-02 10:54:32.667766: step 78300, loss = 49.39 (9463.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:54:34.019361: step 78400, loss = 21.46 (9470.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:54:35.314921: step 78500, loss = 55.00 (9879.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:54:36.579284: step 78600, loss = 25.76 (10123.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:54:37.955946: step 78700, loss = 51.49 (9297.9 examples/sec; 0.014 sec/batch)
2018-02-02 10:54:39.326591: step 78800, loss = 36.85 (9338.7 examples/sec; 0.014 sec/batch)
2018-02-02 10:54:40.718293: step 78900, loss = 44.08 (9197.4 examples/sec; 0.014 sec/batch)
2018-02-02 10:54:42.101973: step 79000, loss = 46.93 (9250.7 examples/sec; 0.014 sec/batch)
2018-02-02 10:54:43.484649: step 79100, loss = 30.29 (9257.4 examples/sec; 0.014 sec/batch)
2018-02-02 10:54:44.948543: step 79200, loss = 40.28 (8743.8 examples/sec; 0.015 sec/batch)
2018-02-02 10:54:47.285759: step 79300, loss = 38.01 (5476.6 examples/sec; 0.023 sec/batch)
2018-02-02 10:54:49.651050: step 79400, loss = 31.86 (5411.6 examples/sec; 0.024 sec/batch)
2018-02-02 10:54:56.178864: step 79500, loss = 36.45 (1960.8 examples/sec; 0.065 sec/batch)
2018-02-02 10:54:58.778263: step 79600, loss = 34.19 (4924.2 examples/sec; 0.026 sec/batch)
2018-02-02 10:55:00.975431: step 79700, loss = 41.36 (5825.7 examples/sec; 0.022 sec/batch)
2018-02-02 10:55:02.261149: step 79800, loss = 56.02 (9955.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:55:03.679708: step 79900, loss = 38.14 (9023.2 examples/sec; 0.014 sec/batch)
2018-02-02 10:55:05.043335: step 80000, loss = 37.74 (9386.7 examples/sec; 0.014 sec/batch)
2018-02-02 10:55:06.505220: step 80100, loss = 39.89 (8755.8 examples/sec; 0.015 sec/batch)
2018-02-02 10:55:07.975253: step 80200, loss = 38.78 (8707.3 examples/sec; 0.015 sec/batch)
2018-02-02 10:55:09.315993: step 80300, loss = 24.98 (9554.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:55:10.811297: step 80400, loss = 34.25 (8554.4 examples/sec; 0.015 sec/batch)
2018-02-02 10:55:12.140275: step 80500, loss = 30.98 (9631.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:55:13.792748: step 80600, loss = 24.18 (7746.0 examples/sec; 0.017 sec/batch)
2018-02-02 10:55:15.446057: step 80700, loss = 39.47 (7742.1 examples/sec; 0.017 sec/batch)
2018-02-02 10:55:16.782528: step 80800, loss = 32.12 (9577.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:55:17.967376: step 80900, loss = 26.94 (10803.1 examples/sec; 0.012 sec/batch)
2018-02-02 10:55:19.174810: step 81000, loss = 41.47 (10601.0 examples/sec; 0.012 sec/batch)
2018-02-02 10:55:20.558880: step 81100, loss = 35.56 (9248.1 examples/sec; 0.014 sec/batch)
2018-02-02 10:55:22.542680: step 81200, loss = 45.53 (6452.3 examples/sec; 0.020 sec/batch)
2018-02-02 10:55:23.795360: step 81300, loss = 40.41 (10218.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:55:25.007164: step 81400, loss = 41.77 (10562.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:55:26.398034: step 81500, loss = 36.53 (9202.9 examples/sec; 0.014 sec/batch)
2018-02-02 10:55:27.679442: step 81600, loss = 39.24 (9989.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:55:28.980904: step 81700, loss = 46.40 (9835.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:55:30.367717: step 81800, loss = 40.18 (9229.8 examples/sec; 0.014 sec/batch)
2018-02-02 10:55:31.670055: step 81900, loss = 53.33 (9828.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:55:33.578975: step 82000, loss = 36.64 (6705.4 examples/sec; 0.019 sec/batch)
2018-02-02 10:55:35.889467: step 82100, loss = 25.82 (5539.9 examples/sec; 0.023 sec/batch)
2018-02-02 10:55:38.467117: step 82200, loss = 54.62 (4965.8 examples/sec; 0.026 sec/batch)
2018-02-02 10:55:40.871047: step 82300, loss = 40.09 (5324.6 examples/sec; 0.024 sec/batch)
2018-02-02 10:55:43.454919: step 82400, loss = 37.91 (4953.8 examples/sec; 0.026 sec/batch)
2018-02-02 10:55:45.836252: step 82500, loss = 47.00 (5375.1 examples/sec; 0.024 sec/batch)
2018-02-02 10:55:48.095260: step 82600, loss = 43.37 (5666.2 examples/sec; 0.023 sec/batch)
2018-02-02 10:55:50.474588: step 82700, loss = 32.27 (5379.7 examples/sec; 0.024 sec/batch)
2018-02-02 10:55:53.138674: step 82800, loss = 30.31 (4804.7 examples/sec; 0.027 sec/batch)
2018-02-02 10:55:54.459186: step 82900, loss = 37.56 (9693.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:55:55.790727: step 83000, loss = 38.38 (9612.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:55:57.142322: step 83100, loss = 45.23 (9470.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:55:58.524999: step 83200, loss = 41.55 (9257.4 examples/sec; 0.014 sec/batch)
2018-02-02 10:55:59.831473: step 83300, loss = 29.27 (9797.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:01.137949: step 83400, loss = 35.86 (9797.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:02.436401: step 83500, loss = 37.72 (9857.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:03.815068: step 83600, loss = 29.51 (9284.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:56:05.106503: step 83700, loss = 36.29 (9911.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:06.377885: step 83800, loss = 30.03 (10067.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:07.646258: step 83900, loss = 34.65 (10091.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:08.918642: step 84000, loss = 45.17 (10059.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:10.194033: step 84100, loss = 25.52 (10036.1 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:11.472433: step 84200, loss = 27.51 (10012.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:12.731783: step 84300, loss = 41.83 (10164.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:13.986119: step 84400, loss = 44.24 (10204.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:15.245468: step 84500, loss = 42.05 (10164.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:16.508828: step 84600, loss = 43.72 (10131.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:17.752135: step 84700, loss = 67.29 (10295.1 examples/sec; 0.012 sec/batch)
2018-02-02 10:56:19.000455: step 84800, loss = 36.19 (10253.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:56:20.267825: step 84900, loss = 43.34 (10099.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:21.535196: step 85000, loss = 36.64 (10099.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:25.545089: step 85100, loss = 28.66 (3192.1 examples/sec; 0.040 sec/batch)
2018-02-02 10:56:27.899351: step 85200, loss = 32.47 (5436.9 examples/sec; 0.024 sec/batch)
2018-02-02 10:56:30.307756: step 85300, loss = 32.82 (5314.7 examples/sec; 0.024 sec/batch)
2018-02-02 10:56:32.714157: step 85400, loss = 26.35 (5319.1 examples/sec; 0.024 sec/batch)
2018-02-02 10:56:35.072428: step 85500, loss = 39.83 (5427.7 examples/sec; 0.024 sec/batch)
2018-02-02 10:56:37.275286: step 85600, loss = 47.25 (5810.6 examples/sec; 0.022 sec/batch)
2018-02-02 10:56:39.505217: step 85700, loss = 58.21 (5740.1 examples/sec; 0.022 sec/batch)
2018-02-02 10:56:40.804673: step 85800, loss = 24.95 (9850.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:42.102124: step 85900, loss = 37.38 (9865.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:43.380523: step 86000, loss = 49.41 (10012.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:44.645890: step 86100, loss = 27.48 (10115.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:45.917270: step 86200, loss = 27.41 (10067.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:47.180630: step 86300, loss = 29.00 (10131.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:48.427948: step 86400, loss = 27.27 (10262.0 examples/sec; 0.012 sec/batch)
2018-02-02 10:56:49.709355: step 86500, loss = 24.42 (9989.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:50.955670: step 86600, loss = 33.06 (10270.3 examples/sec; 0.012 sec/batch)
2018-02-02 10:56:52.871430: step 86700, loss = 32.85 (6681.4 examples/sec; 0.019 sec/batch)
2018-02-02 10:56:54.156848: step 86800, loss = 48.37 (9957.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:55.403163: step 86900, loss = 33.93 (10270.3 examples/sec; 0.012 sec/batch)
2018-02-02 10:56:56.687579: step 87000, loss = 44.64 (9965.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:57.942917: step 87100, loss = 40.63 (10196.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:56:59.203269: step 87200, loss = 33.93 (10155.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:00.482672: step 87300, loss = 27.05 (10004.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:01.744027: step 87400, loss = 34.86 (10147.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:03.058523: step 87500, loss = 36.95 (9737.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:04.414129: step 87600, loss = 38.29 (9442.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:57:05.771739: step 87700, loss = 46.21 (9428.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:57:07.057158: step 87800, loss = 39.92 (9957.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:08.414768: step 87900, loss = 36.37 (9428.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:57:09.780400: step 88000, loss = 30.86 (9373.0 examples/sec; 0.014 sec/batch)
2018-02-02 10:57:12.019355: step 88100, loss = 35.47 (5717.0 examples/sec; 0.022 sec/batch)
2018-02-02 10:57:14.505968: step 88200, loss = 25.74 (5147.6 examples/sec; 0.025 sec/batch)
2018-02-02 10:57:16.968517: step 88300, loss = 42.03 (5197.9 examples/sec; 0.025 sec/batch)
2018-02-02 10:57:19.502256: step 88400, loss = 34.08 (5051.8 examples/sec; 0.025 sec/batch)
2018-02-02 10:57:26.118854: step 88500, loss = 37.84 (1934.5 examples/sec; 0.066 sec/batch)
2018-02-02 10:57:27.468443: step 88600, loss = 30.80 (9484.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:28.757872: step 88700, loss = 25.31 (9926.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:30.219760: step 88800, loss = 34.26 (8755.8 examples/sec; 0.015 sec/batch)
2018-02-02 10:57:31.569349: step 88900, loss = 43.06 (9484.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:32.933979: step 89000, loss = 43.36 (9379.8 examples/sec; 0.014 sec/batch)
2018-02-02 10:57:34.318662: step 89100, loss = 26.07 (9244.0 examples/sec; 0.014 sec/batch)
2018-02-02 10:57:35.653211: step 89200, loss = 65.44 (9591.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:37.075996: step 89300, loss = 29.51 (8996.4 examples/sec; 0.014 sec/batch)
2018-02-02 10:57:38.511518: step 89400, loss = 28.65 (8916.6 examples/sec; 0.014 sec/batch)
2018-02-02 10:57:39.840189: step 89500, loss = 19.37 (9633.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:41.151815: step 89600, loss = 26.17 (9758.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:42.641105: step 89700, loss = 38.29 (8594.7 examples/sec; 0.015 sec/batch)
2018-02-02 10:57:44.047506: step 89800, loss = 42.70 (9101.2 examples/sec; 0.014 sec/batch)
2018-02-02 10:57:45.360145: step 89900, loss = 49.73 (9751.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:46.655717: step 90000, loss = 51.58 (9879.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:47.934751: step 90100, loss = 43.53 (10007.6 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:49.122377: step 90200, loss = 34.94 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:57:50.356884: step 90300, loss = 24.51 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:57:51.637289: step 90400, loss = 34.02 (9996.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:57:53.481236: step 90500, loss = 41.76 (6941.6 examples/sec; 0.018 sec/batch)
2018-02-02 10:57:54.700115: step 90600, loss = 56.76 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:57:55.934622: step 90700, loss = 24.19 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:57:57.169129: step 90800, loss = 22.38 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:57:58.747423: step 90900, loss = 33.34 (8110.0 examples/sec; 0.016 sec/batch)
2018-02-02 10:58:01.095543: step 91000, loss = 37.31 (5451.2 examples/sec; 0.023 sec/batch)
2018-02-02 10:58:03.439543: step 91100, loss = 40.61 (5460.8 examples/sec; 0.023 sec/batch)
2018-02-02 10:58:05.549144: step 91200, loss = 23.99 (6067.5 examples/sec; 0.021 sec/batch)
2018-02-02 10:58:07.799384: step 91300, loss = 45.87 (5688.3 examples/sec; 0.023 sec/batch)
2018-02-02 10:58:10.065251: step 91400, loss = 52.25 (5649.1 examples/sec; 0.023 sec/batch)
2018-02-02 10:58:12.375079: step 91500, loss = 43.21 (5541.5 examples/sec; 0.023 sec/batch)
2018-02-02 10:58:15.015984: step 91600, loss = 41.69 (4846.8 examples/sec; 0.026 sec/batch)
2018-02-02 10:58:17.109958: step 91700, loss = 37.81 (6112.8 examples/sec; 0.021 sec/batch)
2018-02-02 10:58:18.360091: step 91800, loss = 28.06 (10238.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:58:19.593488: step 91900, loss = 28.72 (10377.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:58:20.796737: step 92000, loss = 49.14 (10637.9 examples/sec; 0.012 sec/batch)
2018-02-02 10:58:22.578178: step 92100, loss = 59.31 (7185.2 examples/sec; 0.018 sec/batch)
2018-02-02 10:58:23.790009: step 92200, loss = 43.15 (10562.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:58:25.031152: step 92300, loss = 43.22 (10313.1 examples/sec; 0.012 sec/batch)
2018-02-02 10:58:26.234406: step 92400, loss = 42.71 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:58:27.422033: step 92500, loss = 38.26 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:58:28.656539: step 92600, loss = 41.30 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:58:29.899844: step 92700, loss = 24.88 (10295.1 examples/sec; 0.012 sec/batch)
2018-02-02 10:58:31.183436: step 92800, loss = 36.99 (9972.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:58:32.655990: step 92900, loss = 44.22 (8692.4 examples/sec; 0.015 sec/batch)
2018-02-02 10:58:34.042570: step 93000, loss = 51.42 (9231.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:58:35.404710: step 93100, loss = 39.27 (9397.0 examples/sec; 0.014 sec/batch)
2018-02-02 10:58:36.718303: step 93200, loss = 42.96 (9744.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:58:38.097117: step 93300, loss = 25.71 (9283.3 examples/sec; 0.014 sec/batch)
2018-02-02 10:58:39.385330: step 93400, loss = 25.38 (9936.2 examples/sec; 0.013 sec/batch)
2018-02-02 10:58:40.736832: step 93500, loss = 30.34 (9470.9 examples/sec; 0.014 sec/batch)
2018-02-02 10:58:42.018430: step 93600, loss = 35.07 (9987.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:58:43.321790: step 93700, loss = 27.77 (9820.8 examples/sec; 0.013 sec/batch)
2018-02-02 10:58:44.630915: step 93800, loss = 36.24 (9777.5 examples/sec; 0.013 sec/batch)
2018-02-02 10:58:45.873259: step 93900, loss = 27.57 (10303.1 examples/sec; 0.012 sec/batch)
2018-02-02 10:58:47.260193: step 94000, loss = 39.66 (9229.0 examples/sec; 0.014 sec/batch)
2018-02-02 10:58:48.970993: step 94100, loss = 31.09 (7481.9 examples/sec; 0.017 sec/batch)
2018-02-02 10:58:51.467478: step 94200, loss = 44.19 (5127.2 examples/sec; 0.025 sec/batch)
2018-02-02 10:58:57.746827: step 94300, loss = 45.62 (2038.4 examples/sec; 0.063 sec/batch)
2018-02-02 10:59:00.182849: step 94400, loss = 46.85 (5254.5 examples/sec; 0.024 sec/batch)
2018-02-02 10:59:02.652857: step 94500, loss = 26.60 (5182.2 examples/sec; 0.025 sec/batch)
2018-02-02 10:59:04.808833: step 94600, loss = 48.39 (5937.0 examples/sec; 0.022 sec/batch)
2018-02-02 10:59:06.017774: step 94700, loss = 28.98 (10587.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:59:07.230305: step 94800, loss = 28.47 (10556.4 examples/sec; 0.012 sec/batch)
2018-02-02 10:59:08.449289: step 94900, loss = 36.03 (10500.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:59:09.719009: step 95000, loss = 49.89 (10081.0 examples/sec; 0.013 sec/batch)
2018-02-02 10:59:10.992724: step 95100, loss = 28.63 (10049.3 examples/sec; 0.013 sec/batch)
2018-02-02 10:59:12.253848: step 95200, loss = 35.85 (10149.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:59:13.497707: step 95300, loss = 27.37 (10290.6 examples/sec; 0.012 sec/batch)
2018-02-02 10:59:14.693788: step 95400, loss = 49.68 (10701.6 examples/sec; 0.012 sec/batch)
2018-02-02 10:59:15.897041: step 95500, loss = 27.16 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:59:17.100295: step 95600, loss = 34.96 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:59:18.503349: step 95700, loss = 32.34 (9123.0 examples/sec; 0.014 sec/batch)
2018-02-02 10:59:19.819850: step 95800, loss = 34.64 (9722.7 examples/sec; 0.013 sec/batch)
2018-02-02 10:59:21.159341: step 95900, loss = 30.20 (9555.9 examples/sec; 0.013 sec/batch)
2018-02-02 10:59:23.235388: step 96000, loss = 48.22 (6165.6 examples/sec; 0.021 sec/batch)
2018-02-02 10:59:24.450563: step 96100, loss = 43.78 (10533.5 examples/sec; 0.012 sec/batch)
2018-02-02 10:59:25.905550: step 96200, loss = 28.62 (8797.3 examples/sec; 0.015 sec/batch)
2018-02-02 10:59:27.514365: step 96300, loss = 42.23 (7956.2 examples/sec; 0.016 sec/batch)
2018-02-02 10:59:29.027312: step 96400, loss = 39.86 (8460.3 examples/sec; 0.015 sec/batch)
2018-02-02 10:59:30.685447: step 96500, loss = 41.32 (7719.5 examples/sec; 0.017 sec/batch)
2018-02-02 10:59:32.333595: step 96600, loss = 32.62 (7766.3 examples/sec; 0.016 sec/batch)
2018-02-02 10:59:33.868483: step 96700, loss = 41.96 (8339.4 examples/sec; 0.015 sec/batch)
2018-02-02 10:59:35.210280: step 96800, loss = 32.94 (9539.4 examples/sec; 0.013 sec/batch)
2018-02-02 10:59:36.764645: step 96900, loss = 36.29 (8234.9 examples/sec; 0.016 sec/batch)
2018-02-02 10:59:38.888573: step 97000, loss = 45.65 (6026.6 examples/sec; 0.021 sec/batch)
2018-02-02 10:59:40.880752: step 97100, loss = 31.16 (6425.1 examples/sec; 0.020 sec/batch)
2018-02-02 10:59:43.041394: step 97200, loss = 25.79 (5924.2 examples/sec; 0.022 sec/batch)
2018-02-02 10:59:45.209433: step 97300, loss = 39.34 (5904.0 examples/sec; 0.022 sec/batch)
2018-02-02 10:59:47.373240: step 97400, loss = 40.40 (5915.5 examples/sec; 0.022 sec/batch)
2018-02-02 10:59:49.694749: step 97500, loss = 47.02 (5513.7 examples/sec; 0.023 sec/batch)
2018-02-02 10:59:51.788722: step 97600, loss = 53.10 (6112.8 examples/sec; 0.021 sec/batch)
2018-02-02 10:59:55.335976: step 97700, loss = 44.78 (3608.4 examples/sec; 0.035 sec/batch)
2018-02-02 10:59:56.523604: step 97800, loss = 27.75 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:59:57.711229: step 97900, loss = 33.15 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 10:59:58.914483: step 98000, loss = 33.31 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:00.099277: step 98100, loss = 41.12 (10803.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:01.286904: step 98200, loss = 28.58 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:02.490157: step 98300, loss = 25.22 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:03.677784: step 98400, loss = 31.82 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:04.865413: step 98500, loss = 40.05 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:06.053037: step 98600, loss = 47.31 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:07.240664: step 98700, loss = 28.36 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:08.428290: step 98800, loss = 24.84 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:09.615917: step 98900, loss = 28.25 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:10.803544: step 99000, loss = 63.27 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:11.991170: step 99100, loss = 23.56 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:13.194425: step 99200, loss = 32.63 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:14.382050: step 99300, loss = 40.16 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:15.569677: step 99400, loss = 30.06 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:16.741677: step 99500, loss = 40.74 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:17.929305: step 99600, loss = 48.26 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:19.115655: step 99700, loss = 33.16 (10789.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:20.303281: step 99800, loss = 35.70 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:21.490909: step 99900, loss = 39.60 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:23.319228: step 100000, loss = 37.57 (7001.0 examples/sec; 0.018 sec/batch)
2018-02-02 11:00:24.522481: step 100100, loss = 35.79 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:25.756988: step 100200, loss = 30.50 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:27.505425: step 100300, loss = 35.30 (7320.8 examples/sec; 0.017 sec/batch)
2018-02-02 11:00:29.630650: step 100400, loss = 36.50 (6022.9 examples/sec; 0.021 sec/batch)
2018-02-02 11:00:31.865988: step 100500, loss = 30.04 (5726.2 examples/sec; 0.022 sec/batch)
2018-02-02 11:00:34.084975: step 100600, loss = 49.66 (5768.4 examples/sec; 0.022 sec/batch)
2018-02-02 11:00:36.257081: step 100700, loss = 43.69 (5892.9 examples/sec; 0.022 sec/batch)
2018-02-02 11:00:38.932907: step 100800, loss = 39.07 (4783.6 examples/sec; 0.027 sec/batch)
2018-02-02 11:00:41.083510: step 100900, loss = 29.17 (5951.8 examples/sec; 0.022 sec/batch)
2018-02-02 11:00:43.552523: step 101000, loss = 42.62 (5184.3 examples/sec; 0.025 sec/batch)
2018-02-02 11:00:45.068310: step 101100, loss = 27.52 (8444.5 examples/sec; 0.015 sec/batch)
2018-02-02 11:00:46.255936: step 101200, loss = 51.66 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:47.443563: step 101300, loss = 45.87 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:48.646816: step 101400, loss = 56.45 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:49.834443: step 101500, loss = 30.27 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:51.037696: step 101600, loss = 42.91 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:52.819136: step 101700, loss = 43.87 (7185.2 examples/sec; 0.018 sec/batch)
2018-02-02 11:00:54.022389: step 101800, loss = 32.34 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:55.241269: step 101900, loss = 31.46 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:56.475776: step 102000, loss = 34.14 (10368.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:57.679029: step 102100, loss = 45.91 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:00:58.866657: step 102200, loss = 38.71 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:00.069642: step 102300, loss = 37.77 (10640.2 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:01.257269: step 102400, loss = 35.65 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:02.444896: step 102500, loss = 35.39 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:03.663775: step 102600, loss = 42.00 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:04.851403: step 102700, loss = 28.37 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:06.055531: step 102800, loss = 46.27 (10630.1 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:07.258784: step 102900, loss = 47.05 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:08.450298: step 103000, loss = 36.70 (10742.6 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:09.636922: step 103100, loss = 23.67 (10786.9 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:10.808923: step 103200, loss = 38.07 (10921.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:12.012176: step 103300, loss = 42.88 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:13.231055: step 103400, loss = 52.82 (10501.5 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:14.418682: step 103500, loss = 59.54 (10777.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:15.621936: step 103600, loss = 40.17 (10637.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:17.528390: step 103700, loss = 37.85 (6714.0 examples/sec; 0.019 sec/batch)
2018-02-02 11:01:19.681587: step 103800, loss = 32.44 (5944.6 examples/sec; 0.022 sec/batch)
2018-02-02 11:01:21.588039: step 103900, loss = 29.89 (6714.0 examples/sec; 0.019 sec/batch)
2018-02-02 11:01:29.413028: step 104000, loss = 24.37 (1635.8 examples/sec; 0.078 sec/batch)
2018-02-02 11:01:30.631907: step 104100, loss = 42.78 (10501.4 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:31.926623: step 104200, loss = 34.20 (9886.3 examples/sec; 0.013 sec/batch)
2018-02-02 11:01:33.208013: step 104300, loss = 26.50 (9989.2 examples/sec; 0.013 sec/batch)
2018-02-02 11:01:34.489397: step 104400, loss = 42.53 (9989.2 examples/sec; 0.013 sec/batch)
2018-02-02 11:01:35.770783: step 104500, loss = 39.85 (9989.2 examples/sec; 0.013 sec/batch)
2018-02-02 11:01:37.052169: step 104600, loss = 25.37 (9989.2 examples/sec; 0.013 sec/batch)
2018-02-02 11:01:38.317938: step 104700, loss = 47.26 (10112.4 examples/sec; 0.013 sec/batch)
2018-02-02 11:01:39.567355: step 104800, loss = 34.31 (10244.8 examples/sec; 0.012 sec/batch)
2018-02-02 11:01:40.862918: step 104900, loss = 28.46 (9879.9 examples/sec; 0.013 sec/batch)

