Images -> gris
pas de distored_inputs
f=tf.Variable(initial_value=tf.range(-5,5,10/576,dtype=tf.float32),trainable=True)
wdf=5/576
wdW=5/5760


EVALUATION

2018-02-01 16:29:55.668646: precision @ 1 = 0.082
2018-02-01 16:30:44.435209: precision @ 1 = 0.204
2018-02-01 16:31:26.960230: precision @ 1 = 0.210
2018-02-01 16:32:15.781026: precision @ 1 = 0.210
2018-02-01 16:32:57.527154: precision @ 1 = 0.208
2018-02-01 16:33:44.943228: precision @ 1 = 0.207
2018-02-01 16:34:26.876822: precision @ 1 = 0.205
2018-02-01 16:35:14.616469: precision @ 1 = 0.202
2018-02-01 16:35:56.821200: precision @ 1 = 0.202
2018-02-01 16:36:44.712824: precision @ 1 = 0.201
2018-02-01 16:37:26.738182: precision @ 1 = 0.200
2018-02-01 16:38:14.666637: precision @ 1 = 0.199
2018-02-01 16:38:56.859089: precision @ 1 = 0.199
2018-02-01 16:39:44.287503: precision @ 1 = 0.199
2018-02-01 16:40:26.550540: precision @ 1 = 0.197
2018-02-01 16:41:15.100066: precision @ 1 = 0.197
2018-02-01 16:41:57.095443: precision @ 1 = 0.196
2018-02-01 16:42:44.666623: precision @ 1 = 0.194
2018-02-01 16:43:26.729880: precision @ 1 = 0.195
2018-02-01 16:44:14.157407: precision @ 1 = 0.196
2018-02-01 16:44:56.660190: precision @ 1 = 0.196
2018-02-01 16:45:43.936245: precision @ 1 = 0.195
2018-02-01 16:46:26.784505: precision @ 1 = 0.195
2018-02-01 16:47:14.377744: precision @ 1 = 0.196
2018-02-01 16:47:56.897652: precision @ 1 = 0.196
2018-02-01 16:48:44.666551: precision @ 1 = 0.196
2018-02-01 16:49:27.876149: precision @ 1 = 0.196
2018-02-01 16:50:19.432842: precision @ 1 = 0.196
2018-02-01 16:51:16.292723: precision @ 1 = 0.196
2018-02-01 16:52:24.717712: precision @ 1 = 0.196
2018-02-01 16:53:23.381816: precision @ 1 = 0.196
2018-02-01 16:54:23.607835: precision @ 1 = 0.196
2018-02-01 16:55:19.525567: precision @ 1 = 0.196
2018-02-01 16:55:59.756419: precision @ 1 = 0.196
2018-02-01 16:56:47.281566: precision @ 1 = 0.196
2018-02-01 16:57:28.560884: precision @ 1 = 0.196
2018-02-01 16:58:16.640814: precision @ 1 = 0.196
2018-02-01 16:58:58.309828: precision @ 1 = 0.196
2018-02-01 16:59:45.878618: precision @ 1 = 0.196
2018-02-01 17:00:27.943655: precision @ 1 = 0.195
2018-02-01 17:01:16.045407: precision @ 1 = 0.195
2018-02-01 17:01:57.898338: precision @ 1 = 0.195
2018-02-01 17:02:46.173410: precision @ 1 = 0.195
2018-02-01 17:03:27.932132: precision @ 1 = 0.196
2018-02-01 17:04:15.402924: precision @ 1 = 0.196
2018-02-01 17:04:57.496477: precision @ 1 = 0.196
2018-02-01 17:05:45.219504: precision @ 1 = 0.196
2018-02-01 17:06:27.504014: precision @ 1 = 0.196
2018-02-01 17:07:14.966722: precision @ 1 = 0.196
2018-02-01 17:07:57.439915: precision @ 1 = 0.196
2018-02-01 17:08:45.466933: precision @ 1 = 0.195
2018-02-01 17:09:27.664113: precision @ 1 = 0.195
2018-02-01 17:10:15.461741: precision @ 1 = 0.195
2018-02-01 17:10:57.751263: precision @ 1 = 0.195
2018-02-01 17:11:45.787337: precision @ 1 = 0.195
2018-02-01 17:12:27.795513: precision @ 1 = 0.195
2018-02-01 17:13:15.521379: precision @ 1 = 0.195
2018-02-01 17:13:57.689080: precision @ 1 = 0.195
2018-02-01 17:14:45.128809: precision @ 1 = 0.195
2018-02-01 17:15:27.446701: precision @ 1 = 0.195
2018-02-01 17:16:15.876728: precision @ 1 = 0.195
2018-02-01 17:16:58.015450: precision @ 1 = 0.195
2018-02-01 17:17:45.837977: precision @ 1 = 0.195
2018-02-01 17:18:28.081109: precision @ 1 = 0.195
2018-02-01 17:19:15.561459: precision @ 1 = 0.195
2018-02-01 17:19:57.779267: precision @ 1 = 0.195
2018-02-01 17:20:45.682621: precision @ 1 = 0.195
2018-02-01 17:21:28.109435: precision @ 1 = 0.195
2018-02-01 17:22:15.208169: precision @ 1 = 0.195
2018-02-01 17:22:57.539738: precision @ 1 = 0.195
2018-02-01 17:23:45.481390: precision @ 1 = 0.195
2018-02-01 17:24:27.781483: precision @ 1 = 0.195
2018-02-01 17:25:15.460438: precision @ 1 = 0.195
2018-02-01 17:25:57.843449: precision @ 1 = 0.195
2018-02-01 17:26:45.844951: precision @ 1 = 0.195
2018-02-01 17:27:28.040569: precision @ 1 = 0.195
2018-02-01 17:28:15.563469: precision @ 1 = 0.195
2018-02-01 17:28:57.842879: precision @ 1 = 0.195
2018-02-01 17:29:45.146210: precision @ 1 = 0.195
2018-02-01 17:30:27.579482: precision @ 1 = 0.194
2018-02-01 17:31:15.180714: precision @ 1 = 0.195
2018-02-01 17:31:57.760678: precision @ 1 = 0.195
2018-02-01 17:32:45.988856: precision @ 1 = 0.195
2018-02-01 17:33:28.228235: precision @ 1 = 0.195
2018-02-01 17:34:16.362825: precision @ 1 = 0.194
2018-02-01 17:34:58.506329: precision @ 1 = 0.195
2018-02-01 17:35:37.944525: precision @ 1 = 0.194


LOSS (Train)


2018-02-01 16:29:21.198354: step 0, loss = 23.15 (1556.6 examples/sec; 0.082 sec/batch)
2018-02-01 16:29:22.774355: step 100, loss = 23.41 (8121.8 examples/sec; 0.016 sec/batch)
2018-02-01 16:29:24.249969: step 200, loss = 18.34 (8674.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:29:25.692566: step 300, loss = 16.04 (8872.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:29:27.183759: step 400, loss = 12.72 (8583.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:29:28.632434: step 500, loss = 11.05 (8835.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:29:30.257062: step 600, loss = 8.65 (7878.7 examples/sec; 0.016 sec/batch)
2018-02-01 16:29:31.907451: step 700, loss = 7.59 (7755.7 examples/sec; 0.017 sec/batch)
2018-02-01 16:29:33.449552: step 800, loss = 6.53 (8300.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:29:35.037777: step 900, loss = 5.80 (8059.3 examples/sec; 0.016 sec/batch)
2018-02-01 16:29:36.570854: step 1000, loss = 5.28 (8349.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:29:38.163088: step 1100, loss = 4.63 (8039.0 examples/sec; 0.016 sec/batch)
2018-02-01 16:29:39.669094: step 1200, loss = 4.29 (8499.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:29:41.165072: step 1300, loss = 3.86 (8556.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:29:43.159376: step 1400, loss = 3.60 (6418.3 examples/sec; 0.020 sec/batch)
2018-02-01 16:29:45.949798: step 1500, loss = 3.40 (4587.1 examples/sec; 0.028 sec/batch)
2018-02-01 16:29:48.799377: step 1600, loss = 3.18 (4491.9 examples/sec; 0.028 sec/batch)
2018-02-01 16:29:57.360144: step 1700, loss = 2.92 (1495.2 examples/sec; 0.086 sec/batch)
2018-02-01 16:29:58.882192: step 1800, loss = 2.86 (8409.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:00.386192: step 1900, loss = 2.67 (8510.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:01.879163: step 2000, loss = 2.66 (8573.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:03.387174: step 2100, loss = 2.55 (8488.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:04.878139: step 2200, loss = 2.43 (8585.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:06.392166: step 2300, loss = 2.50 (8454.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:07.926246: step 2400, loss = 2.42 (8343.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:09.426235: step 2500, loss = 2.39 (8533.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:11.114726: step 2600, loss = 2.41 (7580.7 examples/sec; 0.017 sec/batch)
2018-02-01 16:30:12.624742: step 2700, loss = 2.32 (8476.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:14.219984: step 2800, loss = 2.24 (8023.9 examples/sec; 0.016 sec/batch)
2018-02-01 16:30:15.814225: step 2900, loss = 2.26 (8028.9 examples/sec; 0.016 sec/batch)
2018-02-01 16:30:17.554854: step 3000, loss = 2.15 (7353.7 examples/sec; 0.017 sec/batch)
2018-02-01 16:30:19.271252: step 3100, loss = 2.25 (7457.5 examples/sec; 0.017 sec/batch)
2018-02-01 16:30:22.750839: step 3200, loss = 2.16 (3678.6 examples/sec; 0.035 sec/batch)
2018-02-01 16:30:24.343840: step 3300, loss = 2.22 (8035.1 examples/sec; 0.016 sec/batch)
2018-02-01 16:30:25.815826: step 3400, loss = 2.16 (8695.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:27.733277: step 3500, loss = 2.14 (6675.5 examples/sec; 0.019 sec/batch)
2018-02-01 16:30:30.508840: step 3600, loss = 2.27 (4611.7 examples/sec; 0.028 sec/batch)
2018-02-01 16:30:33.338267: step 3700, loss = 2.10 (4523.9 examples/sec; 0.028 sec/batch)
2018-02-01 16:30:36.017993: step 3800, loss = 2.21 (4776.6 examples/sec; 0.027 sec/batch)
2018-02-01 16:30:38.570943: step 3900, loss = 2.24 (5013.8 examples/sec; 0.026 sec/batch)
2018-02-01 16:30:41.395238: step 4000, loss = 2.18 (4532.1 examples/sec; 0.028 sec/batch)
2018-02-01 16:30:44.285113: step 4100, loss = 2.14 (4429.3 examples/sec; 0.029 sec/batch)
2018-02-01 16:30:45.848651: step 4200, loss = 2.15 (8186.6 examples/sec; 0.016 sec/batch)
2018-02-01 16:30:47.353957: step 4300, loss = 2.21 (8503.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:48.804919: step 4400, loss = 2.14 (8821.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:51.910871: step 4500, loss = 2.17 (4121.1 examples/sec; 0.031 sec/batch)
2018-02-01 16:30:53.433005: step 4600, loss = 2.16 (8409.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:55.135533: step 4700, loss = 2.27 (7518.2 examples/sec; 0.017 sec/batch)
2018-02-01 16:30:56.685275: step 4800, loss = 2.15 (8259.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:58.224806: step 4900, loss = 2.17 (8314.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:30:59.812769: step 5000, loss = 2.15 (8060.6 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:01.387147: step 5100, loss = 2.08 (8130.2 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:02.938357: step 5200, loss = 2.21 (8251.6 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:04.494998: step 5300, loss = 2.20 (8222.8 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:06.079906: step 5400, loss = 2.14 (8076.2 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:07.619096: step 5500, loss = 2.09 (8316.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:31:09.208803: step 5600, loss = 2.15 (8051.8 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:10.727650: step 5700, loss = 2.25 (8427.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:31:12.327959: step 5800, loss = 2.17 (7998.5 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:13.813206: step 5900, loss = 2.14 (8618.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:31:15.263675: step 6000, loss = 2.13 (8824.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:31:18.094779: step 6100, loss = 2.17 (4521.2 examples/sec; 0.028 sec/batch)
2018-02-01 16:31:28.236733: step 6200, loss = 2.19 (1262.1 examples/sec; 0.101 sec/batch)
2018-02-01 16:31:29.735518: step 6300, loss = 2.15 (8540.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:31:31.407966: step 6400, loss = 2.15 (7653.5 examples/sec; 0.017 sec/batch)
2018-02-01 16:31:32.970121: step 6500, loss = 2.13 (8193.8 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:34.540297: step 6600, loss = 2.19 (8152.0 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:35.994200: step 6700, loss = 2.12 (8803.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:31:37.496858: step 6800, loss = 2.14 (8518.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:31:39.099466: step 6900, loss = 2.13 (7987.0 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:40.660915: step 7000, loss = 2.25 (8197.5 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:42.210616: step 7100, loss = 2.16 (8259.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:31:43.734834: step 7200, loss = 2.11 (8397.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:31:45.364029: step 7300, loss = 2.20 (7856.6 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:47.027454: step 7400, loss = 2.09 (7695.0 examples/sec; 0.017 sec/batch)
2018-02-01 16:31:48.641542: step 7500, loss = 2.13 (7930.2 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:51.737259: step 7600, loss = 2.19 (4134.7 examples/sec; 0.031 sec/batch)
2018-02-01 16:31:53.290570: step 7700, loss = 2.15 (8240.5 examples/sec; 0.016 sec/batch)
2018-02-01 16:31:54.798322: step 7800, loss = 2.17 (8489.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:31:56.259954: step 7900, loss = 2.22 (8757.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:31:57.728945: step 8000, loss = 2.24 (8713.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:32:00.329705: step 8100, loss = 2.13 (4921.6 examples/sec; 0.026 sec/batch)
2018-02-01 16:32:02.951402: step 8200, loss = 2.12 (4882.3 examples/sec; 0.026 sec/batch)
2018-02-01 16:32:05.602402: step 8300, loss = 2.08 (4828.4 examples/sec; 0.027 sec/batch)
2018-02-01 16:32:08.664603: step 8400, loss = 2.11 (4180.0 examples/sec; 0.031 sec/batch)
2018-02-01 16:32:11.241005: step 8500, loss = 2.19 (4968.2 examples/sec; 0.026 sec/batch)
2018-02-01 16:32:13.910437: step 8600, loss = 2.18 (4795.0 examples/sec; 0.027 sec/batch)
2018-02-01 16:32:16.164063: step 8700, loss = 2.11 (5679.7 examples/sec; 0.023 sec/batch)
2018-02-01 16:32:17.618797: step 8800, loss = 2.20 (8798.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:32:19.043440: step 8900, loss = 2.17 (8984.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:32:22.103523: step 9000, loss = 2.15 (4182.9 examples/sec; 0.031 sec/batch)
2018-02-01 16:32:23.552806: step 9100, loss = 2.14 (8831.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:32:24.999849: step 9200, loss = 2.19 (8845.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:32:26.435629: step 9300, loss = 2.13 (8915.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:32:27.896713: step 9400, loss = 2.23 (8760.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:32:29.320564: step 9500, loss = 2.21 (8989.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:32:30.784852: step 9600, loss = 2.21 (8741.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:32:32.227393: step 9700, loss = 2.19 (8873.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:32:33.671409: step 9800, loss = 2.22 (8864.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:32:35.130895: step 9900, loss = 2.18 (8770.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:32:36.584440: step 10000, loss = 2.13 (8806.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:32:38.037262: step 10100, loss = 2.20 (8810.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:32:39.457418: step 10200, loss = 2.12 (9013.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:32:40.923086: step 10300, loss = 2.18 (8733.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:32:42.354186: step 10400, loss = 2.18 (8944.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:32:43.809866: step 10500, loss = 2.18 (8793.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:32:45.250900: step 10600, loss = 2.10 (8882.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:32:46.698141: step 10700, loss = 2.13 (8844.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:32:49.249707: step 10800, loss = 2.22 (5016.5 examples/sec; 0.026 sec/batch)
2018-02-01 16:32:59.446473: step 10900, loss = 2.24 (1255.3 examples/sec; 0.102 sec/batch)
2018-02-01 16:33:00.899291: step 11000, loss = 2.14 (8810.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:33:02.344897: step 11100, loss = 2.23 (8854.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:03.784479: step 11200, loss = 2.19 (8891.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:05.230256: step 11300, loss = 2.14 (8853.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:06.686246: step 11400, loss = 2.15 (8791.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:33:08.116664: step 11500, loss = 2.10 (8948.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:09.547271: step 11600, loss = 2.19 (8947.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:10.983316: step 11700, loss = 2.18 (8913.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:12.403212: step 11800, loss = 2.17 (9014.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:13.862354: step 11900, loss = 2.14 (8772.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:33:15.314604: step 12000, loss = 2.16 (8813.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:33:16.729555: step 12100, loss = 2.21 (9046.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:18.174344: step 12200, loss = 2.18 (8859.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:19.604333: step 12300, loss = 2.16 (8951.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:22.709555: step 12400, loss = 2.21 (4122.1 examples/sec; 0.031 sec/batch)
2018-02-01 16:33:24.151739: step 12500, loss = 2.16 (8875.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:25.592780: step 12600, loss = 2.21 (8882.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:27.046642: step 12700, loss = 2.11 (8804.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:33:28.615421: step 12800, loss = 2.21 (8159.2 examples/sec; 0.016 sec/batch)
2018-02-01 16:33:31.356746: step 12900, loss = 2.16 (4669.3 examples/sec; 0.027 sec/batch)
2018-02-01 16:33:33.888103: step 13000, loss = 2.10 (5056.6 examples/sec; 0.025 sec/batch)
2018-02-01 16:33:36.669491: step 13100, loss = 2.16 (4602.0 examples/sec; 0.028 sec/batch)
2018-02-01 16:33:39.443010: step 13200, loss = 2.15 (4615.1 examples/sec; 0.028 sec/batch)
2018-02-01 16:33:42.133286: step 13300, loss = 2.15 (4757.9 examples/sec; 0.027 sec/batch)
2018-02-01 16:33:44.869050: step 13400, loss = 2.17 (4678.8 examples/sec; 0.027 sec/batch)
2018-02-01 16:33:46.380067: step 13500, loss = 2.16 (8471.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:33:47.816091: step 13600, loss = 2.20 (8913.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:49.263672: step 13700, loss = 2.14 (8842.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:52.307477: step 13800, loss = 2.19 (4205.3 examples/sec; 0.030 sec/batch)
2018-02-01 16:33:53.753412: step 13900, loss = 2.12 (8852.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:55.188654: step 14000, loss = 2.14 (8918.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:56.633225: step 14100, loss = 2.17 (8860.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:33:58.096727: step 14200, loss = 2.12 (8746.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:33:59.528212: step 14300, loss = 2.18 (8941.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:00.983335: step 14400, loss = 2.15 (8796.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:34:02.434750: step 14500, loss = 2.13 (8819.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:34:03.869796: step 14600, loss = 2.08 (8919.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:05.317413: step 14700, loss = 2.23 (8842.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:06.773948: step 14800, loss = 2.15 (8788.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:34:08.211341: step 14900, loss = 2.23 (8905.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:09.653439: step 15000, loss = 2.11 (8876.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:11.063690: step 15100, loss = 2.08 (9076.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:12.476929: step 15200, loss = 2.11 (9057.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:13.915386: step 15300, loss = 2.18 (8898.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:15.345879: step 15400, loss = 2.16 (8948.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:17.742680: step 15500, loss = 2.09 (5340.5 examples/sec; 0.024 sec/batch)
2018-02-01 16:34:28.100829: step 15600, loss = 2.14 (1235.7 examples/sec; 0.104 sec/batch)
2018-02-01 16:34:29.531275: step 15700, loss = 2.10 (8948.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:30.988057: step 15800, loss = 2.12 (8786.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:34:32.415564: step 15900, loss = 2.23 (8966.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:33.851739: step 16000, loss = 2.20 (8912.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:35.301356: step 16100, loss = 2.14 (8829.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:36.734941: step 16200, loss = 2.15 (8928.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:38.171681: step 16300, loss = 2.09 (8909.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:39.618916: step 16400, loss = 2.17 (8844.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:41.056833: step 16500, loss = 2.13 (8901.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:42.520963: step 16600, loss = 2.13 (8742.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:34:43.954300: step 16700, loss = 2.12 (8930.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:45.372494: step 16800, loss = 2.13 (9025.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:46.791060: step 16900, loss = 2.15 (9023.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:48.243548: step 17000, loss = 2.12 (8812.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:34:51.260464: step 17100, loss = 2.14 (4242.7 examples/sec; 0.030 sec/batch)
2018-02-01 16:34:52.696048: step 17200, loss = 2.28 (8916.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:34:54.151213: step 17300, loss = 2.15 (8796.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:34:55.621961: step 17400, loss = 2.19 (8703.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:34:57.112816: step 17500, loss = 2.25 (8585.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:34:59.324449: step 17600, loss = 2.22 (5787.6 examples/sec; 0.022 sec/batch)
2018-02-01 16:35:02.095544: step 17700, loss = 2.15 (4619.1 examples/sec; 0.028 sec/batch)
2018-02-01 16:35:05.007732: step 17800, loss = 2.10 (4395.3 examples/sec; 0.029 sec/batch)
2018-02-01 16:35:07.862751: step 17900, loss = 2.14 (4483.3 examples/sec; 0.029 sec/batch)
2018-02-01 16:35:10.726893: step 18000, loss = 2.15 (4469.1 examples/sec; 0.029 sec/batch)
2018-02-01 16:35:13.378134: step 18100, loss = 2.13 (4827.9 examples/sec; 0.027 sec/batch)
2018-02-01 16:35:15.458902: step 18200, loss = 2.14 (6151.6 examples/sec; 0.021 sec/batch)
2018-02-01 16:35:16.925572: step 18300, loss = 2.19 (8727.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:35:18.356888: step 18400, loss = 2.10 (8942.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:35:21.434258: step 18500, loss = 2.20 (4159.4 examples/sec; 0.031 sec/batch)
2018-02-01 16:35:22.872739: step 18600, loss = 2.16 (8898.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:35:24.355028: step 18700, loss = 2.14 (8635.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:35:25.812129: step 18800, loss = 2.13 (8784.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:35:27.260936: step 18900, loss = 2.10 (8834.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:35:28.710182: step 19000, loss = 2.11 (8832.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:35:30.178867: step 19100, loss = 2.22 (8715.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:35:31.625299: step 19200, loss = 2.20 (8849.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:35:33.060753: step 19300, loss = 2.11 (8917.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:35:34.513559: step 19400, loss = 2.15 (8810.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:35:35.963914: step 19500, loss = 2.13 (8825.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:35:37.394971: step 19600, loss = 2.15 (8944.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:35:38.841931: step 19700, loss = 2.13 (8846.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:35:40.314472: step 19800, loss = 2.08 (8692.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:35:41.771753: step 19900, loss = 2.15 (8783.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:35:43.220569: step 20000, loss = 2.29 (8834.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:35:44.654668: step 20100, loss = 2.17 (8925.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:35:46.698215: step 20200, loss = 2.20 (6263.6 examples/sec; 0.020 sec/batch)
2018-02-01 16:35:49.144211: step 20300, loss = 2.19 (5233.0 examples/sec; 0.024 sec/batch)
2018-02-01 16:35:58.928173: step 20400, loss = 2.07 (1308.3 examples/sec; 0.098 sec/batch)
2018-02-01 16:36:00.383078: step 20500, loss = 2.15 (8797.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:01.833045: step 20600, loss = 2.02 (8827.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:36:03.285129: step 20700, loss = 2.22 (8814.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:04.731576: step 20800, loss = 2.18 (8849.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:36:06.183602: step 20900, loss = 2.15 (8815.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:07.629273: step 21000, loss = 2.17 (8854.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:36:09.082982: step 21100, loss = 2.17 (8805.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:10.545952: step 21200, loss = 2.13 (8749.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:12.008222: step 21300, loss = 2.13 (8753.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:13.439366: step 21400, loss = 2.14 (8943.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:36:14.880717: step 21500, loss = 2.15 (8880.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:36:16.321620: step 21600, loss = 2.06 (8883.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:36:17.758753: step 21700, loss = 2.12 (8906.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:36:19.213687: step 21800, loss = 2.12 (8797.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:22.249873: step 21900, loss = 2.11 (4215.8 examples/sec; 0.030 sec/batch)
2018-02-01 16:36:23.711585: step 22000, loss = 2.11 (8756.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:25.173201: step 22100, loss = 2.14 (8757.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:26.643554: step 22200, loss = 2.13 (8705.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:28.571549: step 22300, loss = 2.10 (6639.0 examples/sec; 0.019 sec/batch)
2018-02-01 16:36:31.248071: step 22400, loss = 2.18 (4782.3 examples/sec; 0.027 sec/batch)
2018-02-01 16:36:33.949081: step 22500, loss = 2.18 (4739.0 examples/sec; 0.027 sec/batch)
2018-02-01 16:36:36.595183: step 22600, loss = 2.11 (4837.3 examples/sec; 0.026 sec/batch)
2018-02-01 16:36:39.553436: step 22700, loss = 2.12 (4326.9 examples/sec; 0.030 sec/batch)
2018-02-01 16:36:42.314523: step 22800, loss = 2.29 (4635.9 examples/sec; 0.028 sec/batch)
2018-02-01 16:36:44.778036: step 22900, loss = 2.12 (5195.8 examples/sec; 0.025 sec/batch)
2018-02-01 16:36:46.262553: step 23000, loss = 2.25 (8622.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:47.904193: step 23100, loss = 2.12 (7797.1 examples/sec; 0.016 sec/batch)
2018-02-01 16:36:49.504610: step 23200, loss = 2.19 (7997.9 examples/sec; 0.016 sec/batch)
2018-02-01 16:36:52.655464: step 23300, loss = 2.19 (4062.4 examples/sec; 0.032 sec/batch)
2018-02-01 16:36:54.107166: step 23400, loss = 2.19 (8817.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:55.553969: step 23500, loss = 2.11 (8847.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:36:56.997782: step 23600, loss = 2.21 (8865.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:36:58.452659: step 23700, loss = 2.16 (8798.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:36:59.933153: step 23800, loss = 2.13 (8645.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:37:01.390230: step 23900, loss = 2.20 (8784.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:37:02.878925: step 24000, loss = 2.18 (8598.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:37:04.326909: step 24100, loss = 2.19 (8839.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:05.770226: step 24200, loss = 2.10 (8868.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:07.206276: step 24300, loss = 2.17 (8913.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:08.650597: step 24400, loss = 2.13 (8862.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:10.081133: step 24500, loss = 2.23 (8947.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:11.512850: step 24600, loss = 2.20 (8940.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:12.946894: step 24700, loss = 2.18 (8925.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:14.384441: step 24800, loss = 2.09 (8904.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:16.190586: step 24900, loss = 2.15 (7086.9 examples/sec; 0.018 sec/batch)
2018-02-01 16:37:18.961610: step 25000, loss = 2.14 (4619.2 examples/sec; 0.028 sec/batch)
2018-02-01 16:37:28.529041: step 25100, loss = 2.17 (1337.9 examples/sec; 0.096 sec/batch)
2018-02-01 16:37:29.963052: step 25200, loss = 2.21 (8926.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:31.405206: step 25300, loss = 2.19 (8875.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:32.840297: step 25400, loss = 2.11 (8919.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:34.249289: step 25500, loss = 2.19 (9084.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:35.700846: step 25600, loss = 2.18 (8818.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:37:37.142653: step 25700, loss = 2.14 (8877.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:38.585643: step 25800, loss = 2.18 (8870.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:40.039310: step 25900, loss = 2.17 (8805.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:37:41.480513: step 26000, loss = 2.18 (8881.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:42.939120: step 26100, loss = 2.12 (8775.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:37:44.366288: step 26200, loss = 2.09 (8968.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:45.810658: step 26300, loss = 2.24 (8862.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:47.222574: step 26400, loss = 2.19 (9065.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:48.679910: step 26500, loss = 2.21 (8783.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:37:51.715028: step 26600, loss = 2.19 (4217.3 examples/sec; 0.030 sec/batch)
2018-02-01 16:37:53.158458: step 26700, loss = 2.25 (8867.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:54.606713: step 26800, loss = 2.17 (8838.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:56.046565: step 26900, loss = 2.13 (8889.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:37:57.496480: step 27000, loss = 2.20 (8828.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:00.186414: step 27100, loss = 2.14 (4758.5 examples/sec; 0.027 sec/batch)
2018-02-01 16:38:02.780705: step 27200, loss = 2.24 (4933.9 examples/sec; 0.026 sec/batch)
2018-02-01 16:38:05.523745: step 27300, loss = 2.17 (4666.4 examples/sec; 0.027 sec/batch)
2018-02-01 16:38:08.084832: step 27400, loss = 2.13 (4997.9 examples/sec; 0.026 sec/batch)
2018-02-01 16:38:10.641067: step 27500, loss = 2.10 (5007.4 examples/sec; 0.026 sec/batch)
2018-02-01 16:38:13.235929: step 27600, loss = 2.15 (4932.8 examples/sec; 0.026 sec/batch)
2018-02-01 16:38:15.263957: step 27700, loss = 2.14 (6311.6 examples/sec; 0.020 sec/batch)
2018-02-01 16:38:16.697225: step 27800, loss = 2.17 (8930.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:18.139858: step 27900, loss = 2.18 (8872.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:19.569645: step 28000, loss = 2.12 (8952.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:22.565455: step 28100, loss = 2.11 (4272.6 examples/sec; 0.030 sec/batch)
2018-02-01 16:38:24.014183: step 28200, loss = 2.22 (8835.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:25.455175: step 28300, loss = 2.13 (8882.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:26.910940: step 28400, loss = 2.09 (8792.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:38:28.358973: step 28500, loss = 2.08 (8839.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:29.790598: step 28600, loss = 2.09 (8940.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:31.244127: step 28700, loss = 2.11 (8806.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:38:32.681955: step 28800, loss = 2.11 (8902.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:34.135287: step 28900, loss = 2.18 (8807.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:38:35.574929: step 29000, loss = 2.10 (8891.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:37.023878: step 29100, loss = 2.16 (8834.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:38.464670: step 29200, loss = 2.11 (8884.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:39.887370: step 29300, loss = 2.15 (8997.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:41.339143: step 29400, loss = 2.12 (8816.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:38:42.775981: step 29500, loss = 2.19 (8908.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:44.200057: step 29600, loss = 2.10 (8988.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:38:45.766914: step 29700, loss = 2.15 (8169.2 examples/sec; 0.016 sec/batch)
2018-02-01 16:38:48.458745: step 29800, loss = 2.09 (4755.1 examples/sec; 0.027 sec/batch)
2018-02-01 16:38:58.360798: step 29900, loss = 2.11 (1292.7 examples/sec; 0.099 sec/batch)
2018-02-01 16:38:59.832768: step 30000, loss = 2.10 (8695.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:39:01.261174: step 30100, loss = 2.16 (8961.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:02.704106: step 30200, loss = 2.23 (8870.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:04.137163: step 30300, loss = 2.19 (8932.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:05.562751: step 30400, loss = 2.17 (8978.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:07.006253: step 30500, loss = 2.17 (8867.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:08.430264: step 30600, loss = 2.16 (8988.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:09.862470: step 30700, loss = 2.20 (8937.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:11.301186: step 30800, loss = 2.14 (8896.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:12.742683: step 30900, loss = 2.11 (8879.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:14.159705: step 31000, loss = 2.11 (9033.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:15.605707: step 31100, loss = 2.11 (8852.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:17.056961: step 31200, loss = 2.10 (8820.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:39:18.508290: step 31300, loss = 2.16 (8819.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:39:21.474800: step 31400, loss = 2.04 (4314.8 examples/sec; 0.030 sec/batch)
2018-02-01 16:39:22.908358: step 31500, loss = 2.17 (8928.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:24.344718: step 31600, loss = 2.28 (8911.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:25.783692: step 31700, loss = 2.20 (8895.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:27.238145: step 31800, loss = 2.25 (8800.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:39:29.573907: step 31900, loss = 2.21 (5480.0 examples/sec; 0.023 sec/batch)
2018-02-01 16:39:32.428831: step 32000, loss = 2.17 (4483.5 examples/sec; 0.029 sec/batch)
2018-02-01 16:39:34.999627: step 32100, loss = 2.20 (4979.0 examples/sec; 0.026 sec/batch)
2018-02-01 16:39:37.777000: step 32200, loss = 2.13 (4608.7 examples/sec; 0.028 sec/batch)
2018-02-01 16:39:40.386353: step 32300, loss = 2.24 (4905.4 examples/sec; 0.026 sec/batch)
2018-02-01 16:39:43.029969: step 32400, loss = 2.20 (4841.9 examples/sec; 0.026 sec/batch)
2018-02-01 16:39:45.089934: step 32500, loss = 2.20 (6213.7 examples/sec; 0.021 sec/batch)
2018-02-01 16:39:46.536228: step 32600, loss = 2.14 (8850.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:47.972483: step 32700, loss = 2.24 (8912.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:49.374642: step 32800, loss = 2.18 (9128.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:52.413897: step 32900, loss = 2.15 (4211.6 examples/sec; 0.030 sec/batch)
2018-02-01 16:39:53.878628: step 33000, loss = 2.08 (8738.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:39:55.328168: step 33100, loss = 2.21 (8830.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:56.776750: step 33200, loss = 2.17 (8836.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:58.224690: step 33300, loss = 2.15 (8840.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:39:59.660342: step 33400, loss = 2.10 (8915.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:01.108407: step 33500, loss = 2.14 (8839.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:02.536811: step 33600, loss = 2.10 (8961.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:03.981703: step 33700, loss = 2.20 (8858.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:05.428779: step 33800, loss = 2.16 (8845.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:06.859309: step 33900, loss = 2.12 (8947.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:08.288749: step 34000, loss = 2.11 (8954.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:09.721448: step 34100, loss = 2.15 (8934.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:11.179046: step 34200, loss = 2.14 (8781.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:40:12.598660: step 34300, loss = 2.10 (9016.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:14.033884: step 34400, loss = 2.17 (8918.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:15.776928: step 34500, loss = 2.16 (7343.5 examples/sec; 0.017 sec/batch)
2018-02-01 16:40:18.420638: step 34600, loss = 2.15 (4841.7 examples/sec; 0.026 sec/batch)
2018-02-01 16:40:28.203673: step 34700, loss = 2.16 (1308.4 examples/sec; 0.098 sec/batch)
2018-02-01 16:40:29.675566: step 34800, loss = 2.19 (8696.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:40:31.104145: step 34900, loss = 2.12 (8960.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:32.544977: step 35000, loss = 2.19 (8883.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:33.969935: step 35100, loss = 2.18 (8982.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:35.393372: step 35200, loss = 2.13 (8992.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:36.837442: step 35300, loss = 2.14 (8863.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:38.260937: step 35400, loss = 2.09 (8992.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:39.683841: step 35500, loss = 2.10 (8995.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:41.124127: step 35600, loss = 2.20 (8887.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:42.563351: step 35700, loss = 2.21 (8893.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:44.017442: step 35800, loss = 2.17 (8802.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:40:45.456217: step 35900, loss = 2.21 (8896.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:46.878767: step 36000, loss = 2.13 (8997.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:48.307425: step 36100, loss = 2.18 (8959.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:49.737436: step 36200, loss = 2.21 (8951.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:52.724384: step 36300, loss = 2.15 (4285.3 examples/sec; 0.030 sec/batch)
2018-02-01 16:40:54.170547: step 36400, loss = 2.25 (8851.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:55.615361: step 36500, loss = 2.11 (8859.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:40:57.069477: step 36600, loss = 2.18 (8802.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:40:59.228224: step 36700, loss = 2.10 (5929.4 examples/sec; 0.022 sec/batch)
2018-02-01 16:41:01.743955: step 36800, loss = 2.21 (5088.0 examples/sec; 0.025 sec/batch)
2018-02-01 16:41:04.601193: step 36900, loss = 2.14 (4479.9 examples/sec; 0.029 sec/batch)
2018-02-01 16:41:07.204393: step 37000, loss = 2.19 (4917.0 examples/sec; 0.026 sec/batch)
2018-02-01 16:41:09.722745: step 37100, loss = 2.12 (5082.7 examples/sec; 0.025 sec/batch)
2018-02-01 16:41:12.164307: step 37200, loss = 2.18 (5242.5 examples/sec; 0.024 sec/batch)
2018-02-01 16:41:14.777389: step 37300, loss = 2.12 (4898.4 examples/sec; 0.026 sec/batch)
2018-02-01 16:41:16.425891: step 37400, loss = 2.12 (7764.6 examples/sec; 0.016 sec/batch)
2018-02-01 16:41:17.860240: step 37500, loss = 2.08 (8923.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:19.297565: step 37600, loss = 2.08 (8905.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:22.300898: step 37700, loss = 2.15 (4261.9 examples/sec; 0.030 sec/batch)
2018-02-01 16:41:23.736780: step 37800, loss = 2.19 (8914.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:25.176685: step 37900, loss = 2.11 (8889.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:26.615248: step 38000, loss = 2.14 (8897.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:28.058378: step 38100, loss = 2.12 (8869.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:29.477396: step 38200, loss = 2.11 (9020.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:30.896169: step 38300, loss = 2.18 (9021.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:32.331669: step 38400, loss = 2.16 (8916.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:33.762308: step 38500, loss = 2.19 (8947.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:35.212763: step 38600, loss = 2.16 (8824.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:41:36.652641: step 38700, loss = 2.13 (8889.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:38.107393: step 38800, loss = 2.20 (8798.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:41:39.551227: step 38900, loss = 2.07 (8865.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:40.986016: step 39000, loss = 2.18 (8921.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:42.435016: step 39100, loss = 2.16 (8833.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:41:43.897476: step 39200, loss = 2.16 (8752.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:41:45.350082: step 39300, loss = 2.11 (8811.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:41:47.365284: step 39400, loss = 2.27 (6351.7 examples/sec; 0.020 sec/batch)
2018-02-01 16:41:57.985631: step 39500, loss = 2.21 (1205.2 examples/sec; 0.106 sec/batch)
2018-02-01 16:41:59.441517: step 39600, loss = 2.25 (8791.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:42:00.875574: step 39700, loss = 2.08 (8925.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:02.316359: step 39800, loss = 2.14 (8884.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:03.749275: step 39900, loss = 2.11 (8932.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:05.183507: step 40000, loss = 2.19 (8924.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:06.628648: step 40100, loss = 2.14 (8857.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:08.065174: step 40200, loss = 2.17 (8910.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:09.491250: step 40300, loss = 2.18 (8975.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:10.926430: step 40400, loss = 2.17 (8918.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:12.364211: step 40500, loss = 2.05 (8902.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:13.811874: step 40600, loss = 2.17 (8841.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:15.236084: step 40700, loss = 2.14 (8987.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:16.669627: step 40800, loss = 2.18 (8928.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:18.118264: step 40900, loss = 2.13 (8835.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:19.576957: step 41000, loss = 2.20 (8775.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:42:22.625314: step 41100, loss = 2.15 (4199.0 examples/sec; 0.030 sec/batch)
2018-02-01 16:42:24.065997: step 41200, loss = 2.19 (8884.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:25.494871: step 41300, loss = 2.12 (8958.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:26.914110: step 41400, loss = 2.17 (9018.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:28.877305: step 41500, loss = 2.14 (6520.0 examples/sec; 0.020 sec/batch)
2018-02-01 16:42:31.670215: step 41600, loss = 2.13 (4583.0 examples/sec; 0.028 sec/batch)
2018-02-01 16:42:34.196545: step 41700, loss = 2.12 (5066.6 examples/sec; 0.025 sec/batch)
2018-02-01 16:42:37.096115: step 41800, loss = 2.15 (4414.4 examples/sec; 0.029 sec/batch)
2018-02-01 16:42:39.670580: step 41900, loss = 2.17 (4971.9 examples/sec; 0.026 sec/batch)
2018-02-01 16:42:42.227095: step 42000, loss = 2.11 (5006.8 examples/sec; 0.026 sec/batch)
2018-02-01 16:42:44.742784: step 42100, loss = 2.07 (5088.1 examples/sec; 0.025 sec/batch)
2018-02-01 16:42:46.169813: step 42200, loss = 2.11 (8969.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:47.599737: step 42300, loss = 2.11 (8951.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:49.037376: step 42400, loss = 2.18 (8903.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:52.036494: step 42500, loss = 2.15 (4267.9 examples/sec; 0.030 sec/batch)
2018-02-01 16:42:53.473527: step 42600, loss = 2.09 (8907.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:54.910929: step 42700, loss = 2.18 (8905.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:56.346720: step 42800, loss = 2.03 (8914.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:57.787963: step 42900, loss = 2.15 (8881.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:42:59.216602: step 43000, loss = 2.24 (8959.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:00.654510: step 43100, loss = 2.18 (8901.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:02.121804: step 43200, loss = 2.14 (8723.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:43:03.539433: step 43300, loss = 2.18 (9029.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:04.955355: step 43400, loss = 2.15 (9040.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:06.405346: step 43500, loss = 2.09 (8923.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:07.817051: step 43600, loss = 2.22 (8967.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:09.247842: step 43700, loss = 2.23 (8946.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:10.699413: step 43800, loss = 2.23 (8818.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:43:12.117894: step 43900, loss = 2.20 (9023.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:13.567352: step 44000, loss = 2.19 (8830.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:15.009658: step 44100, loss = 2.20 (8874.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:17.487791: step 44200, loss = 2.15 (5165.2 examples/sec; 0.025 sec/batch)
2018-02-01 16:43:27.726246: step 44300, loss = 2.11 (1250.2 examples/sec; 0.102 sec/batch)
2018-02-01 16:43:29.177586: step 44400, loss = 2.10 (8819.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:43:30.619933: step 44500, loss = 2.19 (8874.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:32.054619: step 44600, loss = 2.11 (8921.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:33.473143: step 44700, loss = 2.17 (9023.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:34.932494: step 44800, loss = 2.16 (8771.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:43:36.352029: step 44900, loss = 2.16 (9017.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:37.778444: step 45000, loss = 2.09 (8973.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:39.239662: step 45100, loss = 2.13 (8759.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:43:40.674500: step 45200, loss = 2.17 (8920.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:42.112587: step 45300, loss = 2.29 (8900.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:43.535727: step 45400, loss = 2.12 (8994.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:44.973561: step 45500, loss = 2.22 (8902.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:46.394876: step 45600, loss = 2.16 (9005.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:47.822777: step 45700, loss = 2.16 (8964.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:49.258064: step 45800, loss = 2.13 (8918.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:52.228839: step 45900, loss = 2.13 (4308.6 examples/sec; 0.030 sec/batch)
2018-02-01 16:43:53.725782: step 46000, loss = 2.24 (8550.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:43:55.166397: step 46100, loss = 2.18 (8885.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:56.598319: step 46200, loss = 2.26 (8939.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:43:58.605938: step 46300, loss = 2.09 (6375.7 examples/sec; 0.020 sec/batch)
2018-02-01 16:44:01.305290: step 46400, loss = 2.20 (4741.9 examples/sec; 0.027 sec/batch)
2018-02-01 16:44:03.868345: step 46500, loss = 2.04 (4994.0 examples/sec; 0.026 sec/batch)
2018-02-01 16:44:06.337574: step 46600, loss = 2.15 (5183.8 examples/sec; 0.025 sec/batch)
2018-02-01 16:44:08.903116: step 46700, loss = 2.20 (4989.2 examples/sec; 0.026 sec/batch)
2018-02-01 16:44:11.500294: step 46800, loss = 2.19 (4928.4 examples/sec; 0.026 sec/batch)
2018-02-01 16:44:14.428656: step 46900, loss = 2.15 (4371.0 examples/sec; 0.029 sec/batch)
2018-02-01 16:44:15.893570: step 47000, loss = 2.15 (8737.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:44:17.355323: step 47100, loss = 2.17 (8756.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:44:18.799394: step 47200, loss = 2.12 (8863.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:44:21.817501: step 47300, loss = 2.10 (4241.1 examples/sec; 0.030 sec/batch)
2018-02-01 16:44:23.239493: step 47400, loss = 2.13 (9001.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:44:24.683376: step 47500, loss = 2.19 (8865.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:44:26.096645: step 47600, loss = 2.10 (9057.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:44:27.544810: step 47700, loss = 2.10 (8838.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:44:28.970748: step 47800, loss = 2.15 (8976.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:44:30.421533: step 47900, loss = 2.18 (8822.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:44:31.854418: step 48000, loss = 2.19 (8933.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:44:33.310501: step 48100, loss = 2.21 (8790.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:44:34.775246: step 48200, loss = 2.14 (8738.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:44:36.198921: step 48300, loss = 2.17 (8990.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:44:37.656305: step 48400, loss = 2.12 (8782.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:44:39.089403: step 48500, loss = 2.13 (8931.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:44:40.540954: step 48600, loss = 2.18 (8818.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:44:41.965021: step 48700, loss = 2.19 (8988.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:44:43.390546: step 48800, loss = 2.17 (8979.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:44:44.875062: step 48900, loss = 2.19 (8622.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:44:47.487880: step 49000, loss = 2.15 (4898.9 examples/sec; 0.026 sec/batch)
2018-02-01 16:44:49.952240: step 49100, loss = 2.19 (5194.0 examples/sec; 0.025 sec/batch)
2018-02-01 16:44:58.871108: step 49200, loss = 2.12 (1435.2 examples/sec; 0.089 sec/batch)
2018-02-01 16:45:00.329612: step 49300, loss = 2.11 (8776.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:45:01.770146: step 49400, loss = 2.25 (8885.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:03.185170: step 49500, loss = 2.13 (9045.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:04.634964: step 49600, loss = 2.15 (8828.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:06.057896: step 49700, loss = 2.18 (8995.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:07.488544: step 49800, loss = 2.11 (8947.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:08.939145: step 49900, loss = 2.12 (8823.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:45:10.362603: step 50000, loss = 2.16 (8992.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:11.793285: step 50100, loss = 2.13 (8946.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:13.213680: step 50200, loss = 2.21 (9011.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:14.634209: step 50300, loss = 2.13 (9010.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:16.070564: step 50400, loss = 2.13 (8911.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:17.502377: step 50500, loss = 2.19 (8939.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:18.958320: step 50600, loss = 2.16 (8791.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:45:22.015213: step 50700, loss = 2.19 (4187.3 examples/sec; 0.031 sec/batch)
2018-02-01 16:45:23.462048: step 50800, loss = 2.09 (8846.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:24.934026: step 50900, loss = 2.27 (8695.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:45:26.361037: step 51000, loss = 2.14 (8969.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:28.071598: step 51100, loss = 2.15 (7482.9 examples/sec; 0.017 sec/batch)
2018-02-01 16:45:30.751642: step 51200, loss = 2.14 (4776.0 examples/sec; 0.027 sec/batch)
2018-02-01 16:45:33.572505: step 51300, loss = 2.20 (4537.6 examples/sec; 0.028 sec/batch)
2018-02-01 16:45:36.453376: step 51400, loss = 2.18 (4443.1 examples/sec; 0.029 sec/batch)
2018-02-01 16:45:39.073092: step 51500, loss = 2.06 (4886.0 examples/sec; 0.026 sec/batch)
2018-02-01 16:45:41.718073: step 51600, loss = 2.24 (4839.4 examples/sec; 0.026 sec/batch)
2018-02-01 16:45:44.168532: step 51700, loss = 2.21 (5223.5 examples/sec; 0.025 sec/batch)
2018-02-01 16:45:45.597414: step 51800, loss = 2.02 (8958.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:47.032313: step 51900, loss = 2.17 (8920.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:48.460106: step 52000, loss = 2.09 (8964.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:49.911232: step 52100, loss = 2.17 (8820.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:45:52.866790: step 52200, loss = 2.25 (4330.8 examples/sec; 0.030 sec/batch)
2018-02-01 16:45:54.287762: step 52300, loss = 2.15 (9007.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:55.700861: step 52400, loss = 2.20 (9058.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:45:57.164400: step 52500, loss = 2.16 (8745.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:45:58.661000: step 52600, loss = 2.22 (8552.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:00.175053: step 52700, loss = 2.18 (8454.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:01.620787: step 52800, loss = 2.07 (8853.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:46:03.130838: step 52900, loss = 2.10 (8476.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:04.603446: step 53000, loss = 2.18 (8692.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:06.089412: step 53100, loss = 2.14 (8613.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:07.645770: step 53200, loss = 2.20 (8224.3 examples/sec; 0.016 sec/batch)
2018-02-01 16:46:09.168925: step 53300, loss = 2.21 (8403.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:10.703577: step 53400, loss = 2.08 (8340.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:12.216535: step 53500, loss = 2.14 (8460.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:13.780365: step 53600, loss = 2.28 (8185.0 examples/sec; 0.016 sec/batch)
2018-02-01 16:46:15.542800: step 53700, loss = 2.15 (7262.7 examples/sec; 0.018 sec/batch)
2018-02-01 16:46:18.107309: step 53800, loss = 2.11 (4991.2 examples/sec; 0.026 sec/batch)
2018-02-01 16:46:28.001022: step 53900, loss = 2.11 (1293.8 examples/sec; 0.099 sec/batch)
2018-02-01 16:46:29.459203: step 54000, loss = 2.18 (8778.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:30.908457: step 54100, loss = 2.12 (8832.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:46:32.362612: step 54200, loss = 2.19 (8802.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:33.812091: step 54300, loss = 2.09 (8830.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:46:35.270894: step 54400, loss = 2.23 (8774.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:36.724256: step 54500, loss = 2.18 (8807.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:38.163267: step 54600, loss = 2.05 (8895.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:46:39.604869: step 54700, loss = 2.07 (8879.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:46:41.087054: step 54800, loss = 2.16 (8635.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:42.538996: step 54900, loss = 2.16 (8815.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:43.999396: step 55000, loss = 2.10 (8764.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:45.441529: step 55100, loss = 2.14 (8875.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:46:46.870068: step 55200, loss = 2.18 (8960.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:46:48.347008: step 55300, loss = 2.11 (8666.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:49.798552: step 55400, loss = 2.14 (8818.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:52.895201: step 55500, loss = 2.17 (4133.5 examples/sec; 0.031 sec/batch)
2018-02-01 16:46:54.338514: step 55600, loss = 2.03 (8868.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:46:55.792941: step 55700, loss = 2.12 (8800.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:57.265684: step 55800, loss = 2.25 (8691.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:46:59.710722: step 55900, loss = 2.17 (5235.1 examples/sec; 0.024 sec/batch)
2018-02-01 16:47:02.266232: step 56000, loss = 2.17 (5008.8 examples/sec; 0.026 sec/batch)
2018-02-01 16:47:05.094242: step 56100, loss = 2.14 (4526.2 examples/sec; 0.028 sec/batch)
2018-02-01 16:47:07.727858: step 56200, loss = 2.15 (4860.2 examples/sec; 0.026 sec/batch)
2018-02-01 16:47:10.258660: step 56300, loss = 2.18 (5057.7 examples/sec; 0.025 sec/batch)
2018-02-01 16:47:12.939958: step 56400, loss = 2.22 (4773.8 examples/sec; 0.027 sec/batch)
2018-02-01 16:47:15.138652: step 56500, loss = 2.09 (5821.6 examples/sec; 0.022 sec/batch)
2018-02-01 16:47:16.570745: step 56600, loss = 2.15 (8938.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:47:18.016822: step 56700, loss = 2.25 (8851.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:47:19.476590: step 56800, loss = 2.14 (8768.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:47:22.492540: step 56900, loss = 2.12 (4244.1 examples/sec; 0.030 sec/batch)
2018-02-01 16:47:23.961612: step 57000, loss = 2.13 (8713.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:47:25.427181: step 57100, loss = 2.12 (8733.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:47:26.885840: step 57200, loss = 2.17 (8775.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:47:28.335124: step 57300, loss = 2.17 (8831.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:47:29.790005: step 57400, loss = 2.19 (8798.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:47:31.240292: step 57500, loss = 2.13 (8825.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:47:32.693385: step 57600, loss = 2.20 (8808.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:47:34.152239: step 57700, loss = 2.17 (8774.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:47:35.629001: step 57800, loss = 2.17 (8667.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:47:37.110228: step 57900, loss = 2.17 (8641.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:47:38.537204: step 58000, loss = 2.07 (8970.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:47:40.008146: step 58100, loss = 2.19 (8701.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:47:41.445155: step 58200, loss = 2.18 (8907.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:47:42.882035: step 58300, loss = 2.16 (8908.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:47:44.333960: step 58400, loss = 2.07 (8815.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:47:46.398099: step 58500, loss = 2.12 (6201.1 examples/sec; 0.021 sec/batch)
2018-02-01 16:47:49.180164: step 58600, loss = 2.13 (4600.9 examples/sec; 0.028 sec/batch)
2018-02-01 16:47:58.643312: step 58700, loss = 2.11 (1352.6 examples/sec; 0.095 sec/batch)
2018-02-01 16:48:00.090832: step 58800, loss = 2.14 (8842.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:48:01.554532: step 58900, loss = 2.16 (8745.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:03.012800: step 59000, loss = 2.14 (8777.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:04.479482: step 59100, loss = 2.15 (8727.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:05.923417: step 59200, loss = 2.15 (8864.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:48:07.376612: step 59300, loss = 2.24 (8808.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:08.816667: step 59400, loss = 2.14 (8888.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:48:10.262455: step 59500, loss = 2.09 (8853.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:48:11.722188: step 59600, loss = 2.12 (8768.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:13.135684: step 59700, loss = 2.14 (9055.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:48:14.599456: step 59800, loss = 2.14 (8744.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:16.054301: step 59900, loss = 2.13 (8798.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:17.520032: step 60000, loss = 2.14 (8732.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:18.993760: step 60100, loss = 2.16 (8685.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:22.018889: step 60200, loss = 2.14 (4231.2 examples/sec; 0.030 sec/batch)
2018-02-01 16:48:23.478443: step 60300, loss = 2.20 (8769.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:24.920407: step 60400, loss = 2.09 (8876.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:48:26.372055: step 60500, loss = 2.13 (8817.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:27.854536: step 60600, loss = 2.18 (8634.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:30.700883: step 60700, loss = 2.16 (4497.0 examples/sec; 0.028 sec/batch)
2018-02-01 16:48:33.141615: step 60800, loss = 2.14 (5244.3 examples/sec; 0.024 sec/batch)
2018-02-01 16:48:35.655324: step 60900, loss = 2.11 (5092.1 examples/sec; 0.025 sec/batch)
2018-02-01 16:48:38.507120: step 61000, loss = 2.16 (4488.4 examples/sec; 0.029 sec/batch)
2018-02-01 16:48:41.148269: step 61100, loss = 2.08 (4846.4 examples/sec; 0.026 sec/batch)
2018-02-01 16:48:43.853601: step 61200, loss = 2.12 (4731.4 examples/sec; 0.027 sec/batch)
2018-02-01 16:48:45.643435: step 61300, loss = 2.12 (7151.5 examples/sec; 0.018 sec/batch)
2018-02-01 16:48:47.110672: step 61400, loss = 2.18 (8723.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:48.569915: step 61500, loss = 2.22 (8771.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:50.028753: step 61600, loss = 2.11 (8774.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:53.039276: step 61700, loss = 2.13 (4251.8 examples/sec; 0.030 sec/batch)
2018-02-01 16:48:54.498322: step 61800, loss = 2.11 (8772.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:55.959697: step 61900, loss = 2.24 (8758.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:57.411554: step 62000, loss = 2.16 (8816.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:48:58.864224: step 62100, loss = 2.20 (8811.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:49:00.364363: step 62200, loss = 2.15 (8532.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:49:01.885728: step 62300, loss = 2.10 (8413.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:49:03.344259: step 62400, loss = 2.14 (8776.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:49:04.784416: step 62500, loss = 2.10 (8887.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:49:06.243568: step 62600, loss = 2.23 (8772.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:49:07.692090: step 62700, loss = 2.15 (8836.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:49:09.150053: step 62800, loss = 2.11 (8779.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:49:10.587780: step 62900, loss = 2.14 (8902.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:49:12.045142: step 63000, loss = 2.09 (8783.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:49:13.470123: step 63100, loss = 2.16 (8982.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:49:14.938177: step 63200, loss = 2.21 (8719.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:49:17.219117: step 63300, loss = 2.07 (5611.7 examples/sec; 0.023 sec/batch)
2018-02-01 16:49:19.884219: step 63400, loss = 2.10 (4802.8 examples/sec; 0.027 sec/batch)
2018-02-01 16:49:30.118220: step 63500, loss = 2.07 (1250.7 examples/sec; 0.102 sec/batch)
2018-02-01 16:49:31.737019: step 63600, loss = 2.16 (7907.1 examples/sec; 0.016 sec/batch)
2018-02-01 16:49:33.626043: step 63700, loss = 2.15 (6776.0 examples/sec; 0.019 sec/batch)
2018-02-01 16:49:35.143276: step 63800, loss = 2.13 (8436.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:49:36.630564: step 63900, loss = 2.10 (8606.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:49:38.375289: step 64000, loss = 2.18 (7336.4 examples/sec; 0.017 sec/batch)
2018-02-01 16:49:40.154020: step 64100, loss = 2.16 (7196.1 examples/sec; 0.018 sec/batch)
2018-02-01 16:49:41.860558: step 64200, loss = 2.03 (7500.6 examples/sec; 0.017 sec/batch)
2018-02-01 16:49:43.568100: step 64300, loss = 2.10 (7496.2 examples/sec; 0.017 sec/batch)
2018-02-01 16:49:45.343973: step 64400, loss = 2.22 (7207.7 examples/sec; 0.018 sec/batch)
2018-02-01 16:49:47.380446: step 64500, loss = 2.18 (6285.4 examples/sec; 0.020 sec/batch)
2018-02-01 16:49:49.327415: step 64600, loss = 2.02 (6574.3 examples/sec; 0.019 sec/batch)
2018-02-01 16:49:53.304171: step 64700, loss = 2.28 (3218.7 examples/sec; 0.040 sec/batch)
2018-02-01 16:49:54.811940: step 64800, loss = 2.16 (8489.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:49:56.451445: step 64900, loss = 2.16 (7807.2 examples/sec; 0.016 sec/batch)
2018-02-01 16:49:58.048061: step 65000, loss = 2.12 (8017.0 examples/sec; 0.016 sec/batch)
2018-02-01 16:50:00.544712: step 65100, loss = 2.10 (5126.9 examples/sec; 0.025 sec/batch)
2018-02-01 16:50:03.484845: step 65200, loss = 2.07 (4353.5 examples/sec; 0.029 sec/batch)
2018-02-01 16:50:06.722231: step 65300, loss = 2.16 (3953.8 examples/sec; 0.032 sec/batch)
2018-02-01 16:50:09.848020: step 65400, loss = 2.19 (4095.0 examples/sec; 0.031 sec/batch)
2018-02-01 16:50:12.934658: step 65500, loss = 2.20 (4146.9 examples/sec; 0.031 sec/batch)
2018-02-01 16:50:15.574679: step 65600, loss = 2.17 (4848.4 examples/sec; 0.026 sec/batch)
2018-02-01 16:50:19.121575: step 65700, loss = 2.11 (3608.8 examples/sec; 0.035 sec/batch)
2018-02-01 16:50:22.686984: step 65800, loss = 2.21 (3590.1 examples/sec; 0.036 sec/batch)
2018-02-01 16:50:24.522209: step 65900, loss = 2.05 (6974.6 examples/sec; 0.018 sec/batch)
2018-02-01 16:50:26.349299: step 66000, loss = 2.20 (7005.7 examples/sec; 0.018 sec/batch)
2018-02-01 16:50:27.899262: step 66100, loss = 2.10 (8258.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:50:29.445474: step 66200, loss = 2.08 (8278.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:50:31.808992: step 66300, loss = 2.19 (5415.7 examples/sec; 0.024 sec/batch)
2018-02-01 16:50:35.385797: step 66400, loss = 2.11 (3578.6 examples/sec; 0.036 sec/batch)
2018-02-01 16:50:37.119501: step 66500, loss = 2.15 (7383.0 examples/sec; 0.017 sec/batch)
2018-02-01 16:50:41.261894: step 66600, loss = 2.15 (3090.0 examples/sec; 0.041 sec/batch)
2018-02-01 16:50:44.671746: step 66700, loss = 2.11 (3753.8 examples/sec; 0.034 sec/batch)
2018-02-01 16:50:48.759797: step 66800, loss = 2.21 (3131.1 examples/sec; 0.041 sec/batch)
2018-02-01 16:51:08.746008: step 66900, loss = 2.20 (640.4 examples/sec; 0.200 sec/batch)
2018-02-01 16:51:13.764897: step 67000, loss = 2.22 (2550.4 examples/sec; 0.050 sec/batch)
2018-02-01 16:51:16.336310: step 67100, loss = 2.16 (4977.8 examples/sec; 0.026 sec/batch)
2018-02-01 16:51:20.026850: step 67200, loss = 2.15 (3468.3 examples/sec; 0.037 sec/batch)
2018-02-01 16:51:29.696186: step 67300, loss = 2.15 (1323.8 examples/sec; 0.097 sec/batch)
2018-02-01 16:51:32.759094: step 67400, loss = 2.12 (4179.0 examples/sec; 0.031 sec/batch)
2018-02-01 16:51:35.644558: step 67500, loss = 2.11 (4436.0 examples/sec; 0.029 sec/batch)
2018-02-01 16:51:38.242031: step 67600, loss = 2.14 (4929.8 examples/sec; 0.026 sec/batch)
2018-02-01 16:51:41.032471: step 67700, loss = 2.14 (4585.4 examples/sec; 0.028 sec/batch)
2018-02-01 16:51:44.383002: step 67800, loss = 2.14 (3820.3 examples/sec; 0.034 sec/batch)
2018-02-01 16:51:46.960976: step 67900, loss = 2.16 (4965.1 examples/sec; 0.026 sec/batch)
2018-02-01 16:52:01.372931: step 68000, loss = 2.24 (888.2 examples/sec; 0.144 sec/batch)
2018-02-01 16:52:06.955298: step 68100, loss = 2.20 (2292.9 examples/sec; 0.056 sec/batch)
2018-02-01 16:52:13.586767: step 68200, loss = 2.20 (1930.2 examples/sec; 0.066 sec/batch)
2018-02-01 16:52:19.811056: step 68300, loss = 2.12 (2056.5 examples/sec; 0.062 sec/batch)
2018-02-01 16:52:33.690930: step 68400, loss = 2.16 (922.2 examples/sec; 0.139 sec/batch)
2018-02-01 16:52:37.308836: step 68500, loss = 2.26 (3538.0 examples/sec; 0.036 sec/batch)
2018-02-01 16:52:42.255354: step 68600, loss = 2.13 (2587.7 examples/sec; 0.049 sec/batch)
2018-02-01 16:52:45.742445: step 68700, loss = 2.16 (3670.7 examples/sec; 0.035 sec/batch)
2018-02-01 16:52:50.027741: step 68800, loss = 2.14 (2987.0 examples/sec; 0.043 sec/batch)
2018-02-01 16:53:00.716603: step 68900, loss = 2.20 (1197.5 examples/sec; 0.107 sec/batch)
2018-02-01 16:53:04.007731: step 69000, loss = 2.21 (3889.2 examples/sec; 0.033 sec/batch)
2018-02-01 16:53:07.593307: step 69100, loss = 2.08 (3569.9 examples/sec; 0.036 sec/batch)
2018-02-01 16:53:10.909874: step 69200, loss = 2.14 (3859.4 examples/sec; 0.033 sec/batch)
2018-02-01 16:53:14.587140: step 69300, loss = 2.10 (3480.8 examples/sec; 0.037 sec/batch)
2018-02-01 16:53:18.165766: step 69400, loss = 2.10 (3576.8 examples/sec; 0.036 sec/batch)
2018-02-01 16:53:30.311966: step 69500, loss = 2.12 (1053.8 examples/sec; 0.121 sec/batch)
2018-02-01 16:53:34.419947: step 69600, loss = 2.15 (3115.9 examples/sec; 0.041 sec/batch)
2018-02-01 16:53:38.425764: step 69700, loss = 2.10 (3195.4 examples/sec; 0.040 sec/batch)
2018-02-01 16:53:42.736044: step 69800, loss = 2.17 (2969.6 examples/sec; 0.043 sec/batch)
2018-02-01 16:53:47.035408: step 69900, loss = 2.13 (2977.2 examples/sec; 0.043 sec/batch)
2018-02-01 16:54:04.245090: step 70000, loss = 2.20 (743.8 examples/sec; 0.172 sec/batch)
2018-02-01 16:54:08.795164: step 70100, loss = 2.13 (2813.1 examples/sec; 0.046 sec/batch)
2018-02-01 16:54:12.803232: step 70200, loss = 2.13 (3193.6 examples/sec; 0.040 sec/batch)
2018-02-01 16:54:18.196261: step 70300, loss = 2.12 (2373.4 examples/sec; 0.054 sec/batch)
2018-02-01 16:54:27.609954: step 70400, loss = 2.15 (1359.7 examples/sec; 0.094 sec/batch)
2018-02-01 16:54:30.002315: step 70500, loss = 2.16 (5350.4 examples/sec; 0.024 sec/batch)
2018-02-01 16:54:34.562697: step 70600, loss = 2.18 (2806.8 examples/sec; 0.046 sec/batch)
2018-02-01 16:54:37.026506: step 70700, loss = 2.10 (5195.2 examples/sec; 0.025 sec/batch)
2018-02-01 16:54:39.302115: step 70800, loss = 2.18 (5624.9 examples/sec; 0.023 sec/batch)
2018-02-01 16:54:41.876564: step 70900, loss = 2.08 (4971.9 examples/sec; 0.026 sec/batch)
2018-02-01 16:54:46.826813: step 71000, loss = 2.16 (2585.7 examples/sec; 0.050 sec/batch)
2018-02-01 16:54:57.414950: step 71100, loss = 2.06 (1208.9 examples/sec; 0.106 sec/batch)
2018-02-01 16:55:02.683775: step 71200, loss = 2.10 (2429.4 examples/sec; 0.053 sec/batch)
2018-02-01 16:55:05.865261: step 71300, loss = 2.21 (4023.3 examples/sec; 0.032 sec/batch)
2018-02-01 16:55:10.032320: step 71400, loss = 2.12 (3071.7 examples/sec; 0.042 sec/batch)
2018-02-01 16:55:14.702740: step 71500, loss = 2.21 (2740.7 examples/sec; 0.047 sec/batch)
2018-02-01 16:55:17.738815: step 71600, loss = 2.11 (4216.0 examples/sec; 0.030 sec/batch)
2018-02-01 16:55:20.209565: step 71700, loss = 2.08 (5180.6 examples/sec; 0.025 sec/batch)
2018-02-01 16:55:23.513701: step 71800, loss = 2.13 (3873.9 examples/sec; 0.033 sec/batch)
2018-02-01 16:55:25.142647: step 71900, loss = 2.22 (7857.8 examples/sec; 0.016 sec/batch)
2018-02-01 16:55:26.713470: step 72000, loss = 2.15 (8148.6 examples/sec; 0.016 sec/batch)
2018-02-01 16:55:28.298646: step 72100, loss = 2.14 (8074.8 examples/sec; 0.016 sec/batch)
2018-02-01 16:55:29.769105: step 72200, loss = 2.12 (8704.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:55:31.208310: step 72300, loss = 2.18 (8893.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:55:32.645209: step 72400, loss = 2.14 (8908.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:55:34.121250: step 72500, loss = 2.16 (8671.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:55:35.587359: step 72600, loss = 2.16 (8730.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:55:37.039355: step 72700, loss = 2.16 (8815.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:55:38.491394: step 72800, loss = 2.22 (8815.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:55:39.945730: step 72900, loss = 2.20 (8801.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:55:41.371039: step 73000, loss = 2.13 (8980.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:55:42.805930: step 73100, loss = 2.11 (8920.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:55:44.238764: step 73200, loss = 2.17 (8933.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:55:45.669533: step 73300, loss = 2.12 (8946.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:55:47.121513: step 73400, loss = 2.13 (8815.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:55:48.568550: step 73500, loss = 2.10 (8845.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:55:50.001777: step 73600, loss = 2.17 (8930.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:01.387056: step 73700, loss = 2.15 (1124.3 examples/sec; 0.114 sec/batch)
2018-02-01 16:56:02.820518: step 73800, loss = 2.17 (8929.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:04.284052: step 73900, loss = 2.09 (8746.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:56:05.745046: step 74000, loss = 2.12 (8761.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:56:07.186997: step 74100, loss = 2.16 (8876.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:08.638608: step 74200, loss = 2.26 (8817.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:56:10.094147: step 74300, loss = 2.19 (8794.0 examples/sec; 0.015 sec/batch)
2018-02-01 16:56:11.538461: step 74400, loss = 2.10 (8862.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:12.973244: step 74500, loss = 2.13 (8921.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:14.423147: step 74600, loss = 2.18 (8828.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:15.872262: step 74700, loss = 2.18 (8833.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:17.317151: step 74800, loss = 2.24 (8858.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:18.766589: step 74900, loss = 2.13 (8831.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:20.217931: step 75000, loss = 2.21 (8819.4 examples/sec; 0.015 sec/batch)
2018-02-01 16:56:23.272271: step 75100, loss = 2.16 (4190.8 examples/sec; 0.031 sec/batch)
2018-02-01 16:56:24.706501: step 75200, loss = 2.17 (8924.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:26.118024: step 75300, loss = 2.17 (9068.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:27.562263: step 75400, loss = 2.14 (8862.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:29.026179: step 75500, loss = 2.12 (8743.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:56:30.468244: step 75600, loss = 2.09 (8876.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:32.898128: step 75700, loss = 2.19 (5267.7 examples/sec; 0.024 sec/batch)
2018-02-01 16:56:35.443175: step 75800, loss = 2.18 (5029.4 examples/sec; 0.025 sec/batch)
2018-02-01 16:56:38.344878: step 75900, loss = 2.08 (4411.2 examples/sec; 0.029 sec/batch)
2018-02-01 16:56:40.890811: step 76000, loss = 2.22 (5027.6 examples/sec; 0.025 sec/batch)
2018-02-01 16:56:43.542724: step 76100, loss = 2.19 (4826.7 examples/sec; 0.027 sec/batch)
2018-02-01 16:56:46.299886: step 76200, loss = 2.20 (4642.5 examples/sec; 0.028 sec/batch)
2018-02-01 16:56:48.257019: step 76300, loss = 2.13 (6540.2 examples/sec; 0.020 sec/batch)
2018-02-01 16:56:49.683750: step 76400, loss = 2.12 (8971.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:56:52.637179: step 76500, loss = 2.17 (4333.9 examples/sec; 0.030 sec/batch)
2018-02-01 16:56:54.099691: step 76600, loss = 2.14 (8752.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:56:55.568464: step 76700, loss = 2.14 (8714.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:56:57.018774: step 76800, loss = 2.20 (8825.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:56:58.473410: step 76900, loss = 2.16 (8799.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:56:59.909119: step 77000, loss = 2.10 (8915.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:01.338916: step 77100, loss = 2.12 (8952.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:02.777604: step 77200, loss = 2.17 (8897.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:04.202762: step 77300, loss = 2.16 (8981.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:05.667579: step 77400, loss = 2.17 (8738.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:57:07.107538: step 77500, loss = 2.09 (8889.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:08.550518: step 77600, loss = 2.14 (8870.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:10.010258: step 77700, loss = 2.20 (8768.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:57:11.463308: step 77800, loss = 2.12 (8809.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:57:12.909743: step 77900, loss = 2.19 (8849.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:14.358029: step 78000, loss = 2.11 (8838.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:15.791679: step 78100, loss = 2.14 (8928.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:17.234071: step 78200, loss = 2.14 (8874.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:19.162978: step 78300, loss = 2.18 (6635.9 examples/sec; 0.019 sec/batch)
2018-02-01 16:57:30.086323: step 78400, loss = 2.20 (1171.8 examples/sec; 0.109 sec/batch)
2018-02-01 16:57:31.548639: step 78500, loss = 2.08 (8753.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:57:32.983458: step 78600, loss = 2.16 (8921.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:34.422066: step 78700, loss = 2.18 (8897.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:35.877172: step 78800, loss = 2.18 (8796.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:57:37.336012: step 78900, loss = 2.18 (8774.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:57:38.786098: step 79000, loss = 2.14 (8827.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:57:40.220220: step 79100, loss = 2.12 (8925.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:41.682796: step 79200, loss = 2.07 (8751.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:57:43.131958: step 79300, loss = 2.10 (8832.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:44.566711: step 79400, loss = 2.18 (8921.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:45.991958: step 79500, loss = 2.18 (8980.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:47.449725: step 79600, loss = 2.12 (8780.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:57:48.904976: step 79700, loss = 2.15 (8795.7 examples/sec; 0.015 sec/batch)
2018-02-01 16:57:50.357508: step 79800, loss = 2.14 (8812.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:57:53.331353: step 79900, loss = 2.15 (4304.2 examples/sec; 0.030 sec/batch)
2018-02-01 16:57:54.769534: step 80000, loss = 2.20 (8900.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:56.214262: step 80100, loss = 2.16 (8859.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:57.643453: step 80200, loss = 2.06 (8956.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:57:59.083897: step 80300, loss = 2.17 (8886.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:01.387436: step 80400, loss = 2.25 (5556.7 examples/sec; 0.023 sec/batch)
2018-02-01 16:58:03.798388: step 80500, loss = 2.15 (5309.1 examples/sec; 0.024 sec/batch)
2018-02-01 16:58:06.389295: step 80600, loss = 2.17 (4940.4 examples/sec; 0.026 sec/batch)
2018-02-01 16:58:09.151480: step 80700, loss = 2.15 (4634.0 examples/sec; 0.028 sec/batch)
2018-02-01 16:58:11.761524: step 80800, loss = 2.16 (4904.1 examples/sec; 0.026 sec/batch)
2018-02-01 16:58:14.255712: step 80900, loss = 2.09 (5131.9 examples/sec; 0.025 sec/batch)
2018-02-01 16:58:16.773308: step 81000, loss = 2.20 (5084.2 examples/sec; 0.025 sec/batch)
2018-02-01 16:58:18.207980: step 81100, loss = 2.09 (8921.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:19.658721: step 81200, loss = 2.18 (8823.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:58:22.621783: step 81300, loss = 2.19 (4319.9 examples/sec; 0.030 sec/batch)
2018-02-01 16:58:24.073985: step 81400, loss = 2.14 (8814.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:58:25.509654: step 81500, loss = 2.13 (8915.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:26.943025: step 81600, loss = 2.08 (8930.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:28.386932: step 81700, loss = 2.13 (8864.8 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:29.821343: step 81800, loss = 2.15 (8923.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:31.243307: step 81900, loss = 2.19 (9001.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:32.687001: step 82000, loss = 2.18 (8866.1 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:34.130956: step 82100, loss = 2.23 (8864.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:35.595264: step 82200, loss = 2.15 (8741.3 examples/sec; 0.015 sec/batch)
2018-02-01 16:58:37.050123: step 82300, loss = 2.17 (8798.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:58:38.488662: step 82400, loss = 2.11 (8897.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:39.943941: step 82500, loss = 2.21 (8795.6 examples/sec; 0.015 sec/batch)
2018-02-01 16:58:41.403769: step 82600, loss = 2.15 (8768.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:58:42.853550: step 82700, loss = 2.14 (8828.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:44.290320: step 82800, loss = 2.12 (8908.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:45.735749: step 82900, loss = 2.22 (8855.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:58:47.208224: step 83000, loss = 2.12 (8692.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:58:49.610928: step 83100, loss = 2.13 (5327.3 examples/sec; 0.024 sec/batch)
2018-02-01 16:58:59.915929: step 83200, loss = 2.18 (1242.1 examples/sec; 0.103 sec/batch)
2018-02-01 16:59:01.367157: step 83300, loss = 2.15 (8820.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:59:02.785988: step 83400, loss = 2.20 (9021.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:04.226836: step 83500, loss = 2.06 (8883.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:05.675031: step 83600, loss = 2.13 (8838.6 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:07.114608: step 83700, loss = 2.07 (8891.5 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:08.580832: step 83800, loss = 2.15 (8729.9 examples/sec; 0.015 sec/batch)
2018-02-01 16:59:10.022409: step 83900, loss = 2.08 (8879.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:11.454596: step 84000, loss = 2.22 (8937.4 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:12.921610: step 84100, loss = 2.13 (8725.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:59:14.373387: step 84200, loss = 2.15 (8816.8 examples/sec; 0.015 sec/batch)
2018-02-01 16:59:15.819358: step 84300, loss = 2.18 (8852.2 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:17.256918: step 84400, loss = 2.13 (8904.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:18.690011: step 84500, loss = 2.14 (8931.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:20.142378: step 84600, loss = 2.27 (8813.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:59:23.367691: step 84700, loss = 2.14 (3968.6 examples/sec; 0.032 sec/batch)
2018-02-01 16:59:25.005448: step 84800, loss = 2.15 (7815.6 examples/sec; 0.016 sec/batch)
2018-02-01 16:59:26.486032: step 84900, loss = 2.18 (8645.2 examples/sec; 0.015 sec/batch)
2018-02-01 16:59:27.935191: step 85000, loss = 2.20 (8832.7 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:29.564622: step 85100, loss = 2.15 (7855.5 examples/sec; 0.016 sec/batch)
2018-02-01 16:59:32.292337: step 85200, loss = 2.17 (4692.6 examples/sec; 0.027 sec/batch)
2018-02-01 16:59:35.011664: step 85300, loss = 2.12 (4707.0 examples/sec; 0.027 sec/batch)
2018-02-01 16:59:37.595603: step 85400, loss = 2.12 (4953.7 examples/sec; 0.026 sec/batch)
2018-02-01 16:59:40.211874: step 85500, loss = 2.11 (4892.5 examples/sec; 0.026 sec/batch)
2018-02-01 16:59:42.891529: step 85600, loss = 2.17 (4776.7 examples/sec; 0.027 sec/batch)
2018-02-01 16:59:45.842906: step 85700, loss = 2.16 (4337.0 examples/sec; 0.030 sec/batch)
2018-02-01 16:59:47.410921: step 85800, loss = 2.11 (8163.2 examples/sec; 0.016 sec/batch)
2018-02-01 16:59:48.904492: step 85900, loss = 2.19 (8570.1 examples/sec; 0.015 sec/batch)
2018-02-01 16:59:50.352804: step 86000, loss = 2.14 (8837.9 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:53.327346: step 86100, loss = 2.15 (4303.2 examples/sec; 0.030 sec/batch)
2018-02-01 16:59:54.761318: step 86200, loss = 2.17 (8926.3 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:56.233690: step 86300, loss = 2.22 (8693.5 examples/sec; 0.015 sec/batch)
2018-02-01 16:59:57.674486: step 86400, loss = 2.17 (8884.0 examples/sec; 0.014 sec/batch)
2018-02-01 16:59:59.116311: step 86500, loss = 2.05 (8877.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:00.569412: step 86600, loss = 2.09 (8808.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:00:02.009211: step 86700, loss = 2.11 (8890.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:03.458095: step 86800, loss = 2.14 (8834.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:04.898002: step 86900, loss = 2.14 (8889.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:06.333044: step 87000, loss = 2.10 (8919.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:07.784559: step 87100, loss = 2.10 (8818.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:00:09.222956: step 87200, loss = 2.12 (8898.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:10.701227: step 87300, loss = 2.19 (8658.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:00:12.130068: step 87400, loss = 2.14 (8958.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:13.579454: step 87500, loss = 2.13 (8831.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:15.030680: step 87600, loss = 2.08 (8820.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:00:16.481997: step 87700, loss = 2.13 (8819.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:00:18.758268: step 87800, loss = 2.19 (5623.2 examples/sec; 0.023 sec/batch)
2018-02-01 17:00:29.146185: step 87900, loss = 2.08 (1232.2 examples/sec; 0.104 sec/batch)
2018-02-01 17:00:30.576939: step 88000, loss = 2.20 (8946.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:32.026938: step 88100, loss = 2.18 (8827.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:33.492905: step 88200, loss = 2.12 (8731.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:00:34.935246: step 88300, loss = 2.09 (8874.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:36.427801: step 88400, loss = 2.12 (8575.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:00:37.865476: step 88500, loss = 2.10 (8903.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:39.298909: step 88600, loss = 2.30 (8929.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:40.746041: step 88700, loss = 2.13 (8845.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:42.212833: step 88800, loss = 2.17 (8726.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:00:43.659772: step 88900, loss = 2.21 (8846.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:45.122254: step 89000, loss = 2.18 (8752.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:00:46.554642: step 89100, loss = 2.24 (8936.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:47.985508: step 89200, loss = 2.11 (8945.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:49.441190: step 89300, loss = 2.19 (8793.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:00:52.483212: step 89400, loss = 2.13 (4207.7 examples/sec; 0.030 sec/batch)
2018-02-01 17:00:53.913165: step 89500, loss = 2.09 (8951.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:55.347787: step 89600, loss = 2.12 (8922.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:00:56.803806: step 89700, loss = 2.14 (8791.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:00:58.251164: step 89800, loss = 2.18 (8843.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:00.631223: step 89900, loss = 2.10 (5378.0 examples/sec; 0.024 sec/batch)
2018-02-01 17:01:03.267753: step 90000, loss = 2.16 (4854.9 examples/sec; 0.026 sec/batch)
2018-02-01 17:01:05.870441: step 90100, loss = 2.20 (4918.0 examples/sec; 0.026 sec/batch)
2018-02-01 17:01:08.392265: step 90200, loss = 2.18 (5075.7 examples/sec; 0.025 sec/batch)
2018-02-01 17:01:10.911661: step 90300, loss = 2.11 (5080.6 examples/sec; 0.025 sec/batch)
2018-02-01 17:01:13.646637: step 90400, loss = 2.14 (4680.1 examples/sec; 0.027 sec/batch)
2018-02-01 17:01:16.045407: step 90500, loss = 2.18 (5336.1 examples/sec; 0.024 sec/batch)
2018-02-01 17:01:17.481970: step 90600, loss = 2.11 (8910.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:18.952708: step 90700, loss = 2.10 (8703.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:01:20.372997: step 90800, loss = 2.11 (9012.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:23.434587: step 90900, loss = 2.16 (4180.8 examples/sec; 0.031 sec/batch)
2018-02-01 17:01:24.852622: step 91000, loss = 2.14 (9026.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:26.302824: step 91100, loss = 2.08 (8826.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:01:27.746265: step 91200, loss = 2.23 (8867.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:29.174546: step 91300, loss = 2.13 (8961.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:30.668614: step 91400, loss = 2.19 (8567.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:01:32.110466: step 91500, loss = 2.14 (8877.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:33.554709: step 91600, loss = 2.21 (8862.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:34.961613: step 91700, loss = 2.13 (9098.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:36.408205: step 91800, loss = 2.21 (8848.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:37.842257: step 91900, loss = 2.14 (8925.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:39.330220: step 92000, loss = 2.11 (8602.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:01:40.768680: step 92100, loss = 2.16 (8898.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:42.194701: step 92200, loss = 2.19 (8976.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:43.635780: step 92300, loss = 2.18 (8882.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:45.085139: step 92400, loss = 2.13 (8831.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:46.528333: step 92500, loss = 2.16 (8869.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:01:48.883069: step 92600, loss = 2.10 (5435.9 examples/sec; 0.024 sec/batch)
2018-02-01 17:01:59.200489: step 92700, loss = 2.21 (1240.6 examples/sec; 0.103 sec/batch)
2018-02-01 17:02:00.625573: step 92800, loss = 2.17 (8981.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:02.092773: step 92900, loss = 2.08 (8724.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:02:03.538012: step 93000, loss = 2.07 (8856.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:04.974539: step 93100, loss = 2.11 (8910.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:06.423828: step 93200, loss = 2.13 (8831.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:07.883955: step 93300, loss = 2.23 (8766.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:02:09.323190: step 93400, loss = 2.17 (8893.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:10.749597: step 93500, loss = 2.10 (8973.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:12.197213: step 93600, loss = 2.09 (8842.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:13.637128: step 93700, loss = 2.15 (8889.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:15.061157: step 93800, loss = 2.16 (8988.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:16.497234: step 93900, loss = 2.18 (8913.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:17.957726: step 94000, loss = 2.17 (8764.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:02:19.420374: step 94100, loss = 2.19 (8751.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:02:22.395714: step 94200, loss = 2.19 (4302.0 examples/sec; 0.030 sec/batch)
2018-02-01 17:02:23.813281: step 94300, loss = 2.11 (9029.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:25.285976: step 94400, loss = 2.16 (8691.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:02:26.720594: step 94500, loss = 2.14 (8922.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:28.193542: step 94600, loss = 2.13 (8690.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:02:30.351283: step 94700, loss = 2.19 (5932.1 examples/sec; 0.022 sec/batch)
2018-02-01 17:02:32.942179: step 94800, loss = 2.14 (4940.4 examples/sec; 0.026 sec/batch)
2018-02-01 17:02:35.480933: step 94900, loss = 2.15 (5041.8 examples/sec; 0.025 sec/batch)
2018-02-01 17:02:38.178947: step 95000, loss = 2.10 (4744.2 examples/sec; 0.027 sec/batch)
2018-02-01 17:02:40.647034: step 95100, loss = 2.19 (5186.2 examples/sec; 0.025 sec/batch)
2018-02-01 17:02:43.333817: step 95200, loss = 2.17 (4764.1 examples/sec; 0.027 sec/batch)
2018-02-01 17:02:45.887865: step 95300, loss = 2.13 (5011.7 examples/sec; 0.026 sec/batch)
2018-02-01 17:02:47.498274: step 95400, loss = 2.14 (7948.3 examples/sec; 0.016 sec/batch)
2018-02-01 17:02:48.949181: step 95500, loss = 2.24 (8822.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:02:50.402254: step 95600, loss = 2.13 (8808.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:02:53.322907: step 95700, loss = 2.14 (4382.6 examples/sec; 0.029 sec/batch)
2018-02-01 17:02:54.767157: step 95800, loss = 2.13 (8862.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:56.212959: step 95900, loss = 2.19 (8853.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:57.654570: step 96000, loss = 2.11 (8879.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:02:59.098951: step 96100, loss = 2.18 (8861.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:00.533407: step 96200, loss = 2.18 (8923.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:01.984633: step 96300, loss = 2.17 (8820.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:03:03.416537: step 96400, loss = 2.19 (8939.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:04.861617: step 96500, loss = 2.22 (8857.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:06.281023: step 96600, loss = 2.14 (9017.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:07.724715: step 96700, loss = 2.18 (8866.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:09.184571: step 96800, loss = 2.22 (8768.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:03:10.622238: step 96900, loss = 2.16 (8903.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:12.067622: step 97000, loss = 2.20 (8855.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:13.511464: step 97100, loss = 2.25 (8865.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:14.972432: step 97200, loss = 2.16 (8761.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:03:16.418733: step 97300, loss = 2.11 (8850.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:18.594370: step 97400, loss = 2.16 (5883.3 examples/sec; 0.022 sec/batch)
2018-02-01 17:03:29.179200: step 97500, loss = 2.09 (1211.1 examples/sec; 0.106 sec/batch)
2018-02-01 17:03:30.626562: step 97600, loss = 2.14 (8749.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:03:32.073935: step 97700, loss = 2.25 (8843.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:33.537635: step 97800, loss = 2.09 (8745.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:03:34.978502: step 97900, loss = 2.18 (8883.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:36.401976: step 98000, loss = 2.10 (8992.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:37.850982: step 98100, loss = 2.09 (8833.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:39.283557: step 98200, loss = 2.08 (8935.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:40.721608: step 98300, loss = 2.15 (8900.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:42.181668: step 98400, loss = 2.18 (8766.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:03:43.623183: step 98500, loss = 2.04 (8879.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:45.070305: step 98600, loss = 2.20 (8845.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:46.525596: step 98700, loss = 2.08 (8795.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:03:48.002334: step 98800, loss = 2.17 (8667.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:03:49.436246: step 98900, loss = 2.20 (8926.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:52.498062: step 99000, loss = 2.16 (4180.5 examples/sec; 0.031 sec/batch)
2018-02-01 17:03:53.952326: step 99100, loss = 2.14 (8801.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:03:55.402251: step 99200, loss = 2.13 (8828.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:56.844113: step 99300, loss = 2.17 (8877.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:03:58.291152: step 99400, loss = 2.08 (8845.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:04:00.665751: step 99500, loss = 2.23 (5390.4 examples/sec; 0.024 sec/batch)
2018-02-01 17:04:03.414055: step 99600, loss = 2.14 (4657.4 examples/sec; 0.027 sec/batch)
2018-02-01 17:04:06.228071: step 99700, loss = 2.19 (4548.7 examples/sec; 0.028 sec/batch)
2018-02-01 17:04:08.762281: step 99800, loss = 2.16 (5050.9 examples/sec; 0.025 sec/batch)
2018-02-01 17:04:11.422538: step 99900, loss = 2.24 (4811.6 examples/sec; 0.027 sec/batch)
2018-02-01 17:04:13.981190: step 100000, loss = 2.15 (5002.6 examples/sec; 0.026 sec/batch)
2018-02-01 17:04:16.093883: step 100100, loss = 2.12 (6058.6 examples/sec; 0.021 sec/batch)
2018-02-01 17:04:17.553193: step 100200, loss = 2.17 (8771.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:04:19.021834: step 100300, loss = 2.18 (8715.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:04:20.457014: step 100400, loss = 2.15 (8918.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:04:23.452432: step 100500, loss = 2.11 (4273.2 examples/sec; 0.030 sec/batch)
2018-02-01 17:04:24.882228: step 100600, loss = 2.12 (8952.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:04:26.350596: step 100700, loss = 2.16 (8717.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:04:27.792692: step 100800, loss = 2.20 (8876.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:04:29.249029: step 100900, loss = 2.22 (8789.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:04:30.700214: step 101000, loss = 2.19 (8820.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:04:32.155626: step 101100, loss = 2.10 (8794.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:04:33.590029: step 101200, loss = 2.12 (8923.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:04:35.049796: step 101300, loss = 2.20 (8768.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:04:36.488415: step 101400, loss = 2.21 (8897.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:04:37.934590: step 101500, loss = 2.14 (8850.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:04:39.371447: step 101600, loss = 2.15 (8908.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:04:40.819505: step 101700, loss = 2.17 (8839.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:04:42.261515: step 101800, loss = 2.10 (8876.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:04:43.734836: step 101900, loss = 2.12 (8687.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:04:45.151415: step 102000, loss = 2.17 (9035.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:04:46.937510: step 102100, loss = 2.13 (7166.5 examples/sec; 0.018 sec/batch)
2018-02-01 17:04:49.637848: step 102200, loss = 2.17 (4740.1 examples/sec; 0.027 sec/batch)
2018-02-01 17:04:59.178422: step 102300, loss = 2.13 (1341.6 examples/sec; 0.095 sec/batch)
2018-02-01 17:05:00.612710: step 102400, loss = 2.09 (8924.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:02.079025: step 102500, loss = 2.12 (8729.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:05:03.510667: step 102600, loss = 2.14 (8940.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:04.959894: step 102700, loss = 2.07 (8832.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:06.375017: step 102800, loss = 2.09 (9045.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:07.820678: step 102900, loss = 2.10 (8854.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:09.258731: step 103000, loss = 2.14 (8900.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:10.701341: step 103100, loss = 2.07 (8872.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:12.144136: step 103200, loss = 2.13 (8871.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:13.698146: step 103300, loss = 2.12 (8236.8 examples/sec; 0.016 sec/batch)
2018-02-01 17:05:15.114257: step 103400, loss = 2.15 (9038.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:16.552792: step 103500, loss = 2.14 (8897.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:17.995252: step 103600, loss = 2.09 (8873.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:19.459266: step 103700, loss = 2.11 (8743.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:05:22.436477: step 103800, loss = 2.17 (4299.3 examples/sec; 0.030 sec/batch)
2018-02-01 17:05:23.864115: step 103900, loss = 2.16 (8965.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:25.318098: step 104000, loss = 2.10 (8803.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:05:26.751856: step 104100, loss = 2.07 (8927.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:28.210852: step 104200, loss = 2.17 (8773.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:05:30.653145: step 104300, loss = 2.02 (5241.0 examples/sec; 0.024 sec/batch)
2018-02-01 17:05:33.292973: step 104400, loss = 2.12 (4848.8 examples/sec; 0.026 sec/batch)
2018-02-01 17:05:36.030796: step 104500, loss = 2.13 (4675.2 examples/sec; 0.027 sec/batch)
2018-02-01 17:05:38.746783: step 104600, loss = 2.19 (4712.8 examples/sec; 0.027 sec/batch)
2018-02-01 17:05:41.247040: step 104700, loss = 2.13 (5119.5 examples/sec; 0.025 sec/batch)
2018-02-01 17:05:43.981341: step 104800, loss = 2.16 (4681.3 examples/sec; 0.027 sec/batch)
2018-02-01 17:05:46.057641: step 104900, loss = 2.12 (6164.8 examples/sec; 0.021 sec/batch)
2018-02-01 17:05:47.514675: step 105000, loss = 2.18 (8785.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:05:48.954259: step 105100, loss = 2.22 (8891.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:50.396379: step 105200, loss = 2.21 (8875.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:53.329336: step 105300, loss = 2.07 (4364.2 examples/sec; 0.029 sec/batch)
2018-02-01 17:05:54.760752: step 105400, loss = 2.20 (8942.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:56.186515: step 105500, loss = 2.20 (8977.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:05:57.645635: step 105600, loss = 2.10 (8772.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:05:59.079216: step 105700, loss = 2.17 (8928.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:00.525350: step 105800, loss = 2.09 (8851.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:01.949543: step 105900, loss = 2.21 (8987.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:03.376958: step 106000, loss = 2.11 (8967.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:04.826045: step 106100, loss = 2.17 (8833.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:06.273069: step 106200, loss = 2.15 (8845.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:07.700275: step 106300, loss = 2.11 (8968.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:09.149462: step 106400, loss = 2.20 (8832.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:10.596810: step 106500, loss = 2.22 (8843.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:12.022996: step 106600, loss = 2.08 (8975.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:13.479650: step 106700, loss = 2.17 (8787.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:06:14.920180: step 106800, loss = 2.21 (8885.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:16.646300: step 106900, loss = 2.20 (7415.5 examples/sec; 0.017 sec/batch)
2018-02-01 17:06:19.337177: step 107000, loss = 2.16 (4756.8 examples/sec; 0.027 sec/batch)
2018-02-01 17:06:29.099131: step 107100, loss = 2.20 (1311.2 examples/sec; 0.098 sec/batch)
2018-02-01 17:06:30.549412: step 107200, loss = 2.13 (8825.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:06:31.999143: step 107300, loss = 2.20 (8829.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:33.457820: step 107400, loss = 2.13 (8775.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:06:34.900035: step 107500, loss = 2.12 (8875.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:36.355185: step 107600, loss = 2.08 (8796.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:06:37.798378: step 107700, loss = 2.19 (8869.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:39.236212: step 107800, loss = 2.16 (8902.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:40.681469: step 107900, loss = 2.25 (8856.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:42.119725: step 108000, loss = 2.13 (8899.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:43.546890: step 108100, loss = 2.11 (8968.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:44.990619: step 108200, loss = 2.01 (8865.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:46.431393: step 108300, loss = 2.17 (8884.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:47.866194: step 108400, loss = 2.15 (8921.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:49.305104: step 108500, loss = 2.24 (8895.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:52.336758: step 108600, loss = 2.15 (4222.1 examples/sec; 0.030 sec/batch)
2018-02-01 17:06:53.781160: step 108700, loss = 2.13 (8861.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:55.220843: step 108800, loss = 2.19 (8890.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:56.668809: step 108900, loss = 2.13 (8840.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:06:58.117343: step 109000, loss = 2.25 (8836.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:00.625114: step 109100, loss = 2.10 (5104.1 examples/sec; 0.025 sec/batch)
2018-02-01 17:07:03.288155: step 109200, loss = 2.24 (4806.5 examples/sec; 0.027 sec/batch)
2018-02-01 17:07:05.869145: step 109300, loss = 2.12 (4959.3 examples/sec; 0.026 sec/batch)
2018-02-01 17:07:08.781916: step 109400, loss = 2.13 (4394.4 examples/sec; 0.029 sec/batch)
2018-02-01 17:07:11.189114: step 109500, loss = 2.12 (5317.4 examples/sec; 0.024 sec/batch)
2018-02-01 17:07:13.999451: step 109600, loss = 2.10 (4554.6 examples/sec; 0.028 sec/batch)
2018-02-01 17:07:15.854058: step 109700, loss = 2.16 (6901.7 examples/sec; 0.019 sec/batch)
2018-02-01 17:07:17.287917: step 109800, loss = 2.16 (8927.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:18.708941: step 109900, loss = 2.18 (9007.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:20.146491: step 110000, loss = 2.04 (8904.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:23.108129: step 110100, loss = 2.23 (4321.9 examples/sec; 0.030 sec/batch)
2018-02-01 17:07:24.547501: step 110200, loss = 2.08 (8892.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:25.970198: step 110300, loss = 2.12 (8997.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:27.401855: step 110400, loss = 2.22 (8940.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:28.859968: step 110500, loss = 2.21 (8778.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:07:30.300808: step 110600, loss = 2.12 (8883.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:31.774668: step 110700, loss = 2.19 (8684.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:07:33.211234: step 110800, loss = 2.18 (8910.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:34.635626: step 110900, loss = 2.15 (8986.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:36.085341: step 111000, loss = 2.13 (8829.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:37.516119: step 111100, loss = 2.08 (8946.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:38.961762: step 111200, loss = 2.19 (8854.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:40.389078: step 111300, loss = 2.16 (8967.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:41.821263: step 111400, loss = 2.18 (8937.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:43.260311: step 111500, loss = 2.15 (8894.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:44.705552: step 111600, loss = 2.20 (8856.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:07:46.411344: step 111700, loss = 2.24 (7503.8 examples/sec; 0.017 sec/batch)
2018-02-01 17:07:48.861462: step 111800, loss = 2.17 (5224.2 examples/sec; 0.025 sec/batch)
2018-02-01 17:07:58.752817: step 111900, loss = 2.13 (1294.1 examples/sec; 0.099 sec/batch)
2018-02-01 17:08:00.196413: step 112000, loss = 2.09 (8866.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:01.619392: step 112100, loss = 2.12 (8995.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:03.067888: step 112200, loss = 2.13 (8836.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:04.502665: step 112300, loss = 2.11 (8921.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:05.949316: step 112400, loss = 2.19 (8848.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:07.407936: step 112500, loss = 2.21 (8775.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:08:08.864612: step 112600, loss = 2.20 (8787.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:08:10.309729: step 112700, loss = 2.14 (8857.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:11.763900: step 112800, loss = 2.21 (8802.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:08:13.216856: step 112900, loss = 2.10 (8809.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:08:14.643405: step 113000, loss = 2.19 (8972.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:16.084157: step 113100, loss = 2.15 (8884.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:17.533159: step 113200, loss = 2.12 (8833.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:18.955643: step 113300, loss = 2.12 (8998.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:20.387646: step 113400, loss = 2.14 (8938.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:23.415524: step 113500, loss = 2.18 (4227.4 examples/sec; 0.030 sec/batch)
2018-02-01 17:08:24.826565: step 113600, loss = 2.16 (9071.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:26.288921: step 113700, loss = 2.14 (8753.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:08:27.716738: step 113800, loss = 2.07 (8964.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:29.779899: step 113900, loss = 2.12 (6204.1 examples/sec; 0.021 sec/batch)
2018-02-01 17:08:32.435716: step 114000, loss = 2.24 (4819.6 examples/sec; 0.027 sec/batch)
2018-02-01 17:08:34.985743: step 114100, loss = 2.08 (5019.6 examples/sec; 0.026 sec/batch)
2018-02-01 17:08:37.441115: step 114200, loss = 2.09 (5213.1 examples/sec; 0.025 sec/batch)
2018-02-01 17:08:40.049006: step 114300, loss = 2.17 (4908.2 examples/sec; 0.026 sec/batch)
2018-02-01 17:08:42.792480: step 114400, loss = 2.12 (4665.6 examples/sec; 0.027 sec/batch)
2018-02-01 17:08:45.192013: step 114500, loss = 2.21 (5334.4 examples/sec; 0.024 sec/batch)
2018-02-01 17:08:46.808202: step 114600, loss = 2.18 (7919.9 examples/sec; 0.016 sec/batch)
2018-02-01 17:08:48.255644: step 114700, loss = 2.13 (8843.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:49.684982: step 114800, loss = 2.15 (8955.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:52.736893: step 114900, loss = 2.13 (4194.1 examples/sec; 0.031 sec/batch)
2018-02-01 17:08:54.160062: step 115000, loss = 2.13 (8994.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:55.593366: step 115100, loss = 2.16 (8930.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:57.012689: step 115200, loss = 2.18 (9018.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:58.446203: step 115300, loss = 2.23 (8929.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:08:59.890800: step 115400, loss = 2.16 (8860.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:01.322348: step 115500, loss = 2.19 (8941.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:02.763090: step 115600, loss = 2.12 (8884.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:04.192392: step 115700, loss = 2.18 (8955.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:05.624595: step 115800, loss = 2.04 (8937.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:07.062212: step 115900, loss = 2.18 (8903.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:08.508081: step 116000, loss = 2.13 (8852.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:09.958709: step 116100, loss = 2.16 (8823.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:09:11.420310: step 116200, loss = 2.18 (8757.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:09:12.841510: step 116300, loss = 2.13 (9006.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:14.274020: step 116400, loss = 2.22 (8935.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:15.680412: step 116500, loss = 2.11 (9101.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:17.886561: step 116600, loss = 2.13 (5802.0 examples/sec; 0.022 sec/batch)
2018-02-01 17:09:20.308373: step 116700, loss = 2.14 (5285.3 examples/sec; 0.024 sec/batch)
2018-02-01 17:09:29.731086: step 116800, loss = 2.09 (1358.4 examples/sec; 0.094 sec/batch)
2018-02-01 17:09:31.184647: step 116900, loss = 2.21 (8806.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:09:32.619815: step 117000, loss = 2.15 (8918.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:34.079878: step 117100, loss = 2.09 (8766.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:09:35.527078: step 117200, loss = 2.22 (8844.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:36.967548: step 117300, loss = 2.12 (8886.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:38.409036: step 117400, loss = 2.26 (8879.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:39.849703: step 117500, loss = 2.14 (8884.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:41.263602: step 117600, loss = 2.07 (9053.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:42.699728: step 117700, loss = 2.15 (8912.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:44.137517: step 117800, loss = 2.16 (8902.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:45.590443: step 117900, loss = 2.09 (8809.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:09:47.032541: step 118000, loss = 2.07 (8876.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:48.464699: step 118100, loss = 2.28 (8937.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:49.899035: step 118200, loss = 2.18 (8924.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:52.863261: step 118300, loss = 2.17 (4318.2 examples/sec; 0.030 sec/batch)
2018-02-01 17:09:54.325588: step 118400, loss = 2.15 (8753.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:09:55.751342: step 118500, loss = 2.13 (8977.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:57.188403: step 118600, loss = 2.15 (8907.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:09:58.684199: step 118700, loss = 2.13 (8557.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:10:01.249959: step 118800, loss = 2.10 (4988.8 examples/sec; 0.026 sec/batch)
2018-02-01 17:10:04.002710: step 118900, loss = 2.12 (4649.9 examples/sec; 0.028 sec/batch)
2018-02-01 17:10:06.479659: step 119000, loss = 2.11 (5167.6 examples/sec; 0.025 sec/batch)
2018-02-01 17:10:09.004441: step 119100, loss = 2.07 (5069.7 examples/sec; 0.025 sec/batch)
2018-02-01 17:10:11.784304: step 119200, loss = 2.16 (4604.5 examples/sec; 0.028 sec/batch)
2018-02-01 17:10:14.370505: step 119300, loss = 2.18 (4949.3 examples/sec; 0.026 sec/batch)
2018-02-01 17:10:16.321389: step 119400, loss = 2.21 (6561.1 examples/sec; 0.020 sec/batch)
2018-02-01 17:10:17.773725: step 119500, loss = 2.20 (8813.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:10:19.190387: step 119600, loss = 2.25 (9035.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:20.656335: step 119700, loss = 2.22 (8731.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:10:23.636372: step 119800, loss = 2.23 (4295.2 examples/sec; 0.030 sec/batch)
2018-02-01 17:10:25.082573: step 119900, loss = 2.14 (8850.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:26.520515: step 120000, loss = 2.12 (8901.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:27.971126: step 120100, loss = 2.11 (8823.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:10:29.416700: step 120200, loss = 2.15 (8854.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:30.874825: step 120300, loss = 2.04 (8778.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:10:32.308929: step 120400, loss = 2.15 (8925.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:33.748773: step 120500, loss = 2.13 (8889.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:35.223773: step 120600, loss = 2.10 (8678.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:10:36.659441: step 120700, loss = 2.09 (8915.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:38.093841: step 120800, loss = 2.15 (8923.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:39.540081: step 120900, loss = 2.12 (8850.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:40.970974: step 121000, loss = 2.12 (8945.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:42.396208: step 121100, loss = 2.12 (8981.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:43.831653: step 121200, loss = 2.13 (8917.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:45.270115: step 121300, loss = 2.11 (8898.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:10:47.053897: step 121400, loss = 2.10 (7175.8 examples/sec; 0.018 sec/batch)
2018-02-01 17:10:49.560386: step 121500, loss = 2.13 (5106.7 examples/sec; 0.025 sec/batch)
2018-02-01 17:10:59.392706: step 121600, loss = 2.24 (1301.8 examples/sec; 0.098 sec/batch)
2018-02-01 17:11:00.823888: step 121700, loss = 2.04 (8943.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:02.262127: step 121800, loss = 2.12 (8899.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:03.685812: step 121900, loss = 2.21 (8990.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:05.150207: step 122000, loss = 2.09 (8740.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:11:06.574760: step 122100, loss = 2.18 (8985.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:08.039568: step 122200, loss = 2.19 (8738.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:11:09.496905: step 122300, loss = 2.10 (8783.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:11:10.920460: step 122400, loss = 2.14 (8991.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:12.367209: step 122500, loss = 2.27 (8847.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:13.824492: step 122600, loss = 2.14 (8783.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:11:15.291534: step 122700, loss = 2.07 (8725.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:11:16.744286: step 122800, loss = 2.26 (8810.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:11:18.180657: step 122900, loss = 2.12 (8911.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:19.628928: step 123000, loss = 2.13 (8838.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:22.607825: step 123100, loss = 2.05 (4296.9 examples/sec; 0.030 sec/batch)
2018-02-01 17:11:24.070877: step 123200, loss = 2.12 (8748.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:11:25.525617: step 123300, loss = 2.12 (8798.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:11:26.959062: step 123400, loss = 2.21 (8929.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:28.391612: step 123500, loss = 2.09 (8935.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:30.766725: step 123600, loss = 2.12 (5389.2 examples/sec; 0.024 sec/batch)
2018-02-01 17:11:33.424203: step 123700, loss = 2.13 (4816.6 examples/sec; 0.027 sec/batch)
2018-02-01 17:11:36.077337: step 123800, loss = 2.17 (4824.5 examples/sec; 0.027 sec/batch)
2018-02-01 17:11:38.683831: step 123900, loss = 2.14 (4910.8 examples/sec; 0.026 sec/batch)
2018-02-01 17:11:41.298708: step 124000, loss = 2.20 (4895.1 examples/sec; 0.026 sec/batch)
2018-02-01 17:11:43.886930: step 124100, loss = 2.22 (4945.5 examples/sec; 0.026 sec/batch)
2018-02-01 17:11:46.147133: step 124200, loss = 2.15 (5663.2 examples/sec; 0.023 sec/batch)
2018-02-01 17:11:47.593120: step 124300, loss = 2.16 (8852.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:49.015595: step 124400, loss = 2.06 (8998.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:50.461430: step 124500, loss = 2.13 (8853.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:53.512723: step 124600, loss = 2.15 (4194.9 examples/sec; 0.031 sec/batch)
2018-02-01 17:11:54.965929: step 124700, loss = 2.07 (8808.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:11:56.396356: step 124800, loss = 2.23 (8948.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:11:57.851495: step 124900, loss = 2.13 (8796.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:11:59.261502: step 125000, loss = 2.15 (9078.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:00.707552: step 125100, loss = 2.13 (8851.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:02.149648: step 125200, loss = 2.14 (8876.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:03.601876: step 125300, loss = 2.11 (8814.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:12:05.057049: step 125400, loss = 2.19 (8796.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:12:06.507133: step 125500, loss = 2.05 (8827.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:12:07.944158: step 125600, loss = 2.20 (8907.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:09.376228: step 125700, loss = 2.07 (8938.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:10.830950: step 125800, loss = 2.22 (8798.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:12:12.262618: step 125900, loss = 2.11 (8940.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:13.682518: step 126000, loss = 2.21 (9014.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:15.133600: step 126100, loss = 2.07 (8821.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:12:16.687028: step 126200, loss = 2.12 (8239.8 examples/sec; 0.016 sec/batch)
2018-02-01 17:12:19.088116: step 126300, loss = 2.19 (5330.9 examples/sec; 0.024 sec/batch)
2018-02-01 17:12:29.226473: step 126400, loss = 2.08 (1262.5 examples/sec; 0.101 sec/batch)
2018-02-01 17:12:30.657355: step 126500, loss = 2.11 (8945.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:32.099599: step 126600, loss = 2.12 (8875.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:33.559124: step 126700, loss = 2.21 (8770.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:12:35.001266: step 126800, loss = 2.17 (8875.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:36.419458: step 126900, loss = 2.22 (9025.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:37.871371: step 127000, loss = 2.06 (8816.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:12:39.316099: step 127100, loss = 2.12 (8859.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:40.747498: step 127200, loss = 2.17 (8942.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:42.194285: step 127300, loss = 2.21 (8847.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:43.619313: step 127400, loss = 2.14 (8982.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:45.048743: step 127500, loss = 2.19 (8954.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:46.510881: step 127600, loss = 2.06 (8754.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:12:47.949301: step 127700, loss = 2.12 (8898.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:49.368837: step 127800, loss = 2.09 (9017.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:52.376835: step 127900, loss = 2.14 (4255.3 examples/sec; 0.030 sec/batch)
2018-02-01 17:12:53.795517: step 128000, loss = 2.16 (9022.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:55.248040: step 128100, loss = 2.11 (8812.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:12:56.661702: step 128200, loss = 2.17 (9054.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:12:58.092646: step 128300, loss = 2.12 (8945.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:00.097054: step 128400, loss = 2.05 (6385.9 examples/sec; 0.020 sec/batch)
2018-02-01 17:13:02.829041: step 128500, loss = 2.14 (4685.2 examples/sec; 0.027 sec/batch)
2018-02-01 17:13:05.516237: step 128600, loss = 2.09 (4763.3 examples/sec; 0.027 sec/batch)
2018-02-01 17:13:08.019593: step 128700, loss = 2.14 (5113.1 examples/sec; 0.025 sec/batch)
2018-02-01 17:13:10.721208: step 128800, loss = 2.17 (4737.9 examples/sec; 0.027 sec/batch)
2018-02-01 17:13:13.542192: step 128900, loss = 2.13 (4537.4 examples/sec; 0.028 sec/batch)
2018-02-01 17:13:15.863521: step 129000, loss = 2.12 (5514.1 examples/sec; 0.023 sec/batch)
2018-02-01 17:13:17.311744: step 129100, loss = 2.13 (8838.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:18.762688: step 129200, loss = 2.17 (8821.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:13:20.184653: step 129300, loss = 2.03 (9001.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:23.141472: step 129400, loss = 2.10 (4329.0 examples/sec; 0.030 sec/batch)
2018-02-01 17:13:24.588639: step 129500, loss = 2.19 (8844.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:26.032836: step 129600, loss = 2.25 (8863.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:27.461934: step 129700, loss = 2.09 (8956.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:28.881049: step 129800, loss = 2.28 (9019.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:30.322624: step 129900, loss = 2.20 (8879.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:31.767262: step 130000, loss = 2.17 (8860.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:33.195776: step 130100, loss = 2.08 (8960.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:34.615751: step 130200, loss = 2.18 (9014.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:36.057837: step 130300, loss = 2.15 (8876.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:37.492400: step 130400, loss = 2.13 (8922.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:38.942913: step 130500, loss = 2.13 (8824.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:13:40.374219: step 130600, loss = 2.15 (8942.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:41.827242: step 130700, loss = 2.12 (8809.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:13:43.275617: step 130800, loss = 2.09 (8837.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:44.731245: step 130900, loss = 2.11 (8793.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:13:46.165061: step 131000, loss = 2.22 (8927.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:13:48.806608: step 131100, loss = 2.11 (4845.6 examples/sec; 0.026 sec/batch)
2018-02-01 17:13:58.710064: step 131200, loss = 2.15 (1292.5 examples/sec; 0.099 sec/batch)
2018-02-01 17:14:00.149912: step 131300, loss = 2.11 (8889.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:01.568033: step 131400, loss = 2.20 (9026.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:03.013463: step 131500, loss = 2.18 (8855.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:04.461575: step 131600, loss = 2.14 (8839.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:05.886851: step 131700, loss = 2.14 (8980.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:07.325782: step 131800, loss = 2.21 (8895.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:08.741538: step 131900, loss = 2.20 (9041.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:10.186707: step 132000, loss = 2.09 (8857.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:11.625682: step 132100, loss = 2.08 (8895.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:13.066512: step 132200, loss = 2.09 (8883.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:14.527707: step 132300, loss = 2.17 (8759.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:14:15.949264: step 132400, loss = 2.13 (9004.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:17.395632: step 132500, loss = 2.16 (8849.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:18.819879: step 132600, loss = 2.08 (8987.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:20.281093: step 132700, loss = 2.14 (8759.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:14:23.308445: step 132800, loss = 2.17 (4228.1 examples/sec; 0.030 sec/batch)
2018-02-01 17:14:24.731841: step 132900, loss = 2.17 (8992.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:26.169601: step 133000, loss = 2.10 (8902.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:27.624108: step 133100, loss = 2.17 (8800.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:14:29.509468: step 133200, loss = 2.23 (6789.2 examples/sec; 0.019 sec/batch)
2018-02-01 17:14:32.159970: step 133300, loss = 2.10 (4829.3 examples/sec; 0.027 sec/batch)
2018-02-01 17:14:34.841467: step 133400, loss = 2.10 (4773.5 examples/sec; 0.027 sec/batch)
2018-02-01 17:14:37.434006: step 133500, loss = 2.16 (4937.2 examples/sec; 0.026 sec/batch)
2018-02-01 17:14:40.010116: step 133600, loss = 2.19 (4968.7 examples/sec; 0.026 sec/batch)
2018-02-01 17:14:42.912687: step 133700, loss = 2.18 (4409.9 examples/sec; 0.029 sec/batch)
2018-02-01 17:14:45.419014: step 133800, loss = 2.20 (5107.1 examples/sec; 0.025 sec/batch)
2018-02-01 17:14:46.858504: step 133900, loss = 2.19 (8892.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:48.305388: step 134000, loss = 2.09 (8846.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:49.755909: step 134100, loss = 2.16 (8824.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:14:52.830459: step 134200, loss = 2.09 (4163.2 examples/sec; 0.031 sec/batch)
2018-02-01 17:14:54.257366: step 134300, loss = 2.11 (8970.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:55.719874: step 134400, loss = 2.21 (8752.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:14:57.151183: step 134500, loss = 2.18 (8942.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:14:58.598272: step 134600, loss = 2.19 (8845.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:00.029213: step 134700, loss = 2.22 (8945.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:01.458625: step 134800, loss = 2.16 (8954.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:02.893808: step 134900, loss = 2.22 (8918.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:04.313885: step 135000, loss = 2.10 (9013.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:05.765828: step 135100, loss = 2.17 (8815.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:15:07.227531: step 135200, loss = 2.13 (8756.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:15:08.648830: step 135300, loss = 2.16 (9005.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:10.079237: step 135400, loss = 2.17 (8948.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:11.522909: step 135500, loss = 2.17 (8866.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:12.989616: step 135600, loss = 2.16 (8727.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:15:14.421357: step 135700, loss = 2.17 (8940.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:15.859548: step 135800, loss = 2.09 (8900.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:18.358768: step 135900, loss = 2.26 (5121.6 examples/sec; 0.025 sec/batch)
2018-02-01 17:15:28.365692: step 136000, loss = 2.09 (1279.1 examples/sec; 0.100 sec/batch)
2018-02-01 17:15:29.813303: step 136100, loss = 2.14 (8842.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:31.257189: step 136200, loss = 2.13 (8865.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:32.701915: step 136300, loss = 2.16 (8859.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:34.138466: step 136400, loss = 2.16 (8910.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:35.584177: step 136500, loss = 2.20 (8853.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:37.026559: step 136600, loss = 2.17 (8874.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:38.489223: step 136700, loss = 2.14 (8751.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:15:39.938055: step 136800, loss = 2.10 (8834.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:41.379003: step 136900, loss = 2.20 (8883.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:42.831892: step 137000, loss = 2.25 (8810.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:15:44.263231: step 137100, loss = 2.06 (8942.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:45.702440: step 137200, loss = 2.12 (8893.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:47.131882: step 137300, loss = 2.14 (8954.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:48.604472: step 137400, loss = 2.17 (8692.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:15:50.026053: step 137500, loss = 2.15 (9004.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:53.068452: step 137600, loss = 2.20 (4207.2 examples/sec; 0.030 sec/batch)
2018-02-01 17:15:54.494395: step 137700, loss = 2.19 (8976.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:15:55.947666: step 137800, loss = 2.14 (8807.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:15:57.521589: step 137900, loss = 2.21 (8132.5 examples/sec; 0.016 sec/batch)
2018-02-01 17:15:59.638738: step 138000, loss = 2.13 (6045.9 examples/sec; 0.021 sec/batch)
2018-02-01 17:16:02.400936: step 138100, loss = 2.19 (4634.0 examples/sec; 0.028 sec/batch)
2018-02-01 17:16:05.010246: step 138200, loss = 2.12 (4905.5 examples/sec; 0.026 sec/batch)
2018-02-01 17:16:07.494125: step 138300, loss = 2.10 (5153.2 examples/sec; 0.025 sec/batch)
2018-02-01 17:16:10.059347: step 138400, loss = 2.11 (4989.8 examples/sec; 0.026 sec/batch)
2018-02-01 17:16:12.696688: step 138500, loss = 2.15 (4853.4 examples/sec; 0.026 sec/batch)
2018-02-01 17:16:15.419782: step 138600, loss = 2.10 (4700.5 examples/sec; 0.027 sec/batch)
2018-02-01 17:16:17.127396: step 138700, loss = 2.14 (7495.8 examples/sec; 0.017 sec/batch)
2018-02-01 17:16:18.568406: step 138800, loss = 2.20 (8882.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:19.988338: step 138900, loss = 2.18 (9014.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:22.954711: step 139000, loss = 2.19 (4315.0 examples/sec; 0.030 sec/batch)
2018-02-01 17:16:24.374409: step 139100, loss = 2.19 (9016.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:25.822753: step 139200, loss = 2.18 (8837.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:27.258505: step 139300, loss = 2.07 (8915.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:28.705332: step 139400, loss = 2.13 (8846.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:30.128230: step 139500, loss = 2.07 (8995.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:31.568914: step 139600, loss = 2.11 (8884.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:32.990219: step 139700, loss = 2.17 (9005.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:34.437165: step 139800, loss = 2.10 (8846.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:35.865245: step 139900, loss = 2.20 (8963.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:37.288429: step 140000, loss = 2.07 (8993.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:38.738668: step 140100, loss = 2.18 (8826.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:16:40.169720: step 140200, loss = 2.16 (8944.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:41.610841: step 140300, loss = 2.13 (8882.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:43.024394: step 140400, loss = 2.26 (9055.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:44.465667: step 140500, loss = 2.22 (8881.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:45.891702: step 140600, loss = 2.07 (8975.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:16:47.811124: step 140700, loss = 2.21 (6668.7 examples/sec; 0.019 sec/batch)
2018-02-01 17:16:50.350684: step 140800, loss = 2.24 (5040.2 examples/sec; 0.025 sec/batch)
2018-02-01 17:17:00.111961: step 140900, loss = 2.07 (1311.3 examples/sec; 0.098 sec/batch)
2018-02-01 17:17:01.565328: step 141000, loss = 2.18 (8807.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:17:03.024004: step 141100, loss = 2.09 (8775.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:17:04.458688: step 141200, loss = 2.18 (8921.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:05.892588: step 141300, loss = 2.21 (8926.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:07.333942: step 141400, loss = 2.12 (8880.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:08.763279: step 141500, loss = 2.21 (8955.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:10.190070: step 141600, loss = 2.07 (8971.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:11.625460: step 141700, loss = 2.21 (8917.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:13.048980: step 141800, loss = 2.14 (8991.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:14.481262: step 141900, loss = 2.11 (8936.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:15.941816: step 142000, loss = 2.13 (8763.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:17:17.385859: step 142100, loss = 2.12 (8864.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:18.829690: step 142200, loss = 2.08 (8865.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:20.261722: step 142300, loss = 2.19 (8938.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:23.317762: step 142400, loss = 2.12 (4188.4 examples/sec; 0.031 sec/batch)
2018-02-01 17:17:24.752795: step 142500, loss = 2.18 (8919.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:26.182611: step 142600, loss = 2.17 (8952.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:27.640274: step 142700, loss = 2.08 (8781.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:17:29.323525: step 142800, loss = 2.14 (7604.3 examples/sec; 0.017 sec/batch)
2018-02-01 17:17:32.120210: step 142900, loss = 2.18 (4576.8 examples/sec; 0.028 sec/batch)
2018-02-01 17:17:34.471344: step 143000, loss = 2.12 (5444.2 examples/sec; 0.024 sec/batch)
2018-02-01 17:17:37.276033: step 143100, loss = 2.09 (4563.8 examples/sec; 0.028 sec/batch)
2018-02-01 17:17:40.256350: step 143200, loss = 2.12 (4294.8 examples/sec; 0.030 sec/batch)
2018-02-01 17:17:42.711723: step 143300, loss = 2.14 (5213.1 examples/sec; 0.025 sec/batch)
2018-02-01 17:17:45.107933: step 143400, loss = 2.14 (5341.8 examples/sec; 0.024 sec/batch)
2018-02-01 17:17:46.837335: step 143500, loss = 2.19 (7401.4 examples/sec; 0.017 sec/batch)
2018-02-01 17:17:48.280626: step 143600, loss = 2.20 (8868.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:49.721748: step 143700, loss = 2.15 (8882.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:52.699089: step 143800, loss = 2.15 (4299.1 examples/sec; 0.030 sec/batch)
2018-02-01 17:17:54.123531: step 143900, loss = 2.21 (8986.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:55.558546: step 144000, loss = 2.18 (8919.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:56.984619: step 144100, loss = 2.13 (8975.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:58.423455: step 144200, loss = 2.16 (8896.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:17:59.869929: step 144300, loss = 2.17 (8849.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:01.327671: step 144400, loss = 2.12 (8780.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:18:02.749028: step 144500, loss = 2.08 (9005.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:04.159222: step 144600, loss = 2.12 (9076.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:05.616282: step 144700, loss = 2.15 (8784.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:18:07.065580: step 144800, loss = 2.13 (8831.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:08.501382: step 144900, loss = 2.14 (8914.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:09.922371: step 145000, loss = 2.14 (9007.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:11.382610: step 145100, loss = 2.15 (8765.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:18:12.834954: step 145200, loss = 2.22 (8813.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:18:14.285074: step 145300, loss = 2.10 (8826.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:18:15.725692: step 145400, loss = 2.19 (8885.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:17.506633: step 145500, loss = 2.14 (7187.2 examples/sec; 0.018 sec/batch)
2018-02-01 17:18:19.999749: step 145600, loss = 2.19 (5134.1 examples/sec; 0.025 sec/batch)
2018-02-01 17:18:29.844082: step 145700, loss = 2.20 (1300.2 examples/sec; 0.098 sec/batch)
2018-02-01 17:18:31.264237: step 145800, loss = 2.20 (9013.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:32.719394: step 145900, loss = 2.23 (8796.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:18:34.150033: step 146000, loss = 2.10 (8947.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:35.575105: step 146100, loss = 2.06 (8982.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:36.998513: step 146200, loss = 2.15 (8992.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:38.431385: step 146300, loss = 2.22 (8933.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:39.849240: step 146400, loss = 2.13 (9027.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:41.277154: step 146500, loss = 2.16 (8964.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:42.711908: step 146600, loss = 2.17 (8921.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:44.134411: step 146700, loss = 2.15 (8998.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:45.596640: step 146800, loss = 2.09 (8753.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:18:47.021051: step 146900, loss = 2.10 (8986.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:48.462160: step 147000, loss = 2.19 (8882.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:49.907618: step 147100, loss = 2.10 (8855.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:52.947312: step 147200, loss = 2.15 (4211.0 examples/sec; 0.030 sec/batch)
2018-02-01 17:18:54.378900: step 147300, loss = 2.15 (8941.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:55.805852: step 147400, loss = 2.17 (8970.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:57.243246: step 147500, loss = 2.08 (8905.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:18:58.689836: step 147600, loss = 2.14 (8848.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:00.918943: step 147700, loss = 2.13 (5742.2 examples/sec; 0.022 sec/batch)
2018-02-01 17:19:03.825308: step 147800, loss = 2.15 (4404.1 examples/sec; 0.029 sec/batch)
2018-02-01 17:19:06.406084: step 147900, loss = 2.23 (4959.7 examples/sec; 0.026 sec/batch)
2018-02-01 17:19:09.168690: step 148000, loss = 2.12 (4633.3 examples/sec; 0.028 sec/batch)
2018-02-01 17:19:11.951107: step 148100, loss = 2.21 (4600.3 examples/sec; 0.028 sec/batch)
2018-02-01 17:19:14.603431: step 148200, loss = 2.13 (4826.0 examples/sec; 0.027 sec/batch)
2018-02-01 17:19:16.532069: step 148300, loss = 2.14 (6636.8 examples/sec; 0.019 sec/batch)
2018-02-01 17:19:17.978760: step 148400, loss = 2.10 (8847.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:19.406131: step 148500, loss = 2.10 (8967.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:20.827931: step 148600, loss = 2.14 (9002.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:23.882122: step 148700, loss = 2.13 (4191.0 examples/sec; 0.031 sec/batch)
2018-02-01 17:19:25.290780: step 148800, loss = 2.14 (9086.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:26.758507: step 148900, loss = 2.17 (8721.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:19:28.180898: step 149000, loss = 2.11 (8998.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:29.592432: step 149100, loss = 2.15 (9068.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:31.027877: step 149200, loss = 2.13 (8917.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:32.457444: step 149300, loss = 2.19 (8953.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:33.886803: step 149400, loss = 2.19 (8955.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:35.315583: step 149500, loss = 2.17 (8958.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:36.758319: step 149600, loss = 2.13 (8872.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:38.211782: step 149700, loss = 2.10 (8806.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:19:39.660111: step 149800, loss = 2.19 (8837.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:41.085675: step 149900, loss = 2.19 (8978.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:42.531589: step 150000, loss = 2.08 (8852.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:43.957542: step 150100, loss = 2.15 (8976.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:45.382058: step 150200, loss = 2.07 (8985.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:19:47.212220: step 150300, loss = 2.15 (6993.9 examples/sec; 0.018 sec/batch)
2018-02-01 17:19:49.849204: step 150400, loss = 2.17 (4854.0 examples/sec; 0.026 sec/batch)
2018-02-01 17:19:59.454298: step 150500, loss = 2.10 (1332.6 examples/sec; 0.096 sec/batch)
2018-02-01 17:20:00.896014: step 150600, loss = 2.19 (8878.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:02.339334: step 150700, loss = 2.17 (8868.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:03.761876: step 150800, loss = 2.13 (8998.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:05.170778: step 150900, loss = 2.20 (9085.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:06.607621: step 151000, loss = 2.20 (8908.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:08.054528: step 151100, loss = 2.21 (8846.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:09.482489: step 151200, loss = 2.17 (8963.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:11.045636: step 151300, loss = 2.14 (8188.6 examples/sec; 0.016 sec/batch)
2018-02-01 17:20:12.493400: step 151400, loss = 2.19 (8841.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:14.002109: step 151500, loss = 2.05 (8484.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:20:15.434191: step 151600, loss = 2.11 (8938.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:16.868761: step 151700, loss = 2.14 (8922.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:18.303440: step 151800, loss = 2.07 (8921.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:19.747013: step 151900, loss = 2.14 (8866.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:22.709186: step 152000, loss = 2.13 (4321.2 examples/sec; 0.030 sec/batch)
2018-02-01 17:20:24.180328: step 152100, loss = 2.22 (8700.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:20:25.610817: step 152200, loss = 2.03 (8948.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:27.023662: step 152300, loss = 2.16 (9059.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:28.460406: step 152400, loss = 2.12 (8909.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:20:30.976660: step 152500, loss = 2.09 (5086.9 examples/sec; 0.025 sec/batch)
2018-02-01 17:20:33.673111: step 152600, loss = 2.16 (4747.0 examples/sec; 0.027 sec/batch)
2018-02-01 17:20:36.175237: step 152700, loss = 2.18 (5115.7 examples/sec; 0.025 sec/batch)
2018-02-01 17:20:38.795739: step 152800, loss = 2.12 (4884.6 examples/sec; 0.026 sec/batch)
2018-02-01 17:20:41.575208: step 152900, loss = 2.16 (4605.2 examples/sec; 0.028 sec/batch)
2018-02-01 17:20:44.284570: step 153000, loss = 2.11 (4724.4 examples/sec; 0.027 sec/batch)
2018-02-01 17:20:46.382136: step 153100, loss = 2.18 (6102.3 examples/sec; 0.021 sec/batch)
2018-02-01 17:20:47.833634: step 153200, loss = 2.14 (8818.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:20:49.314425: step 153300, loss = 2.16 (8644.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:20:50.799437: step 153400, loss = 2.12 (8619.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:20:53.763293: step 153500, loss = 2.21 (4318.7 examples/sec; 0.030 sec/batch)
2018-02-01 17:20:55.243289: step 153600, loss = 2.10 (8648.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:20:56.722726: step 153700, loss = 2.17 (8651.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:20:58.215972: step 153800, loss = 2.18 (8571.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:20:59.692661: step 153900, loss = 2.14 (8668.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:01.178879: step 154000, loss = 2.20 (8612.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:02.661217: step 154100, loss = 2.16 (8635.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:04.127878: step 154200, loss = 2.12 (8727.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:05.567828: step 154300, loss = 2.09 (8889.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:21:07.038651: step 154400, loss = 2.16 (8702.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:08.500114: step 154500, loss = 2.13 (8758.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:09.950458: step 154600, loss = 2.17 (8825.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:11.383576: step 154700, loss = 2.24 (8931.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:21:12.823677: step 154800, loss = 2.15 (8888.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:21:14.261337: step 154900, loss = 2.13 (8903.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:21:15.713643: step 155000, loss = 2.22 (8813.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:17.572064: step 155100, loss = 2.21 (6887.6 examples/sec; 0.019 sec/batch)
2018-02-01 17:21:20.240805: step 155200, loss = 2.12 (4796.3 examples/sec; 0.027 sec/batch)
2018-02-01 17:21:29.961919: step 155300, loss = 2.19 (1316.7 examples/sec; 0.097 sec/batch)
2018-02-01 17:21:31.419453: step 155400, loss = 2.06 (8782.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:32.864617: step 155500, loss = 2.17 (8857.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:21:34.352209: step 155600, loss = 2.11 (8604.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:35.823076: step 155700, loss = 2.16 (8702.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:37.275483: step 155800, loss = 2.11 (8813.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:38.735718: step 155900, loss = 2.16 (8765.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:40.180824: step 156000, loss = 2.09 (8857.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:21:41.635601: step 156100, loss = 2.19 (8798.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:43.080756: step 156200, loss = 2.18 (8857.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:21:44.533013: step 156300, loss = 2.09 (8813.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:46.003845: step 156400, loss = 2.14 (8702.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:47.444383: step 156500, loss = 2.10 (8885.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:21:48.880248: step 156600, loss = 2.20 (8914.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:21:50.333161: step 156700, loss = 2.15 (8809.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:53.331289: step 156800, loss = 2.17 (4269.3 examples/sec; 0.030 sec/batch)
2018-02-01 17:21:54.776666: step 156900, loss = 2.08 (8855.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:21:56.238779: step 157000, loss = 2.13 (8754.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:57.702132: step 157100, loss = 2.06 (8747.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:21:59.577315: step 157200, loss = 2.05 (6826.0 examples/sec; 0.019 sec/batch)
2018-02-01 17:22:01.986768: step 157300, loss = 2.22 (5312.4 examples/sec; 0.024 sec/batch)
2018-02-01 17:22:05.411181: step 157400, loss = 2.24 (3737.9 examples/sec; 0.034 sec/batch)
2018-02-01 17:22:07.928765: step 157500, loss = 2.10 (5084.2 examples/sec; 0.025 sec/batch)
2018-02-01 17:22:10.657924: step 157600, loss = 2.13 (4690.1 examples/sec; 0.027 sec/batch)
2018-02-01 17:22:13.269871: step 157700, loss = 2.11 (4900.6 examples/sec; 0.026 sec/batch)
2018-02-01 17:22:15.673930: step 157800, loss = 2.12 (5324.3 examples/sec; 0.024 sec/batch)
2018-02-01 17:22:17.118032: step 157900, loss = 2.18 (8863.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:18.561637: step 158000, loss = 2.13 (8866.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:20.002969: step 158100, loss = 2.16 (8880.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:23.084749: step 158200, loss = 2.14 (4153.4 examples/sec; 0.031 sec/batch)
2018-02-01 17:22:24.540099: step 158300, loss = 2.18 (8795.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:22:25.981376: step 158400, loss = 2.19 (8881.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:27.394595: step 158500, loss = 2.19 (9057.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:28.829654: step 158600, loss = 2.13 (8919.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:30.256780: step 158700, loss = 2.10 (8969.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:31.700500: step 158800, loss = 2.14 (8866.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:33.170843: step 158900, loss = 2.18 (8705.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:22:34.609125: step 159000, loss = 2.14 (8899.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:36.091645: step 159100, loss = 2.13 (8633.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:22:37.552022: step 159200, loss = 2.14 (8764.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:22:39.001986: step 159300, loss = 2.21 (8827.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:40.440715: step 159400, loss = 2.13 (8896.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:41.876042: step 159500, loss = 2.19 (8917.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:43.306073: step 159600, loss = 2.19 (8950.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:44.738967: step 159700, loss = 2.10 (8933.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:22:46.361890: step 159800, loss = 2.24 (7887.0 examples/sec; 0.016 sec/batch)
2018-02-01 17:22:49.016795: step 159900, loss = 2.14 (4821.3 examples/sec; 0.027 sec/batch)
2018-02-01 17:22:58.952940: step 160000, loss = 2.16 (1288.2 examples/sec; 0.099 sec/batch)
2018-02-01 17:23:00.422784: step 160100, loss = 2.10 (8708.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:23:01.882161: step 160200, loss = 2.09 (8770.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:23:03.307923: step 160300, loss = 2.10 (8977.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:04.788871: step 160400, loss = 2.13 (8643.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:23:06.226099: step 160500, loss = 2.16 (8906.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:07.649556: step 160600, loss = 2.09 (8992.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:09.115337: step 160700, loss = 2.21 (8732.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:23:10.557565: step 160800, loss = 2.19 (8875.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:12.005365: step 160900, loss = 2.15 (8841.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:13.451498: step 161000, loss = 2.09 (8851.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:14.901628: step 161100, loss = 2.23 (8826.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:23:16.321713: step 161200, loss = 2.22 (9013.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:17.778107: step 161300, loss = 2.04 (8788.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:23:19.211806: step 161400, loss = 2.12 (8928.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:20.662207: step 161500, loss = 2.12 (8825.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:23:23.677852: step 161600, loss = 2.10 (4244.5 examples/sec; 0.030 sec/batch)
2018-02-01 17:23:25.127385: step 161700, loss = 2.15 (8830.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:26.571224: step 161800, loss = 2.10 (8865.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:28.025235: step 161900, loss = 2.19 (8803.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:23:30.262427: step 162000, loss = 2.10 (5721.5 examples/sec; 0.022 sec/batch)
2018-02-01 17:23:33.058772: step 162100, loss = 2.13 (4577.4 examples/sec; 0.028 sec/batch)
2018-02-01 17:23:35.647731: step 162200, loss = 2.12 (4944.1 examples/sec; 0.026 sec/batch)
2018-02-01 17:23:38.319608: step 162300, loss = 2.14 (4790.6 examples/sec; 0.027 sec/batch)
2018-02-01 17:23:41.017620: step 162400, loss = 2.20 (4744.2 examples/sec; 0.027 sec/batch)
2018-02-01 17:23:43.644270: step 162500, loss = 2.12 (4873.1 examples/sec; 0.026 sec/batch)
2018-02-01 17:23:45.891030: step 162600, loss = 2.19 (5697.1 examples/sec; 0.022 sec/batch)
2018-02-01 17:23:47.339363: step 162700, loss = 2.19 (8837.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:48.800082: step 162800, loss = 2.18 (8762.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:23:50.237721: step 162900, loss = 2.11 (8903.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:53.212629: step 163000, loss = 2.11 (4302.7 examples/sec; 0.030 sec/batch)
2018-02-01 17:23:54.675707: step 163100, loss = 2.08 (8748.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:23:56.136571: step 163200, loss = 2.17 (8761.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:23:57.571343: step 163300, loss = 2.08 (8921.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:23:59.030234: step 163400, loss = 2.27 (8773.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:24:00.485057: step 163500, loss = 2.06 (8798.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:24:01.957425: step 163600, loss = 2.11 (8693.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:24:03.396659: step 163700, loss = 2.21 (8893.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:04.819471: step 163800, loss = 2.11 (8996.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:06.266296: step 163900, loss = 2.09 (8847.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:07.691917: step 164000, loss = 2.10 (8978.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:09.128769: step 164100, loss = 2.13 (8908.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:10.580717: step 164200, loss = 2.26 (8815.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:24:12.029106: step 164300, loss = 2.12 (8837.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:13.468371: step 164400, loss = 2.14 (8893.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:14.921447: step 164500, loss = 2.09 (8808.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:24:16.490116: step 164600, loss = 2.16 (8159.8 examples/sec; 0.016 sec/batch)
2018-02-01 17:24:19.174744: step 164700, loss = 2.24 (4767.9 examples/sec; 0.027 sec/batch)
2018-02-01 17:24:28.994754: step 164800, loss = 2.18 (1303.5 examples/sec; 0.098 sec/batch)
2018-02-01 17:24:30.430026: step 164900, loss = 2.12 (8918.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:31.892743: step 165000, loss = 2.11 (8750.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:24:33.331232: step 165100, loss = 2.17 (8898.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:34.776774: step 165200, loss = 2.16 (8854.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:36.200640: step 165300, loss = 2.11 (8989.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:37.647558: step 165400, loss = 2.16 (8846.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:39.092014: step 165500, loss = 2.08 (8861.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:40.537654: step 165600, loss = 2.21 (8854.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:41.984250: step 165700, loss = 2.16 (8848.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:43.430220: step 165800, loss = 2.15 (8852.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:44.868350: step 165900, loss = 2.13 (8900.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:46.306137: step 166000, loss = 2.12 (8902.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:47.765527: step 166100, loss = 2.14 (8770.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:24:49.196338: step 166200, loss = 2.16 (8946.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:50.646273: step 166300, loss = 2.11 (8828.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:53.681873: step 166400, loss = 2.15 (4216.6 examples/sec; 0.030 sec/batch)
2018-02-01 17:24:55.120582: step 166500, loss = 2.18 (8896.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:24:56.581032: step 166600, loss = 2.12 (8764.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:24:58.015939: step 166700, loss = 2.17 (8920.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:25:00.189783: step 166800, loss = 2.08 (5888.2 examples/sec; 0.022 sec/batch)
2018-02-01 17:25:02.719565: step 166900, loss = 2.24 (5059.7 examples/sec; 0.025 sec/batch)
2018-02-01 17:25:05.451597: step 167000, loss = 2.11 (4685.2 examples/sec; 0.027 sec/batch)
2018-02-01 17:25:08.055331: step 167100, loss = 2.15 (4916.0 examples/sec; 0.026 sec/batch)
2018-02-01 17:25:10.862205: step 167200, loss = 2.11 (4560.2 examples/sec; 0.028 sec/batch)
2018-02-01 17:25:13.612602: step 167300, loss = 2.06 (4653.9 examples/sec; 0.028 sec/batch)
2018-02-01 17:25:15.831775: step 167400, loss = 2.13 (5767.9 examples/sec; 0.022 sec/batch)
2018-02-01 17:25:17.281728: step 167500, loss = 2.13 (8827.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:25:18.721422: step 167600, loss = 2.14 (8890.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:25:20.146861: step 167700, loss = 2.19 (8979.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:25:23.206796: step 167800, loss = 2.10 (4183.1 examples/sec; 0.031 sec/batch)
2018-02-01 17:25:24.669332: step 167900, loss = 2.06 (8751.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:25:26.125354: step 168000, loss = 2.16 (8791.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:25:27.572787: step 168100, loss = 2.16 (8843.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:25:29.006301: step 168200, loss = 2.18 (8929.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:25:30.506771: step 168300, loss = 2.15 (8530.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:25:31.969453: step 168400, loss = 2.14 (8751.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:25:33.419978: step 168500, loss = 2.21 (8824.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:25:34.859764: step 168600, loss = 2.07 (8890.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:25:36.282294: step 168700, loss = 2.15 (8998.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:25:37.734321: step 168800, loss = 2.15 (8815.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:25:39.186070: step 168900, loss = 2.13 (8817.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:25:40.630028: step 169000, loss = 2.12 (8864.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:25:42.084130: step 169100, loss = 2.19 (8802.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:25:43.527140: step 169200, loss = 2.10 (8870.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:25:44.976373: step 169300, loss = 2.10 (8832.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:25:46.629890: step 169400, loss = 2.19 (7741.1 examples/sec; 0.017 sec/batch)
2018-02-01 17:25:49.305446: step 169500, loss = 2.15 (4784.1 examples/sec; 0.027 sec/batch)
2018-02-01 17:25:59.055032: step 169600, loss = 2.02 (1312.9 examples/sec; 0.097 sec/batch)
2018-02-01 17:26:00.473033: step 169700, loss = 2.13 (9026.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:01.926595: step 169800, loss = 2.13 (8806.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:26:03.367102: step 169900, loss = 2.17 (8885.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:04.807805: step 170000, loss = 2.14 (8884.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:06.250066: step 170100, loss = 2.16 (8875.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:07.713145: step 170200, loss = 2.13 (8748.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:26:09.152407: step 170300, loss = 2.14 (8893.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:10.574178: step 170400, loss = 2.10 (9002.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:12.020247: step 170500, loss = 2.13 (8851.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:13.473350: step 170600, loss = 2.17 (8808.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:26:14.929734: step 170700, loss = 2.17 (8788.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:26:16.372699: step 170800, loss = 2.12 (8870.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:17.805374: step 170900, loss = 2.21 (8934.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:19.254558: step 171000, loss = 2.16 (8832.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:20.688708: step 171100, loss = 2.17 (8925.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:23.742552: step 171200, loss = 2.15 (4191.4 examples/sec; 0.031 sec/batch)
2018-02-01 17:26:25.188247: step 171300, loss = 2.14 (8853.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:26.627234: step 171400, loss = 2.11 (8895.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:28.067296: step 171500, loss = 2.14 (8888.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:30.194005: step 171600, loss = 2.18 (6018.7 examples/sec; 0.021 sec/batch)
2018-02-01 17:26:32.719885: step 171700, loss = 2.10 (5067.5 examples/sec; 0.025 sec/batch)
2018-02-01 17:26:35.307726: step 171800, loss = 2.05 (4946.2 examples/sec; 0.026 sec/batch)
2018-02-01 17:26:37.964339: step 171900, loss = 2.12 (4818.2 examples/sec; 0.027 sec/batch)
2018-02-01 17:26:40.503628: step 172000, loss = 2.10 (5040.8 examples/sec; 0.025 sec/batch)
2018-02-01 17:26:43.272127: step 172100, loss = 2.10 (4623.4 examples/sec; 0.028 sec/batch)
2018-02-01 17:26:46.020108: step 172200, loss = 2.10 (4658.0 examples/sec; 0.027 sec/batch)
2018-02-01 17:26:47.448252: step 172300, loss = 2.17 (8962.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:48.875331: step 172400, loss = 2.18 (8969.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:50.330716: step 172500, loss = 2.20 (8794.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:26:53.337007: step 172600, loss = 2.10 (4257.7 examples/sec; 0.030 sec/batch)
2018-02-01 17:26:54.767755: step 172700, loss = 2.07 (8946.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:56.202689: step 172800, loss = 2.06 (8920.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:26:57.653118: step 172900, loss = 2.15 (8825.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:26:59.069892: step 173000, loss = 2.10 (9034.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:27:00.518098: step 173100, loss = 2.16 (8838.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:27:01.992083: step 173200, loss = 2.16 (8683.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:03.441739: step 173300, loss = 2.09 (8829.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:27:04.887202: step 173400, loss = 2.13 (8855.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:27:06.333209: step 173500, loss = 2.20 (8852.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:27:07.783708: step 173600, loss = 2.12 (8824.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:09.228708: step 173700, loss = 2.11 (8858.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:27:10.666357: step 173800, loss = 2.20 (8903.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:27:12.112877: step 173900, loss = 2.19 (8848.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:27:13.552247: step 174000, loss = 2.19 (8892.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:27:15.023302: step 174100, loss = 2.14 (8701.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:16.466569: step 174200, loss = 2.14 (8868.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:27:19.162472: step 174300, loss = 2.17 (4747.9 examples/sec; 0.027 sec/batch)
2018-02-01 17:27:29.300596: step 174400, loss = 2.11 (1262.6 examples/sec; 0.101 sec/batch)
2018-02-01 17:27:30.762884: step 174500, loss = 2.13 (8753.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:32.241460: step 174600, loss = 2.10 (8657.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:33.706260: step 174700, loss = 2.10 (8738.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:35.171365: step 174800, loss = 2.08 (8736.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:36.643671: step 174900, loss = 2.18 (8693.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:38.106125: step 175000, loss = 2.11 (8752.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:39.586656: step 175100, loss = 2.13 (8645.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:41.055888: step 175200, loss = 2.25 (8712.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:42.551979: step 175300, loss = 2.08 (8555.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:43.999389: step 175400, loss = 2.16 (8843.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:27:45.481437: step 175500, loss = 2.06 (8636.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:46.959417: step 175600, loss = 2.13 (8660.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:48.458448: step 175700, loss = 2.20 (8538.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:49.913544: step 175800, loss = 2.00 (8796.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:53.042629: step 175900, loss = 2.26 (4090.7 examples/sec; 0.031 sec/batch)
2018-02-01 17:27:54.497825: step 176000, loss = 2.21 (8796.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:55.980563: step 176100, loss = 2.17 (8632.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:57.451744: step 176200, loss = 2.19 (8700.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:27:58.973746: step 176300, loss = 2.15 (8410.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:28:01.813737: step 176400, loss = 2.16 (4507.1 examples/sec; 0.028 sec/batch)
2018-02-01 17:28:04.416144: step 176500, loss = 2.18 (4918.5 examples/sec; 0.026 sec/batch)
2018-02-01 17:28:07.259783: step 176600, loss = 2.10 (4501.3 examples/sec; 0.028 sec/batch)
2018-02-01 17:28:09.992015: step 176700, loss = 2.10 (4684.8 examples/sec; 0.027 sec/batch)
2018-02-01 17:28:12.593142: step 176800, loss = 2.13 (4920.9 examples/sec; 0.026 sec/batch)
2018-02-01 17:28:15.565473: step 176900, loss = 2.14 (4306.4 examples/sec; 0.030 sec/batch)
2018-02-01 17:28:17.021705: step 177000, loss = 2.18 (8789.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:28:18.471930: step 177100, loss = 2.17 (8826.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:28:19.935567: step 177200, loss = 2.06 (8745.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:28:22.902756: step 177300, loss = 2.09 (4313.8 examples/sec; 0.030 sec/batch)
2018-02-01 17:28:24.331273: step 177400, loss = 2.11 (8960.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:25.761905: step 177500, loss = 2.23 (8947.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:27.219561: step 177600, loss = 2.17 (8781.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:28:28.663871: step 177700, loss = 2.23 (8862.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:30.102501: step 177800, loss = 2.12 (8897.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:31.531944: step 177900, loss = 2.17 (8954.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:32.980897: step 178000, loss = 2.19 (8834.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:34.419099: step 178100, loss = 2.10 (8900.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:35.855659: step 178200, loss = 2.19 (8910.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:37.284251: step 178300, loss = 2.16 (8959.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:38.713928: step 178400, loss = 2.17 (8953.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:40.173643: step 178500, loss = 2.15 (8768.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:28:41.603425: step 178600, loss = 2.15 (8952.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:43.051413: step 178700, loss = 2.10 (8839.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:44.492856: step 178800, loss = 2.10 (8880.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:28:45.983684: step 178900, loss = 2.12 (8585.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:28:48.486809: step 179000, loss = 2.06 (5113.6 examples/sec; 0.025 sec/batch)
2018-02-01 17:28:51.093554: step 179100, loss = 2.07 (4910.3 examples/sec; 0.026 sec/batch)
2018-02-01 17:29:00.115297: step 179200, loss = 2.11 (1418.8 examples/sec; 0.090 sec/batch)
2018-02-01 17:29:01.575285: step 179300, loss = 2.06 (8767.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:29:03.014060: step 179400, loss = 2.15 (8896.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:04.463185: step 179500, loss = 2.22 (8832.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:05.880718: step 179600, loss = 2.15 (9029.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:07.335759: step 179700, loss = 2.18 (8797.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:29:08.762912: step 179800, loss = 2.06 (8968.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:10.205852: step 179900, loss = 2.12 (8870.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:11.651785: step 180000, loss = 2.11 (8852.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:13.119444: step 180100, loss = 2.10 (8721.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:29:14.557584: step 180200, loss = 2.10 (8900.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:15.976752: step 180300, loss = 2.15 (9019.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:17.409739: step 180400, loss = 2.14 (8932.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:18.842609: step 180500, loss = 2.12 (8933.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:20.307993: step 180600, loss = 2.13 (8734.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:29:23.342886: step 180700, loss = 2.06 (4217.6 examples/sec; 0.030 sec/batch)
2018-02-01 17:29:24.786643: step 180800, loss = 2.08 (8865.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:26.231035: step 180900, loss = 2.11 (8861.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:27.671901: step 181000, loss = 2.14 (8883.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:29.507657: step 181100, loss = 2.07 (6972.6 examples/sec; 0.018 sec/batch)
2018-02-01 17:29:32.556118: step 181200, loss = 2.14 (4198.8 examples/sec; 0.030 sec/batch)
2018-02-01 17:29:35.227615: step 181300, loss = 2.10 (4791.3 examples/sec; 0.027 sec/batch)
2018-02-01 17:29:37.653952: step 181400, loss = 2.16 (5275.4 examples/sec; 0.024 sec/batch)
2018-02-01 17:29:40.436789: step 181500, loss = 2.09 (4599.6 examples/sec; 0.028 sec/batch)
2018-02-01 17:29:43.061911: step 181600, loss = 2.17 (4876.0 examples/sec; 0.026 sec/batch)
2018-02-01 17:29:45.573271: step 181700, loss = 2.13 (5096.8 examples/sec; 0.025 sec/batch)
2018-02-01 17:29:47.007016: step 181800, loss = 2.17 (8927.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:48.431001: step 181900, loss = 2.13 (8988.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:49.875236: step 182000, loss = 2.28 (8862.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:52.932075: step 182100, loss = 2.21 (4187.3 examples/sec; 0.031 sec/batch)
2018-02-01 17:29:54.372182: step 182200, loss = 2.09 (8888.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:55.829352: step 182300, loss = 2.20 (8784.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:29:57.268149: step 182400, loss = 2.11 (8896.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:29:58.716633: step 182500, loss = 2.16 (8836.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:00.139348: step 182600, loss = 2.08 (8996.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:01.582507: step 182700, loss = 2.12 (8869.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:03.038777: step 182800, loss = 2.09 (8789.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:30:04.464603: step 182900, loss = 2.17 (8977.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:05.946489: step 183000, loss = 2.14 (8637.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:30:07.385259: step 183100, loss = 2.20 (8896.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:08.820181: step 183200, loss = 2.15 (8920.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:10.258249: step 183300, loss = 2.13 (8900.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:11.697038: step 183400, loss = 2.16 (8896.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:13.146397: step 183500, loss = 2.09 (8831.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:14.596294: step 183600, loss = 2.20 (8828.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:16.274038: step 183700, loss = 2.17 (7629.3 examples/sec; 0.017 sec/batch)
2018-02-01 17:30:19.275312: step 183800, loss = 2.18 (4264.9 examples/sec; 0.030 sec/batch)
2018-02-01 17:30:28.807308: step 183900, loss = 2.14 (1342.8 examples/sec; 0.095 sec/batch)
2018-02-01 17:30:30.222082: step 184000, loss = 2.15 (9047.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:31.667693: step 184100, loss = 2.18 (8854.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:33.110809: step 184200, loss = 2.09 (8869.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:34.566126: step 184300, loss = 2.14 (8795.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:30:36.012139: step 184400, loss = 2.23 (8851.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:37.461614: step 184500, loss = 2.20 (8830.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:38.921988: step 184600, loss = 2.08 (8764.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:30:40.373699: step 184700, loss = 2.21 (8817.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:30:41.817700: step 184800, loss = 2.21 (8864.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:43.271691: step 184900, loss = 2.18 (8803.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:30:44.716245: step 185000, loss = 2.12 (8860.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:46.170878: step 185100, loss = 2.17 (8799.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:30:47.593286: step 185200, loss = 2.24 (8998.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:49.041656: step 185300, loss = 2.07 (8837.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:50.520660: step 185400, loss = 2.20 (8654.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:30:53.570434: step 185500, loss = 2.14 (4197.0 examples/sec; 0.030 sec/batch)
2018-02-01 17:30:55.084476: step 185600, loss = 2.16 (8454.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:30:56.530397: step 185700, loss = 2.16 (8852.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:30:58.010135: step 185800, loss = 2.29 (8650.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:31:00.465855: step 185900, loss = 2.16 (5212.3 examples/sec; 0.025 sec/batch)
2018-02-01 17:31:03.310814: step 186000, loss = 2.18 (4499.2 examples/sec; 0.028 sec/batch)
2018-02-01 17:31:06.230804: step 186100, loss = 2.04 (4383.6 examples/sec; 0.029 sec/batch)
2018-02-01 17:31:09.122317: step 186200, loss = 2.14 (4426.7 examples/sec; 0.029 sec/batch)
2018-02-01 17:31:12.022136: step 186300, loss = 2.13 (4414.1 examples/sec; 0.029 sec/batch)
2018-02-01 17:31:14.685241: step 186400, loss = 2.13 (4806.4 examples/sec; 0.027 sec/batch)
2018-02-01 17:31:16.445451: step 186500, loss = 2.16 (7271.9 examples/sec; 0.018 sec/batch)
2018-02-01 17:31:17.899599: step 186600, loss = 2.09 (8802.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:31:19.355609: step 186700, loss = 2.16 (8791.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:31:20.805357: step 186800, loss = 2.11 (8829.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:31:23.945087: step 186900, loss = 2.11 (4076.8 examples/sec; 0.031 sec/batch)
2018-02-01 17:31:25.413174: step 187000, loss = 2.11 (8718.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:31:26.853040: step 187100, loss = 2.18 (8889.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:31:28.319355: step 187200, loss = 2.04 (8729.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:31:29.799216: step 187300, loss = 2.20 (8649.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:31:31.232533: step 187400, loss = 2.12 (8930.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:31:32.661567: step 187500, loss = 2.13 (8957.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:31:34.124032: step 187600, loss = 2.09 (8752.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:31:35.567006: step 187700, loss = 2.18 (8870.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:31:37.033725: step 187800, loss = 2.22 (8727.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:31:38.463867: step 187900, loss = 2.08 (8950.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:31:39.926453: step 188000, loss = 2.15 (8751.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:31:41.358164: step 188100, loss = 2.16 (8940.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:31:42.813740: step 188200, loss = 2.22 (8793.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:31:44.263878: step 188300, loss = 2.09 (8826.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:31:45.737348: step 188400, loss = 2.22 (8687.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:31:48.045415: step 188500, loss = 2.14 (5545.8 examples/sec; 0.023 sec/batch)
2018-02-01 17:31:50.879529: step 188600, loss = 2.17 (4516.4 examples/sec; 0.028 sec/batch)
2018-02-01 17:31:59.918080: step 188700, loss = 2.11 (1416.2 examples/sec; 0.090 sec/batch)
2018-02-01 17:32:01.349770: step 188800, loss = 2.13 (8940.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:32:02.803818: step 188900, loss = 2.17 (8803.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:32:04.236548: step 189000, loss = 2.10 (8934.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:32:05.676040: step 189100, loss = 2.26 (8892.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:32:07.157996: step 189200, loss = 2.14 (8637.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:32:08.607245: step 189300, loss = 2.13 (8832.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:32:10.062743: step 189400, loss = 2.18 (8794.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:32:11.515303: step 189500, loss = 2.14 (8812.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:32:12.977410: step 189600, loss = 2.19 (8754.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:32:14.451720: step 189700, loss = 2.16 (8682.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:32:15.901972: step 189800, loss = 2.14 (8826.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:32:17.346250: step 189900, loss = 2.17 (8862.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:32:18.789718: step 190000, loss = 2.08 (8867.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:32:20.215735: step 190100, loss = 2.23 (8976.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:32:23.228249: step 190200, loss = 2.05 (4248.9 examples/sec; 0.030 sec/batch)
2018-02-01 17:32:24.654000: step 190300, loss = 2.05 (8977.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:32:26.120498: step 190400, loss = 2.24 (8728.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:32:27.558947: step 190500, loss = 2.16 (8898.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:32:29.428393: step 190600, loss = 2.15 (6847.0 examples/sec; 0.019 sec/batch)
2018-02-01 17:32:32.024360: step 190700, loss = 2.17 (4930.7 examples/sec; 0.026 sec/batch)
2018-02-01 17:32:34.758673: step 190800, loss = 2.14 (4681.2 examples/sec; 0.027 sec/batch)
2018-02-01 17:32:37.215460: step 190900, loss = 2.23 (5210.1 examples/sec; 0.025 sec/batch)
2018-02-01 17:32:39.879613: step 191000, loss = 2.09 (4804.5 examples/sec; 0.027 sec/batch)
2018-02-01 17:32:42.436782: step 191100, loss = 2.07 (5005.5 examples/sec; 0.026 sec/batch)
2018-02-01 17:32:44.911762: step 191200, loss = 2.14 (5171.8 examples/sec; 0.025 sec/batch)
2018-02-01 17:32:46.809831: step 191300, loss = 2.18 (6743.7 examples/sec; 0.019 sec/batch)
2018-02-01 17:32:48.269903: step 191400, loss = 2.17 (8766.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:32:49.710064: step 191500, loss = 2.10 (8887.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:32:51.158467: step 191600, loss = 2.10 (8837.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:32:54.189071: step 191700, loss = 2.17 (4223.6 examples/sec; 0.030 sec/batch)
2018-02-01 17:32:55.680978: step 191800, loss = 2.15 (8579.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:32:57.141590: step 191900, loss = 2.20 (8763.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:32:58.578748: step 192000, loss = 2.12 (8906.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:00.017446: step 192100, loss = 2.20 (8896.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:01.478163: step 192200, loss = 2.18 (8762.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:02.974974: step 192300, loss = 2.14 (8551.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:04.433359: step 192400, loss = 2.13 (8776.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:05.866466: step 192500, loss = 2.06 (8931.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:07.334792: step 192600, loss = 2.13 (8717.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:08.777641: step 192700, loss = 2.11 (8871.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:10.229033: step 192800, loss = 2.14 (8819.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:11.660952: step 192900, loss = 2.10 (8939.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:13.117014: step 193000, loss = 2.22 (8790.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:14.595562: step 193100, loss = 2.09 (8657.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:16.044421: step 193200, loss = 2.07 (8834.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:17.978257: step 193300, loss = 2.13 (6619.0 examples/sec; 0.019 sec/batch)
2018-02-01 17:33:20.647905: step 193400, loss = 2.17 (4794.6 examples/sec; 0.027 sec/batch)
2018-02-01 17:33:30.279487: step 193500, loss = 2.18 (1329.0 examples/sec; 0.096 sec/batch)
2018-02-01 17:33:31.730421: step 193600, loss = 2.14 (8821.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:33.191184: step 193700, loss = 2.13 (8762.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:34.634459: step 193800, loss = 2.09 (8868.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:36.072399: step 193900, loss = 2.17 (8901.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:37.526340: step 194000, loss = 2.16 (8803.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:38.963092: step 194100, loss = 2.15 (8909.0 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:40.419469: step 194200, loss = 2.12 (8788.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:41.862444: step 194300, loss = 2.04 (8870.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:43.322544: step 194400, loss = 2.12 (8766.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:44.776915: step 194500, loss = 2.19 (8801.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:46.241020: step 194600, loss = 2.15 (8742.5 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:47.688076: step 194700, loss = 2.17 (8845.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:49.125595: step 194800, loss = 2.22 (8904.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:50.575173: step 194900, loss = 2.06 (8830.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:53.588363: step 195000, loss = 2.13 (4248.0 examples/sec; 0.030 sec/batch)
2018-02-01 17:33:55.032966: step 195100, loss = 2.10 (8860.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:33:56.498566: step 195200, loss = 2.14 (8733.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:57.949380: step 195300, loss = 2.16 (8822.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:33:59.619593: step 195400, loss = 2.15 (7663.7 examples/sec; 0.017 sec/batch)
2018-02-01 17:34:02.150346: step 195500, loss = 2.10 (5057.8 examples/sec; 0.025 sec/batch)
2018-02-01 17:34:04.943037: step 195600, loss = 2.20 (4583.4 examples/sec; 0.028 sec/batch)
2018-02-01 17:34:07.669698: step 195700, loss = 2.11 (4694.4 examples/sec; 0.027 sec/batch)
2018-02-01 17:34:10.519716: step 195800, loss = 2.23 (4491.2 examples/sec; 0.029 sec/batch)
2018-02-01 17:34:12.960795: step 195900, loss = 2.08 (5243.6 examples/sec; 0.024 sec/batch)
2018-02-01 17:34:15.378816: step 196000, loss = 2.04 (5293.6 examples/sec; 0.024 sec/batch)
2018-02-01 17:34:17.259159: step 196100, loss = 2.15 (6807.3 examples/sec; 0.019 sec/batch)
2018-02-01 17:34:18.715055: step 196200, loss = 2.16 (8791.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:34:20.159271: step 196300, loss = 2.13 (8862.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:34:23.161856: step 196400, loss = 2.09 (4263.0 examples/sec; 0.030 sec/batch)
2018-02-01 17:34:24.608262: step 196500, loss = 2.19 (8849.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:34:26.047607: step 196600, loss = 2.05 (8892.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:34:27.500942: step 196700, loss = 2.09 (8807.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:34:28.945933: step 196800, loss = 2.25 (8858.2 examples/sec; 0.014 sec/batch)
2018-02-01 17:34:30.386780: step 196900, loss = 2.13 (8883.7 examples/sec; 0.014 sec/batch)
2018-02-01 17:34:31.857990: step 197000, loss = 2.08 (8700.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:34:33.300832: step 197100, loss = 2.14 (8871.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:34:34.767097: step 197200, loss = 2.10 (8729.7 examples/sec; 0.015 sec/batch)
2018-02-01 17:34:36.220299: step 197300, loss = 2.14 (8808.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:34:37.680103: step 197400, loss = 2.11 (8768.3 examples/sec; 0.015 sec/batch)
2018-02-01 17:34:39.144990: step 197500, loss = 2.18 (8737.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:34:40.595673: step 197600, loss = 2.16 (8823.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:34:42.049254: step 197700, loss = 2.14 (8805.8 examples/sec; 0.015 sec/batch)
2018-02-01 17:34:43.490543: step 197800, loss = 2.19 (8880.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:34:44.956601: step 197900, loss = 2.07 (8730.9 examples/sec; 0.015 sec/batch)
2018-02-01 17:34:46.388858: step 198000, loss = 2.12 (8936.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:34:48.403809: step 198100, loss = 2.12 (6352.5 examples/sec; 0.020 sec/batch)
2018-02-01 17:34:51.202899: step 198200, loss = 2.07 (4572.9 examples/sec; 0.028 sec/batch)
2018-02-01 17:35:00.505941: step 198300, loss = 2.18 (1375.9 examples/sec; 0.093 sec/batch)
2018-02-01 17:35:01.946182: step 198400, loss = 2.17 (8887.4 examples/sec; 0.014 sec/batch)
2018-02-01 17:35:03.400372: step 198500, loss = 2.14 (8802.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:35:04.845671: step 198600, loss = 2.21 (8856.3 examples/sec; 0.014 sec/batch)
2018-02-01 17:35:06.302272: step 198700, loss = 2.13 (8787.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:35:07.748250: step 198800, loss = 2.14 (8852.1 examples/sec; 0.014 sec/batch)
2018-02-01 17:35:09.246890: step 198900, loss = 2.09 (8541.1 examples/sec; 0.015 sec/batch)
2018-02-01 17:35:10.708579: step 199000, loss = 2.14 (8757.0 examples/sec; 0.015 sec/batch)
2018-02-01 17:35:12.149240: step 199100, loss = 2.04 (8884.8 examples/sec; 0.014 sec/batch)
2018-02-01 17:35:13.605538: step 199200, loss = 2.14 (8789.4 examples/sec; 0.015 sec/batch)
2018-02-01 17:35:15.129312: step 199300, loss = 2.18 (8400.2 examples/sec; 0.015 sec/batch)
2018-02-01 17:35:16.583753: step 199400, loss = 2.19 (8800.6 examples/sec; 0.015 sec/batch)
2018-02-01 17:35:18.033250: step 199500, loss = 2.14 (8830.6 examples/sec; 0.014 sec/batch)
2018-02-01 17:35:19.479422: step 199600, loss = 2.10 (8850.9 examples/sec; 0.014 sec/batch)
2018-02-01 17:35:20.920291: step 199700, loss = 2.16 (8883.5 examples/sec; 0.014 sec/batch)
2018-02-01 17:35:23.973351: step 199800, loss = 2.12 (4192.5 examples/sec; 0.031 sec/batch)
2018-02-01 17:35:25.430365: step 199900, loss = 2.16 (8785.1 examples/sec; 0.015 sec/batch)