Images -> gris
pas de distored_inputs
f=tf.Variable(initial_value=tf.range(-5,5,10/576,dtype=tf.float32),trainable=True)
wdf=1/576
wdW=1/5760


EVALUATION


2018-02-01 14:52:45.915044: precision @ 1 = 0.104
2018-02-01 14:53:34.528572: precision @ 1 = 0.191
2018-02-01 14:54:16.260265: precision @ 1 = 0.192
2018-02-01 14:55:04.754186: precision @ 1 = 0.197
2018-02-01 14:55:46.769016: precision @ 1 = 0.199
2018-02-01 14:56:35.168834: precision @ 1 = 0.201
2018-02-01 14:57:18.594509: precision @ 1 = 0.196
2018-02-01 14:58:06.317868: precision @ 1 = 0.192
2018-02-01 14:58:55.680897: precision @ 1 = 0.190
2018-02-01 14:59:39.924459: precision @ 1 = 0.189
2018-02-01 15:00:27.020667: precision @ 1 = 0.187
2018-02-01 15:01:10.658283: precision @ 1 = 0.187
2018-02-01 15:01:57.841152: precision @ 1 = 0.186
2018-02-01 15:02:40.922868: precision @ 1 = 0.187
2018-02-01 15:03:28.849328: precision @ 1 = 0.187
2018-02-01 15:04:11.813456: precision @ 1 = 0.186
2018-02-01 15:04:59.754384: precision @ 1 = 0.184
2018-02-01 15:05:42.206044: precision @ 1 = 0.185
2018-02-01 15:06:29.292635: precision @ 1 = 0.184
2018-02-01 15:07:11.655996: precision @ 1 = 0.184
2018-02-01 15:07:59.002264: precision @ 1 = 0.182
2018-02-01 15:08:41.638682: precision @ 1 = 0.181
2018-02-01 15:09:29.093673: precision @ 1 = 0.182
2018-02-01 15:10:11.700769: precision @ 1 = 0.182
2018-02-01 15:10:59.182139: precision @ 1 = 0.180
2018-02-01 15:11:42.207828: precision @ 1 = 0.181
2018-02-01 15:12:30.238651: precision @ 1 = 0.181
2018-02-01 15:13:12.170873: precision @ 1 = 0.180
2018-02-01 15:13:59.840725: precision @ 1 = 0.181
2018-02-01 15:14:42.362205: precision @ 1 = 0.181
2018-02-01 15:15:30.018416: precision @ 1 = 0.182
2018-02-01 15:16:12.397539: precision @ 1 = 0.182
2018-02-01 15:17:00.341099: precision @ 1 = 0.181
2018-02-01 15:17:42.690671: precision @ 1 = 0.180
2018-02-01 15:18:30.425720: precision @ 1 = 0.181
2018-02-01 15:19:12.688259: precision @ 1 = 0.181
2018-02-01 15:20:00.211358: precision @ 1 = 0.181
2018-02-01 15:20:42.569627: precision @ 1 = 0.181
2018-02-01 15:21:29.728389: precision @ 1 = 0.182
2018-02-01 15:22:12.376174: precision @ 1 = 0.182
2018-02-01 15:22:59.607630: precision @ 1 = 0.182
2018-02-01 15:23:42.309987: precision @ 1 = 0.183
2018-02-01 15:24:29.341707: precision @ 1 = 0.182
2018-02-01 15:25:12.072279: precision @ 1 = 0.184
2018-02-01 15:25:59.523482: precision @ 1 = 0.183
2018-02-01 15:26:42.309854: precision @ 1 = 0.183
2018-02-01 15:27:30.991369: precision @ 1 = 0.183
2018-02-01 15:28:13.044863: precision @ 1 = 0.183
2018-02-01 15:29:00.987370: precision @ 1 = 0.183
2018-02-01 15:29:43.243013: precision @ 1 = 0.183
2018-02-01 15:30:30.444017: precision @ 1 = 0.183
2018-02-01 15:31:12.781047: precision @ 1 = 0.183
2018-02-01 15:32:00.193144: precision @ 1 = 0.183
2018-02-01 15:32:42.762849: precision @ 1 = 0.183
2018-02-01 15:33:30.533525: precision @ 1 = 0.183
2018-02-01 15:34:12.748907: precision @ 1 = 0.183
2018-02-01 15:35:00.560530: precision @ 1 = 0.183
2018-02-01 15:35:42.870999: precision @ 1 = 0.183
2018-02-01 15:36:30.753984: precision @ 1 = 0.182
2018-02-01 15:37:12.859059: precision @ 1 = 0.182
2018-02-01 15:38:01.138463: precision @ 1 = 0.182
2018-02-01 15:38:43.378647: precision @ 1 = 0.182
2018-02-01 15:39:31.192029: precision @ 1 = 0.182
2018-02-01 15:40:13.436030: precision @ 1 = 0.182
2018-02-01 15:41:00.917790: precision @ 1 = 0.181
2018-02-01 15:41:43.120144: precision @ 1 = 0.181
2018-02-01 15:42:31.728218: precision @ 1 = 0.181
2018-02-01 15:43:13.823407: precision @ 1 = 0.181
2018-02-01 15:44:01.945662: precision @ 1 = 0.181
2018-02-01 15:44:43.944825: precision @ 1 = 0.181
2018-02-01 15:45:31.891938: precision @ 1 = 0.181
2018-02-01 15:46:13.833725: precision @ 1 = 0.181
2018-02-01 15:47:01.388186: precision @ 1 = 0.181
2018-02-01 15:47:43.611073: precision @ 1 = 0.181
2018-02-01 15:48:31.640603: precision @ 1 = 0.181
2018-02-01 15:49:13.617822: precision @ 1 = 0.181
2018-02-01 15:50:01.398080: precision @ 1 = 0.181
2018-02-01 15:50:43.945405: precision @ 1 = 0.181
2018-02-01 15:51:31.607664: precision @ 1 = 0.182
2018-02-01 15:52:13.726025: precision @ 1 = 0.182
2018-02-01 15:53:00.935939: precision @ 1 = 0.181
2018-02-01 15:53:43.274738: precision @ 1 = 0.181
2018-02-01 15:54:31.037805: precision @ 1 = 0.181
2018-02-01 15:55:13.170799: precision @ 1 = 0.181
2018-02-01 15:55:52.617128: precision @ 1 = 0.181
2018-02-01 15:56:31.916238: precision @ 1 = 0.181
2018-02-01 15:57:11.361679: precision @ 1 = 0.181
2018-02-01 15:57:50.673751: precision @ 1 = 0.181
2018-02-01 15:58:30.079630: precision @ 1 = 0.181
2018-02-01 15:59:09.436670: precision @ 1 = 0.181
2018-02-01 15:59:48.858787: precision @ 1 = 0.181
2018-02-01 16:00:28.289663: precision @ 1 = 0.181
2018-02-01 16:01:07.678983: precision @ 1 = 0.181
2018-02-01 16:01:47.020662: precision @ 1 = 0.181
2018-02-01 16:02:26.343496: precision @ 1 = 0.181
2018-02-01 16:03:05.735562: precision @ 1 = 0.181
2018-02-01 16:03:45.058140: precision @ 1 = 0.181
2018-02-01 16:04:24.417823: precision @ 1 = 0.181
2018-02-01 16:05:03.850235: precision @ 1 = 0.181
2018-02-01 16:05:43.260351: precision @ 1 = 0.181
2018-02-01 16:06:24.297982: precision @ 1 = 0.181

LOSS (Train)

2018-02-01 14:52:06.536418: step 0, loss = 6.47 (1513.2 examples/sec; 0.085 sec/batch)
2018-02-01 14:52:08.267531: step 100, loss = 12.28 (7394.1 examples/sec; 0.017 sec/batch)
2018-02-01 14:52:09.838209: step 200, loss = 14.13 (8149.3 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:11.376400: step 300, loss = 8.02 (8321.5 examples/sec; 0.015 sec/batch)
2018-02-01 14:52:12.906469: step 400, loss = 8.43 (8365.6 examples/sec; 0.015 sec/batch)
2018-02-01 14:52:14.464112: step 500, loss = 10.01 (8217.5 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:16.035291: step 600, loss = 13.38 (8146.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:17.586323: step 700, loss = 9.41 (8252.6 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:19.143475: step 800, loss = 8.60 (8220.1 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:20.708146: step 900, loss = 7.76 (8180.6 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:22.291357: step 1000, loss = 6.61 (8084.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:23.937736: step 1100, loss = 5.99 (7774.6 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:25.512943: step 1200, loss = 5.66 (8125.9 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:27.055546: step 1300, loss = 5.73 (8297.7 examples/sec; 0.015 sec/batch)
2018-02-01 14:52:28.603663: step 1400, loss = 5.52 (8268.1 examples/sec; 0.015 sec/batch)
2018-02-01 14:52:30.174852: step 1500, loss = 4.91 (8146.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:31.764361: step 1600, loss = 5.07 (8052.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:33.319497: step 1700, loss = 4.23 (8230.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:44.266145: step 1800, loss = 4.19 (1169.3 examples/sec; 0.109 sec/batch)
2018-02-01 14:52:46.595855: step 1900, loss = 3.98 (5494.2 examples/sec; 0.023 sec/batch)
2018-02-01 14:52:48.160015: step 2000, loss = 3.63 (8183.3 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:49.734201: step 2100, loss = 3.80 (8131.2 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:51.297359: step 2200, loss = 3.56 (8188.6 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:52.891611: step 2300, loss = 3.57 (8028.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:54.479572: step 2400, loss = 3.48 (8060.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:56.067306: step 2500, loss = 3.39 (8061.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:57.655562: step 2600, loss = 3.21 (8059.2 examples/sec; 0.016 sec/batch)
2018-02-01 14:52:59.273364: step 2700, loss = 3.17 (7912.0 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:00.831529: step 2800, loss = 3.34 (8214.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:02.409239: step 2900, loss = 3.12 (8113.0 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:03.968397: step 3000, loss = 2.97 (8209.6 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:07.247485: step 3100, loss = 3.03 (3903.5 examples/sec; 0.033 sec/batch)
2018-02-01 14:53:08.813688: step 3200, loss = 3.13 (8172.6 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:10.359298: step 3300, loss = 2.94 (8281.5 examples/sec; 0.015 sec/batch)
2018-02-01 14:53:11.887864: step 3400, loss = 3.00 (8373.9 examples/sec; 0.015 sec/batch)
2018-02-01 14:53:13.414935: step 3500, loss = 2.86 (8382.1 examples/sec; 0.015 sec/batch)
2018-02-01 14:53:14.935479: step 3600, loss = 2.86 (8418.0 examples/sec; 0.015 sec/batch)
2018-02-01 14:53:16.488108: step 3700, loss = 2.87 (8244.1 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:19.280752: step 3800, loss = 2.72 (4583.5 examples/sec; 0.028 sec/batch)
2018-02-01 14:53:22.103259: step 3900, loss = 2.92 (4535.0 examples/sec; 0.028 sec/batch)
2018-02-01 14:53:24.854576: step 4000, loss = 2.70 (4652.3 examples/sec; 0.028 sec/batch)
2018-02-01 14:53:27.688112: step 4100, loss = 2.78 (4517.3 examples/sec; 0.028 sec/batch)
2018-02-01 14:53:30.360721: step 4200, loss = 2.59 (4789.3 examples/sec; 0.027 sec/batch)
2018-02-01 14:53:33.335398: step 4300, loss = 2.59 (4303.0 examples/sec; 0.030 sec/batch)
2018-02-01 14:53:37.106739: step 4400, loss = 2.77 (3394.0 examples/sec; 0.038 sec/batch)
2018-02-01 14:53:38.683433: step 4500, loss = 2.59 (8118.3 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:40.246619: step 4600, loss = 2.64 (8188.4 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:41.780732: step 4700, loss = 2.48 (8343.6 examples/sec; 0.015 sec/batch)
2018-02-01 14:53:43.370962: step 4800, loss = 2.49 (8049.2 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:44.928604: step 4900, loss = 2.47 (8217.5 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:46.532884: step 5000, loss = 2.42 (7978.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:48.106120: step 5100, loss = 2.43 (8136.1 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:49.636702: step 5200, loss = 2.49 (8362.8 examples/sec; 0.015 sec/batch)
2018-02-01 14:53:51.205396: step 5300, loss = 2.50 (8159.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:52.755529: step 5400, loss = 2.43 (8257.4 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:54.307186: step 5500, loss = 2.37 (8249.2 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:55.862356: step 5600, loss = 2.40 (8230.6 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:57.416007: step 5700, loss = 2.40 (8238.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:53:58.948107: step 5800, loss = 2.41 (8354.6 examples/sec; 0.015 sec/batch)
2018-02-01 14:54:00.473174: step 5900, loss = 2.42 (8393.1 examples/sec; 0.015 sec/batch)
2018-02-01 14:54:02.058331: step 6000, loss = 2.43 (8074.9 examples/sec; 0.016 sec/batch)
2018-02-01 14:54:03.578679: step 6100, loss = 2.40 (8419.1 examples/sec; 0.015 sec/batch)
2018-02-01 14:54:14.263956: step 6200, loss = 2.28 (1197.9 examples/sec; 0.107 sec/batch)
2018-02-01 14:54:16.865920: step 6300, loss = 2.36 (4919.4 examples/sec; 0.026 sec/batch)
2018-02-01 14:54:18.447649: step 6400, loss = 2.32 (8092.4 examples/sec; 0.016 sec/batch)
2018-02-01 14:54:19.991756: step 6500, loss = 2.40 (8289.6 examples/sec; 0.015 sec/batch)
2018-02-01 14:54:21.534859: step 6600, loss = 2.20 (8295.0 examples/sec; 0.015 sec/batch)
2018-02-01 14:54:23.113591: step 6700, loss = 2.31 (8107.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:54:24.700325: step 6800, loss = 2.29 (8066.9 examples/sec; 0.016 sec/batch)
2018-02-01 14:54:26.258481: step 6900, loss = 2.18 (8214.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:54:27.814991: step 7000, loss = 2.22 (8223.5 examples/sec; 0.016 sec/batch)
2018-02-01 14:54:29.416260: step 7100, loss = 2.27 (7993.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:54:30.936804: step 7200, loss = 2.24 (8418.0 examples/sec; 0.015 sec/batch)
2018-02-01 14:54:32.474904: step 7300, loss = 2.29 (8322.0 examples/sec; 0.015 sec/batch)
2018-02-01 14:54:34.047588: step 7400, loss = 2.18 (8139.0 examples/sec; 0.016 sec/batch)
2018-02-01 14:54:37.242789: step 7500, loss = 2.19 (4006.0 examples/sec; 0.032 sec/batch)
2018-02-01 14:54:38.835650: step 7600, loss = 2.18 (8035.9 examples/sec; 0.016 sec/batch)
2018-02-01 14:54:40.329639: step 7700, loss = 2.22 (8567.7 examples/sec; 0.015 sec/batch)
2018-02-01 14:54:41.867730: step 7800, loss = 2.17 (8322.0 examples/sec; 0.015 sec/batch)
2018-02-01 14:54:43.400807: step 7900, loss = 2.17 (8349.2 examples/sec; 0.015 sec/batch)
2018-02-01 14:54:44.940903: step 8000, loss = 2.20 (8311.2 examples/sec; 0.015 sec/batch)
2018-02-01 14:54:46.487058: step 8100, loss = 2.22 (8278.6 examples/sec; 0.015 sec/batch)
2018-02-01 14:54:48.960169: step 8200, loss = 2.28 (5175.7 examples/sec; 0.025 sec/batch)
2018-02-01 14:54:52.061417: step 8300, loss = 2.24 (4127.4 examples/sec; 0.031 sec/batch)
2018-02-01 14:54:54.895454: step 8400, loss = 2.14 (4516.5 examples/sec; 0.028 sec/batch)
2018-02-01 14:54:57.679860: step 8500, loss = 2.19 (4597.0 examples/sec; 0.028 sec/batch)
2018-02-01 14:55:00.091774: step 8600, loss = 2.16 (5307.0 examples/sec; 0.024 sec/batch)
2018-02-01 14:55:02.957897: step 8700, loss = 2.11 (4466.0 examples/sec; 0.029 sec/batch)
2018-02-01 14:55:07.141428: step 8800, loss = 2.13 (3059.6 examples/sec; 0.042 sec/batch)
2018-02-01 14:55:08.678073: step 8900, loss = 2.24 (8329.8 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:10.201123: step 9000, loss = 2.10 (8404.2 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:11.754755: step 9100, loss = 2.28 (8238.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:55:13.308452: step 9200, loss = 2.08 (8238.4 examples/sec; 0.016 sec/batch)
2018-02-01 14:55:14.848548: step 9300, loss = 2.18 (8311.2 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:16.396687: step 9400, loss = 2.12 (8268.0 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:17.940813: step 9500, loss = 2.11 (8289.5 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:19.434299: step 9600, loss = 2.16 (8570.6 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:20.979910: step 9700, loss = 2.18 (8284.2 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:22.478905: step 9800, loss = 2.20 (8536.2 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:24.020848: step 9900, loss = 2.12 (8301.2 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:25.662714: step 10000, loss = 2.10 (7796.0 examples/sec; 0.016 sec/batch)
2018-02-01 14:55:27.205841: step 10100, loss = 2.15 (8294.8 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:28.753967: step 10200, loss = 2.16 (8268.1 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:30.322281: step 10300, loss = 2.21 (8164.2 examples/sec; 0.016 sec/batch)
2018-02-01 14:55:31.842345: step 10400, loss = 2.27 (8417.9 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:33.443648: step 10500, loss = 2.09 (7993.5 examples/sec; 0.016 sec/batch)
2018-02-01 14:55:43.475745: step 10600, loss = 2.10 (1275.9 examples/sec; 0.100 sec/batch)
2018-02-01 14:55:46.329346: step 10700, loss = 2.19 (4485.6 examples/sec; 0.029 sec/batch)
2018-02-01 14:55:48.051427: step 10800, loss = 2.15 (7432.9 examples/sec; 0.017 sec/batch)
2018-02-01 14:55:49.597038: step 10900, loss = 2.14 (8281.5 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:51.147673: step 11000, loss = 2.16 (8254.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:55:52.670231: step 11100, loss = 2.00 (8406.9 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:54.200300: step 11200, loss = 2.10 (8365.6 examples/sec; 0.015 sec/batch)
2018-02-01 14:55:55.751927: step 11300, loss = 2.20 (8249.4 examples/sec; 0.016 sec/batch)
2018-02-01 14:55:57.317113: step 11400, loss = 2.09 (8177.9 examples/sec; 0.016 sec/batch)
2018-02-01 14:55:58.886798: step 11500, loss = 2.15 (8154.5 examples/sec; 0.016 sec/batch)
2018-02-01 14:56:00.463957: step 11600, loss = 2.21 (8115.9 examples/sec; 0.016 sec/batch)
2018-02-01 14:56:02.034134: step 11700, loss = 2.11 (8151.9 examples/sec; 0.016 sec/batch)
2018-02-01 14:56:03.584758: step 11800, loss = 2.13 (8254.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:56:06.770862: step 11900, loss = 2.09 (4017.4 examples/sec; 0.032 sec/batch)
2018-02-01 14:56:08.322528: step 12000, loss = 2.13 (8249.2 examples/sec; 0.016 sec/batch)
2018-02-01 14:56:09.829035: step 12100, loss = 2.13 (8496.5 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:11.396208: step 12200, loss = 2.12 (8167.6 examples/sec; 0.016 sec/batch)
2018-02-01 14:56:12.944821: step 12300, loss = 2.12 (8265.5 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:14.481918: step 12400, loss = 2.19 (8327.4 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:16.020519: step 12500, loss = 2.17 (8319.2 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:17.627794: step 12600, loss = 2.16 (7963.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:56:20.329109: step 12700, loss = 1.98 (4738.4 examples/sec; 0.027 sec/batch)
2018-02-01 14:56:23.350144: step 12800, loss = 2.12 (4237.0 examples/sec; 0.030 sec/batch)
2018-02-01 14:56:26.180903: step 12900, loss = 2.08 (4521.8 examples/sec; 0.028 sec/batch)
2018-02-01 14:56:29.013023: step 13000, loss = 2.05 (4519.6 examples/sec; 0.028 sec/batch)
2018-02-01 14:56:31.829426: step 13100, loss = 2.10 (4544.8 examples/sec; 0.028 sec/batch)
2018-02-01 14:56:34.705101: step 13200, loss = 2.09 (4451.1 examples/sec; 0.029 sec/batch)
2018-02-01 14:56:38.376718: step 13300, loss = 2.15 (3486.2 examples/sec; 0.037 sec/batch)
2018-02-01 14:56:39.922849: step 13400, loss = 2.17 (8278.7 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:41.437368: step 13500, loss = 2.16 (8451.5 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:42.956408: step 13600, loss = 2.13 (8426.4 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:44.486144: step 13700, loss = 2.13 (8367.5 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:46.040292: step 13800, loss = 2.08 (8236.0 examples/sec; 0.016 sec/batch)
2018-02-01 14:56:47.545796: step 13900, loss = 2.15 (8502.1 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:49.077870: step 14000, loss = 2.23 (8354.7 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:50.614971: step 14100, loss = 2.14 (8327.4 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:52.142102: step 14200, loss = 2.06 (8381.7 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:53.651115: step 14300, loss = 2.13 (8482.4 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:55.168154: step 14400, loss = 2.13 (8437.5 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:56.723806: step 14500, loss = 2.12 (8228.1 examples/sec; 0.016 sec/batch)
2018-02-01 14:56:58.258889: step 14600, loss = 2.09 (8338.3 examples/sec; 0.015 sec/batch)
2018-02-01 14:56:59.815041: step 14700, loss = 2.11 (8225.4 examples/sec; 0.016 sec/batch)
2018-02-01 14:57:01.386220: step 14800, loss = 2.21 (8146.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:57:02.930341: step 14900, loss = 2.15 (8289.5 examples/sec; 0.015 sec/batch)
2018-02-01 14:57:04.456430: step 15000, loss = 2.05 (8387.5 examples/sec; 0.015 sec/batch)
2018-02-01 14:57:13.953137: step 15100, loss = 2.13 (1347.8 examples/sec; 0.095 sec/batch)
2018-02-01 14:57:16.647813: step 15200, loss = 2.11 (4750.1 examples/sec; 0.027 sec/batch)
2018-02-01 14:57:19.036685: step 15300, loss = 2.10 (5358.2 examples/sec; 0.024 sec/batch)
2018-02-01 14:57:20.566273: step 15400, loss = 2.16 (8368.3 examples/sec; 0.015 sec/batch)
2018-02-01 14:57:22.103876: step 15500, loss = 2.14 (8324.6 examples/sec; 0.015 sec/batch)
2018-02-01 14:57:23.652449: step 15600, loss = 2.10 (8265.7 examples/sec; 0.015 sec/batch)
2018-02-01 14:57:25.175011: step 15700, loss = 2.10 (8406.9 examples/sec; 0.015 sec/batch)
2018-02-01 14:57:26.673998: step 15800, loss = 2.01 (8539.1 examples/sec; 0.015 sec/batch)
2018-02-01 14:57:28.209595: step 15900, loss = 2.04 (8335.5 examples/sec; 0.015 sec/batch)
2018-02-01 14:57:29.757725: step 16000, loss = 2.06 (8268.0 examples/sec; 0.015 sec/batch)
2018-02-01 14:57:31.268272: step 16100, loss = 1.99 (8473.7 examples/sec; 0.015 sec/batch)
2018-02-01 14:57:32.779810: step 16200, loss = 2.10 (8468.2 examples/sec; 0.015 sec/batch)
2018-02-01 14:57:34.281304: step 16300, loss = 2.08 (8524.8 examples/sec; 0.015 sec/batch)
2018-02-01 14:57:37.561607: step 16400, loss = 2.09 (3902.7 examples/sec; 0.033 sec/batch)
2018-02-01 14:57:39.176618: step 16500, loss = 2.05 (7923.2 examples/sec; 0.016 sec/batch)
2018-02-01 14:57:40.889674: step 16600, loss = 2.09 (7472.0 examples/sec; 0.017 sec/batch)
2018-02-01 14:57:42.583680: step 16700, loss = 2.05 (7556.1 examples/sec; 0.017 sec/batch)
2018-02-01 14:57:44.259140: step 16800, loss = 2.17 (7639.7 examples/sec; 0.017 sec/batch)
2018-02-01 14:57:46.003524: step 16900, loss = 2.08 (7337.8 examples/sec; 0.017 sec/batch)
2018-02-01 14:57:47.626339: step 17000, loss = 2.13 (7887.5 examples/sec; 0.016 sec/batch)
2018-02-01 14:57:49.220590: step 17100, loss = 2.06 (8028.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:57:52.081653: step 17200, loss = 2.05 (4473.9 examples/sec; 0.029 sec/batch)
2018-02-01 14:57:54.977962: step 17300, loss = 2.13 (4419.4 examples/sec; 0.029 sec/batch)
2018-02-01 14:57:57.836777: step 17400, loss = 2.20 (4477.4 examples/sec; 0.029 sec/batch)
2018-02-01 14:58:00.496341: step 17500, loss = 2.10 (4812.8 examples/sec; 0.027 sec/batch)
2018-02-01 14:58:03.350476: step 17600, loss = 2.08 (4484.7 examples/sec; 0.029 sec/batch)
2018-02-01 14:58:08.410519: step 17700, loss = 2.13 (2529.6 examples/sec; 0.051 sec/batch)
2018-02-01 14:58:09.977687: step 17800, loss = 2.06 (8167.6 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:11.537837: step 17900, loss = 2.21 (8204.3 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:13.095981: step 18000, loss = 2.12 (8214.9 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:14.671170: step 18100, loss = 2.05 (8126.0 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:16.247874: step 18200, loss = 2.19 (8118.2 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:17.829591: step 18300, loss = 2.02 (8092.5 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:19.413805: step 18400, loss = 2.21 (8079.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:20.994008: step 18500, loss = 2.19 (8100.2 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:22.599277: step 18600, loss = 2.17 (7973.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:24.175469: step 18700, loss = 2.07 (8120.8 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:25.721603: step 18800, loss = 2.14 (8278.7 examples/sec; 0.015 sec/batch)
2018-02-01 14:58:27.248175: step 18900, loss = 2.06 (8384.8 examples/sec; 0.015 sec/batch)
2018-02-01 14:58:28.785263: step 19000, loss = 2.08 (8327.4 examples/sec; 0.015 sec/batch)
2018-02-01 14:58:30.368499: step 19100, loss = 2.07 (8084.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:31.920126: step 19200, loss = 2.13 (8249.4 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:33.471752: step 19300, loss = 2.09 (8249.4 examples/sec; 0.016 sec/batch)
2018-02-01 14:58:37.229108: step 19400, loss = 2.05 (3406.7 examples/sec; 0.038 sec/batch)
2018-02-01 14:58:40.085336: step 19500, loss = 2.19 (4481.4 examples/sec; 0.029 sec/batch)
2018-02-01 14:58:43.347804: step 19600, loss = 2.11 (3923.4 examples/sec; 0.033 sec/batch)
2018-02-01 14:58:46.450125: step 19700, loss = 2.11 (4125.9 examples/sec; 0.031 sec/batch)
2018-02-01 14:58:49.422530: step 19800, loss = 2.05 (4306.3 examples/sec; 0.030 sec/batch)
2018-02-01 14:58:52.483268: step 19900, loss = 2.04 (4182.0 examples/sec; 0.031 sec/batch)
2018-02-01 14:58:55.546039: step 20000, loss = 2.18 (4179.2 examples/sec; 0.031 sec/batch)
2018-02-01 14:58:57.095977: step 20100, loss = 2.08 (8258.4 examples/sec; 0.015 sec/batch)
2018-02-01 14:58:58.544684: step 20200, loss = 2.10 (8835.5 examples/sec; 0.014 sec/batch)
2018-02-01 14:59:00.354859: step 20300, loss = 2.27 (7071.1 examples/sec; 0.018 sec/batch)
2018-02-01 14:59:02.118538: step 20400, loss = 2.04 (7257.6 examples/sec; 0.018 sec/batch)
2018-02-01 14:59:03.812043: step 20500, loss = 2.04 (7558.3 examples/sec; 0.017 sec/batch)
2018-02-01 14:59:07.164309: step 20600, loss = 2.09 (3818.3 examples/sec; 0.034 sec/batch)
2018-02-01 14:59:08.717440: step 20700, loss = 2.11 (8241.4 examples/sec; 0.016 sec/batch)
2018-02-01 14:59:10.286613: step 20800, loss = 2.16 (8157.2 examples/sec; 0.016 sec/batch)
2018-02-01 14:59:11.831722: step 20900, loss = 2.11 (8284.2 examples/sec; 0.015 sec/batch)
2018-02-01 14:59:13.401899: step 21000, loss = 2.12 (8152.0 examples/sec; 0.016 sec/batch)
2018-02-01 14:59:14.959040: step 21100, loss = 2.14 (8220.2 examples/sec; 0.016 sec/batch)
2018-02-01 14:59:16.516181: step 21200, loss = 2.02 (8220.2 examples/sec; 0.016 sec/batch)
2018-02-01 14:59:18.066304: step 21300, loss = 2.09 (8257.4 examples/sec; 0.016 sec/batch)
2018-02-01 14:59:19.645504: step 21400, loss = 2.06 (8105.4 examples/sec; 0.016 sec/batch)
2018-02-01 14:59:21.233728: step 21500, loss = 2.17 (8059.3 examples/sec; 0.016 sec/batch)
2018-02-01 14:59:22.773824: step 21600, loss = 2.06 (8311.2 examples/sec; 0.015 sec/batch)
2018-02-01 14:59:24.325952: step 21700, loss = 2.16 (8246.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:59:25.919036: step 21800, loss = 2.14 (8034.7 examples/sec; 0.016 sec/batch)
2018-02-01 14:59:28.255008: step 21900, loss = 2.12 (5479.5 examples/sec; 0.023 sec/batch)
2018-02-01 14:59:30.920590: step 22000, loss = 2.12 (4802.0 examples/sec; 0.027 sec/batch)
2018-02-01 14:59:33.761246: step 22100, loss = 2.12 (4506.0 examples/sec; 0.028 sec/batch)
2018-02-01 14:59:41.647858: step 22200, loss = 2.18 (1623.0 examples/sec; 0.079 sec/batch)
2018-02-01 14:59:43.111528: step 22300, loss = 2.08 (8745.1 examples/sec; 0.015 sec/batch)
2018-02-01 14:59:44.560095: step 22400, loss = 2.14 (8836.3 examples/sec; 0.014 sec/batch)
2018-02-01 14:59:46.000184: step 22500, loss = 2.04 (8888.3 examples/sec; 0.014 sec/batch)
2018-02-01 14:59:47.467459: step 22600, loss = 2.21 (8723.7 examples/sec; 0.015 sec/batch)
2018-02-01 14:59:48.941767: step 22700, loss = 2.05 (8682.0 examples/sec; 0.015 sec/batch)
2018-02-01 14:59:50.368256: step 22800, loss = 2.14 (8973.1 examples/sec; 0.014 sec/batch)
2018-02-01 14:59:51.814509: step 22900, loss = 2.12 (8850.5 examples/sec; 0.014 sec/batch)
2018-02-01 14:59:53.281618: step 23000, loss = 2.11 (8724.6 examples/sec; 0.015 sec/batch)
2018-02-01 14:59:54.711011: step 23100, loss = 2.14 (8954.9 examples/sec; 0.014 sec/batch)
2018-02-01 14:59:56.172968: step 23200, loss = 2.06 (8755.4 examples/sec; 0.015 sec/batch)
2018-02-01 14:59:57.606322: step 23300, loss = 2.15 (8930.1 examples/sec; 0.014 sec/batch)
2018-02-01 14:59:59.049577: step 23400, loss = 2.14 (8868.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:00:00.523335: step 23500, loss = 2.02 (8685.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:01.970616: step 23600, loss = 1.99 (8844.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:00:03.402229: step 23700, loss = 2.12 (8941.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:00:04.841875: step 23800, loss = 2.06 (8891.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:00:07.826114: step 23900, loss = 2.09 (4289.2 examples/sec; 0.030 sec/batch)
2018-02-01 15:00:09.278182: step 24000, loss = 2.12 (8815.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:10.728728: step 24100, loss = 2.05 (8824.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:13.643030: step 24200, loss = 2.01 (4392.1 examples/sec; 0.029 sec/batch)
2018-02-01 15:00:16.349870: step 24300, loss = 2.05 (4728.8 examples/sec; 0.027 sec/batch)
2018-02-01 15:00:19.317797: step 24400, loss = 2.15 (4312.8 examples/sec; 0.030 sec/batch)
2018-02-01 15:00:22.195297: step 24500, loss = 2.10 (4448.3 examples/sec; 0.029 sec/batch)
2018-02-01 15:00:24.674096: step 24600, loss = 2.06 (5163.8 examples/sec; 0.025 sec/batch)
2018-02-01 15:00:27.312377: step 24700, loss = 2.03 (4851.6 examples/sec; 0.026 sec/batch)
2018-02-01 15:00:28.784121: step 24800, loss = 2.10 (8697.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:30.239143: step 24900, loss = 2.07 (8797.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:31.679155: step 25000, loss = 2.15 (8888.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:00:33.146150: step 25100, loss = 2.16 (8725.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:34.588108: step 25200, loss = 2.07 (8876.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:00:37.548662: step 25300, loss = 2.29 (4323.5 examples/sec; 0.030 sec/batch)
2018-02-01 15:00:39.043983: step 25400, loss = 2.01 (8560.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:40.499267: step 25500, loss = 2.12 (8795.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:41.948790: step 25600, loss = 2.07 (8830.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:00:43.438865: step 25700, loss = 2.09 (8590.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:44.894902: step 25800, loss = 2.10 (8791.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:46.358691: step 25900, loss = 2.15 (8744.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:47.793389: step 26000, loss = 2.07 (8921.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:00:49.255504: step 26100, loss = 2.02 (8754.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:50.710472: step 26200, loss = 2.08 (8797.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:52.160013: step 26300, loss = 2.16 (8830.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:00:53.583755: step 26400, loss = 2.09 (8990.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:00:55.015058: step 26500, loss = 2.21 (8942.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:00:56.537010: step 26600, loss = 2.11 (8410.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:00:58.049761: step 26700, loss = 2.16 (8461.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:00.845803: step 26800, loss = 2.09 (4577.9 examples/sec; 0.028 sec/batch)
2018-02-01 15:01:03.475144: step 26900, loss = 2.07 (4868.1 examples/sec; 0.026 sec/batch)
2018-02-01 15:01:12.249859: step 27000, loss = 2.05 (1458.7 examples/sec; 0.088 sec/batch)
2018-02-01 15:01:13.728681: step 27100, loss = 2.01 (8655.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:15.178249: step 27200, loss = 2.15 (8830.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:01:16.658832: step 27300, loss = 2.12 (8645.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:18.119343: step 27400, loss = 2.10 (8764.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:19.557275: step 27500, loss = 2.04 (8901.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:01:21.020447: step 27600, loss = 2.05 (8748.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:22.483592: step 27700, loss = 2.06 (8748.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:23.972249: step 27800, loss = 2.12 (8598.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:25.406142: step 27900, loss = 2.13 (8926.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:01:26.857591: step 28000, loss = 2.10 (8818.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:28.319845: step 28100, loss = 2.11 (8753.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:29.765172: step 28200, loss = 2.18 (8856.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:01:31.235044: step 28300, loss = 2.09 (8708.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:32.683039: step 28400, loss = 2.12 (8839.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:01:34.144858: step 28500, loss = 2.11 (8756.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:37.156539: step 28600, loss = 1.95 (4250.1 examples/sec; 0.030 sec/batch)
2018-02-01 15:01:38.612141: step 28700, loss = 2.07 (8793.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:40.086696: step 28800, loss = 2.07 (8680.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:01:41.706363: step 28900, loss = 2.06 (7902.9 examples/sec; 0.016 sec/batch)
2018-02-01 15:01:44.494684: step 29000, loss = 2.03 (4590.6 examples/sec; 0.028 sec/batch)
2018-02-01 15:01:47.250803: step 29100, loss = 2.17 (4644.2 examples/sec; 0.028 sec/batch)
2018-02-01 15:01:50.100580: step 29200, loss = 2.05 (4491.6 examples/sec; 0.028 sec/batch)
2018-02-01 15:01:53.070191: step 29300, loss = 2.05 (4310.3 examples/sec; 0.030 sec/batch)
2018-02-01 15:01:55.677961: step 29400, loss = 2.10 (4908.4 examples/sec; 0.026 sec/batch)
2018-02-01 15:01:58.026563: step 29500, loss = 2.07 (5450.1 examples/sec; 0.023 sec/batch)
2018-02-01 15:01:59.510393: step 29600, loss = 2.14 (8626.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:00.967879: step 29700, loss = 2.08 (8782.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:02.417035: step 29800, loss = 2.19 (8832.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:02:03.864816: step 29900, loss = 2.15 (8841.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:02:06.927118: step 30000, loss = 2.11 (4179.9 examples/sec; 0.031 sec/batch)
2018-02-01 15:02:08.412329: step 30100, loss = 2.05 (8618.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:09.859881: step 30200, loss = 2.18 (8842.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:02:11.314768: step 30300, loss = 2.16 (8797.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:12.751500: step 30400, loss = 2.10 (8909.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:02:14.194872: step 30500, loss = 2.05 (8868.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:02:15.645234: step 30600, loss = 2.10 (8825.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:17.099100: step 30700, loss = 2.07 (8804.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:18.553778: step 30800, loss = 2.13 (8799.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:20.008254: step 30900, loss = 2.08 (8800.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:21.459152: step 31000, loss = 2.07 (8822.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:22.917305: step 31100, loss = 2.07 (8778.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:24.354126: step 31200, loss = 2.06 (8908.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:02:25.806825: step 31300, loss = 2.21 (8811.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:27.235762: step 31400, loss = 2.07 (8957.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:02:28.692154: step 31500, loss = 2.16 (8788.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:31.559127: step 31600, loss = 2.17 (4464.6 examples/sec; 0.029 sec/batch)
2018-02-01 15:02:34.349765: step 31700, loss = 2.06 (4586.8 examples/sec; 0.028 sec/batch)
2018-02-01 15:02:43.091434: step 31800, loss = 2.07 (1464.3 examples/sec; 0.087 sec/batch)
2018-02-01 15:02:44.557181: step 31900, loss = 2.12 (8732.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:46.014519: step 32000, loss = 2.28 (8783.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:47.568109: step 32100, loss = 2.11 (8239.0 examples/sec; 0.016 sec/batch)
2018-02-01 15:02:49.008021: step 32200, loss = 2.06 (8889.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:02:50.455275: step 32300, loss = 2.21 (8844.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:02:51.914498: step 32400, loss = 2.10 (8771.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:53.390024: step 32500, loss = 2.04 (8674.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:54.823846: step 32600, loss = 2.04 (8927.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:02:56.292464: step 32700, loss = 2.10 (8715.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:57.742906: step 32800, loss = 2.11 (8824.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:02:59.176826: step 32900, loss = 2.06 (8926.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:03:00.656838: step 33000, loss = 2.13 (8648.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:02.100016: step 33100, loss = 2.09 (8869.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:03:03.537599: step 33200, loss = 2.00 (8903.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:03:04.996952: step 33300, loss = 2.07 (8771.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:08.015572: step 33400, loss = 2.10 (4240.3 examples/sec; 0.030 sec/batch)
2018-02-01 15:03:09.458731: step 33500, loss = 2.03 (8869.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:03:10.912950: step 33600, loss = 2.26 (8802.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:12.942952: step 33700, loss = 2.10 (6305.4 examples/sec; 0.020 sec/batch)
2018-02-01 15:03:15.569194: step 33800, loss = 2.04 (4873.9 examples/sec; 0.026 sec/batch)
2018-02-01 15:03:18.417382: step 33900, loss = 2.11 (4494.1 examples/sec; 0.028 sec/batch)
2018-02-01 15:03:20.994091: step 34000, loss = 2.12 (4967.6 examples/sec; 0.026 sec/batch)
2018-02-01 15:03:23.534881: step 34100, loss = 2.07 (5037.8 examples/sec; 0.025 sec/batch)
2018-02-01 15:03:26.204087: step 34200, loss = 2.03 (4795.4 examples/sec; 0.027 sec/batch)
2018-02-01 15:03:28.771257: step 34300, loss = 2.14 (4986.0 examples/sec; 0.026 sec/batch)
2018-02-01 15:03:30.314433: step 34400, loss = 2.10 (8294.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:31.761795: step 34500, loss = 2.05 (8843.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:03:33.222441: step 34600, loss = 2.15 (8763.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:34.697008: step 34700, loss = 2.10 (8680.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:37.698317: step 34800, loss = 2.08 (4264.8 examples/sec; 0.030 sec/batch)
2018-02-01 15:03:39.176498: step 34900, loss = 2.14 (8659.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:40.617871: step 35000, loss = 2.11 (8880.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:03:42.061328: step 35100, loss = 2.19 (8867.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:03:43.551691: step 35200, loss = 2.01 (8588.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:45.077010: step 35300, loss = 2.05 (8391.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:46.549265: step 35400, loss = 2.16 (8694.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:48.036366: step 35500, loss = 2.05 (8607.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:49.515508: step 35600, loss = 2.07 (8653.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:50.975366: step 35700, loss = 2.04 (8768.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:52.419104: step 35800, loss = 2.05 (8865.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:03:53.878279: step 35900, loss = 2.13 (8772.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:55.336866: step 36000, loss = 2.14 (8775.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:56.784277: step 36100, loss = 2.10 (8843.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:03:58.249817: step 36200, loss = 2.10 (8734.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:03:59.689556: step 36300, loss = 2.16 (8890.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:04:02.390715: step 36400, loss = 2.11 (4738.7 examples/sec; 0.027 sec/batch)
2018-02-01 15:04:04.837022: step 36500, loss = 2.17 (5232.4 examples/sec; 0.024 sec/batch)
2018-02-01 15:04:13.951390: step 36600, loss = 2.14 (1404.4 examples/sec; 0.091 sec/batch)
2018-02-01 15:04:15.393105: step 36700, loss = 2.01 (8878.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:04:16.863649: step 36800, loss = 2.20 (8704.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:04:18.319582: step 36900, loss = 2.03 (8791.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:04:19.772697: step 37000, loss = 2.04 (8808.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:04:21.232727: step 37100, loss = 2.05 (8766.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:04:22.710160: step 37200, loss = 2.06 (8663.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:04:24.145930: step 37300, loss = 2.04 (8915.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:04:25.595022: step 37400, loss = 2.07 (8833.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:04:27.037323: step 37500, loss = 2.10 (8874.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:04:28.500011: step 37600, loss = 2.01 (8751.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:04:29.986395: step 37700, loss = 2.22 (8611.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:04:31.441956: step 37800, loss = 2.06 (8793.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:04:32.905265: step 37900, loss = 2.14 (8747.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:04:34.343198: step 38000, loss = 2.15 (8901.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:04:37.420681: step 38100, loss = 2.13 (4159.2 examples/sec; 0.031 sec/batch)
2018-02-01 15:04:38.883031: step 38200, loss = 2.13 (8753.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:04:40.331172: step 38300, loss = 2.18 (8838.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:04:41.806750: step 38400, loss = 2.03 (8674.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:04:43.728409: step 38500, loss = 2.14 (6660.9 examples/sec; 0.019 sec/batch)
2018-02-01 15:04:46.375869: step 38600, loss = 2.07 (4834.8 examples/sec; 0.026 sec/batch)
2018-02-01 15:04:49.110574: step 38700, loss = 2.14 (4680.6 examples/sec; 0.027 sec/batch)
2018-02-01 15:04:51.851339: step 38800, loss = 2.14 (4670.2 examples/sec; 0.027 sec/batch)
2018-02-01 15:04:54.561315: step 38900, loss = 2.04 (4723.3 examples/sec; 0.027 sec/batch)
2018-02-01 15:04:57.090143: step 39000, loss = 2.12 (5061.6 examples/sec; 0.025 sec/batch)
2018-02-01 15:04:59.557483: step 39100, loss = 2.07 (5187.8 examples/sec; 0.025 sec/batch)
2018-02-01 15:05:01.175609: step 39200, loss = 2.06 (7910.4 examples/sec; 0.016 sec/batch)
2018-02-01 15:05:02.611715: step 39300, loss = 2.15 (8913.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:04.121072: step 39400, loss = 2.01 (8480.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:05:07.129209: step 39500, loss = 2.05 (4255.1 examples/sec; 0.030 sec/batch)
2018-02-01 15:05:08.589796: step 39600, loss = 2.05 (8763.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:05:10.022816: step 39700, loss = 2.08 (8932.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:11.492083: step 39800, loss = 2.10 (8711.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:05:12.923028: step 39900, loss = 2.06 (8945.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:14.360359: step 40000, loss = 2.13 (8905.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:15.818203: step 40100, loss = 2.07 (8780.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:05:17.254442: step 40200, loss = 2.09 (8912.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:18.696712: step 40300, loss = 2.03 (8874.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:20.121108: step 40400, loss = 2.01 (8986.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:21.546052: step 40500, loss = 2.09 (8982.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:23.000950: step 40600, loss = 2.14 (8797.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:05:24.461183: step 40700, loss = 2.11 (8765.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:05:25.903870: step 40800, loss = 2.05 (8872.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:27.365330: step 40900, loss = 1.99 (8758.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:05:28.807727: step 41000, loss = 2.08 (8874.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:30.277966: step 41100, loss = 2.09 (8706.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:05:32.748881: step 41200, loss = 1.99 (5180.3 examples/sec; 0.025 sec/batch)
2018-02-01 15:05:43.067312: step 41300, loss = 2.11 (1240.5 examples/sec; 0.103 sec/batch)
2018-02-01 15:05:44.513342: step 41400, loss = 2.15 (8851.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:45.985368: step 41500, loss = 2.11 (8695.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:05:47.425688: step 41600, loss = 2.10 (8886.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:48.886183: step 41700, loss = 2.12 (8764.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:05:50.324517: step 41800, loss = 1.99 (8899.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:51.770565: step 41900, loss = 2.25 (8851.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:53.232539: step 42000, loss = 2.14 (8755.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:05:54.681663: step 42100, loss = 2.12 (8832.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:56.156970: step 42200, loss = 2.07 (8676.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:05:57.600629: step 42300, loss = 2.08 (8866.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:05:59.058466: step 42400, loss = 1.98 (8780.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:00.502375: step 42500, loss = 2.05 (8864.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:06:01.961137: step 42600, loss = 2.07 (8774.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:03.421639: step 42700, loss = 2.00 (8764.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:04.877375: step 42800, loss = 2.07 (8792.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:07.915415: step 42900, loss = 2.05 (4213.2 examples/sec; 0.030 sec/batch)
2018-02-01 15:06:09.372487: step 43000, loss = 2.17 (8784.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:10.820217: step 43100, loss = 1.96 (8841.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:06:12.245331: step 43200, loss = 2.10 (8981.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:06:14.144862: step 43300, loss = 2.07 (6738.5 examples/sec; 0.019 sec/batch)
2018-02-01 15:06:17.057678: step 43400, loss = 2.06 (4394.4 examples/sec; 0.029 sec/batch)
2018-02-01 15:06:19.996892: step 43500, loss = 2.07 (4354.9 examples/sec; 0.029 sec/batch)
2018-02-01 15:06:22.683406: step 43600, loss = 2.08 (4764.5 examples/sec; 0.027 sec/batch)
2018-02-01 15:06:25.442976: step 43700, loss = 2.21 (4638.4 examples/sec; 0.028 sec/batch)
2018-02-01 15:06:28.253481: step 43800, loss = 2.06 (4554.3 examples/sec; 0.028 sec/batch)
2018-02-01 15:06:30.239229: step 43900, loss = 2.05 (6445.9 examples/sec; 0.020 sec/batch)
2018-02-01 15:06:31.662144: step 44000, loss = 2.08 (8995.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:06:33.123945: step 44100, loss = 2.10 (8756.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:34.556675: step 44200, loss = 2.04 (8934.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:06:37.608907: step 44300, loss = 2.16 (4193.7 examples/sec; 0.031 sec/batch)
2018-02-01 15:06:39.077609: step 44400, loss = 2.02 (8715.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:40.540854: step 44500, loss = 2.12 (8747.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:41.983261: step 44600, loss = 2.17 (8874.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:06:43.434123: step 44700, loss = 2.09 (8822.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:44.867990: step 44800, loss = 2.03 (8926.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:06:46.315076: step 44900, loss = 2.09 (8845.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:06:47.762100: step 45000, loss = 2.02 (8845.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:06:49.243022: step 45100, loss = 2.11 (8643.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:50.679751: step 45200, loss = 2.09 (8909.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:06:52.124566: step 45300, loss = 2.05 (8859.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:06:53.576997: step 45400, loss = 2.04 (8812.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:55.006385: step 45500, loss = 2.08 (8954.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:06:56.468512: step 45600, loss = 2.09 (8754.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:57.929703: step 45700, loss = 2.04 (8760.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:06:59.402634: step 45800, loss = 2.04 (8690.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:07:01.629236: step 45900, loss = 2.15 (5748.7 examples/sec; 0.022 sec/batch)
2018-02-01 15:07:04.414592: step 46000, loss = 2.10 (4595.5 examples/sec; 0.028 sec/batch)
2018-02-01 15:07:13.609273: step 46100, loss = 2.15 (1392.1 examples/sec; 0.092 sec/batch)
2018-02-01 15:07:15.051824: step 46200, loss = 2.11 (8873.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:07:16.500352: step 46300, loss = 2.14 (8836.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:07:17.935979: step 46400, loss = 2.00 (8916.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:07:19.403201: step 46500, loss = 1.98 (8724.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:07:20.861272: step 46600, loss = 2.00 (8778.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:07:22.314071: step 46700, loss = 2.04 (8810.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:07:23.754558: step 46800, loss = 2.07 (8885.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:07:25.198750: step 46900, loss = 2.06 (8863.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:07:26.669655: step 47000, loss = 2.12 (8702.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:07:28.124763: step 47100, loss = 2.15 (8796.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:07:29.605561: step 47200, loss = 2.12 (8644.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:07:31.070654: step 47300, loss = 2.12 (8736.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:07:32.520087: step 47400, loss = 2.06 (8831.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:07:33.963856: step 47500, loss = 2.12 (8865.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:07:36.923761: step 47600, loss = 2.07 (4324.5 examples/sec; 0.030 sec/batch)
2018-02-01 15:07:38.367612: step 47700, loss = 2.01 (8865.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:07:39.823860: step 47800, loss = 2.07 (8789.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:07:41.277394: step 47900, loss = 1.97 (8806.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:07:43.020408: step 48000, loss = 2.05 (7343.6 examples/sec; 0.017 sec/batch)
2018-02-01 15:07:45.700220: step 48100, loss = 2.05 (4776.5 examples/sec; 0.027 sec/batch)
2018-02-01 15:07:48.590818: step 48200, loss = 2.15 (4428.1 examples/sec; 0.029 sec/batch)
2018-02-01 15:07:51.106926: step 48300, loss = 2.09 (5087.2 examples/sec; 0.025 sec/batch)
2018-02-01 15:07:54.071480: step 48400, loss = 2.18 (4317.7 examples/sec; 0.030 sec/batch)
2018-02-01 15:07:56.632027: step 48500, loss = 2.02 (4998.9 examples/sec; 0.026 sec/batch)
2018-02-01 15:07:59.178434: step 48600, loss = 2.17 (5026.7 examples/sec; 0.025 sec/batch)
2018-02-01 15:08:00.627264: step 48700, loss = 2.08 (8834.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:02.096805: step 48800, loss = 2.10 (8710.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:03.536024: step 48900, loss = 2.09 (8893.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:04.982873: step 49000, loss = 2.06 (8846.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:08.057038: step 49100, loss = 2.09 (4163.7 examples/sec; 0.031 sec/batch)
2018-02-01 15:08:09.518675: step 49200, loss = 2.10 (8757.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:10.965430: step 49300, loss = 2.05 (8847.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:12.392580: step 49400, loss = 2.06 (8968.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:13.822459: step 49500, loss = 2.07 (8951.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:15.282427: step 49600, loss = 2.13 (8767.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:16.724439: step 49700, loss = 2.18 (8876.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:18.154239: step 49800, loss = 2.08 (8952.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:19.615360: step 49900, loss = 2.10 (8760.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:21.053288: step 50000, loss = 2.09 (8901.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:22.503649: step 50100, loss = 2.10 (8825.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:23.967600: step 50200, loss = 2.06 (8743.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:25.395906: step 50300, loss = 2.24 (8961.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:26.849608: step 50400, loss = 2.09 (8805.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:28.299820: step 50500, loss = 2.06 (8826.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:29.774804: step 50600, loss = 2.12 (8678.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:32.495279: step 50700, loss = 2.15 (4705.1 examples/sec; 0.027 sec/batch)
2018-02-01 15:08:35.228866: step 50800, loss = 2.09 (4682.5 examples/sec; 0.027 sec/batch)
2018-02-01 15:08:43.983154: step 50900, loss = 2.14 (1462.1 examples/sec; 0.088 sec/batch)
2018-02-01 15:08:45.433431: step 51000, loss = 2.10 (8825.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:46.886000: step 51100, loss = 2.11 (8812.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:48.366234: step 51200, loss = 2.05 (8647.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:49.814507: step 51300, loss = 2.08 (8838.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:51.270313: step 51400, loss = 2.08 (8792.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:52.711156: step 51500, loss = 2.18 (8883.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:54.169168: step 51600, loss = 2.10 (8779.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:55.618560: step 51700, loss = 2.08 (8831.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:57.082177: step 51800, loss = 2.12 (8745.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:08:58.527641: step 51900, loss = 2.07 (8855.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:08:59.997275: step 52000, loss = 2.06 (8709.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:01.445889: step 52100, loss = 2.07 (8836.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:09:02.898831: step 52200, loss = 1.98 (8809.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:04.352226: step 52300, loss = 2.02 (8807.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:07.350220: step 52400, loss = 2.08 (4269.5 examples/sec; 0.030 sec/batch)
2018-02-01 15:09:08.805019: step 52500, loss = 2.08 (8798.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:10.257319: step 52600, loss = 2.03 (8813.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:11.726334: step 52700, loss = 2.14 (8713.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:13.747796: step 52800, loss = 1.96 (6332.0 examples/sec; 0.020 sec/batch)
2018-02-01 15:09:16.323618: step 52900, loss = 2.08 (4969.3 examples/sec; 0.026 sec/batch)
2018-02-01 15:09:19.065238: step 53000, loss = 2.17 (4668.8 examples/sec; 0.027 sec/batch)
2018-02-01 15:09:21.621024: step 53100, loss = 2.21 (5008.2 examples/sec; 0.026 sec/batch)
2018-02-01 15:09:24.330117: step 53200, loss = 2.14 (4724.8 examples/sec; 0.027 sec/batch)
2018-02-01 15:09:27.490272: step 53300, loss = 2.03 (4050.4 examples/sec; 0.032 sec/batch)
2018-02-01 15:09:29.760720: step 53400, loss = 2.06 (5637.7 examples/sec; 0.023 sec/batch)
2018-02-01 15:09:31.228793: step 53500, loss = 2.02 (8718.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:32.681533: step 53600, loss = 2.12 (8810.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:34.150606: step 53700, loss = 2.07 (8713.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:37.145710: step 53800, loss = 2.18 (4273.6 examples/sec; 0.030 sec/batch)
2018-02-01 15:09:38.610134: step 53900, loss = 2.11 (8740.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:40.074650: step 54000, loss = 2.07 (8740.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:41.516535: step 54100, loss = 2.20 (8877.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:09:42.961385: step 54200, loss = 2.02 (8859.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:09:44.439682: step 54300, loss = 2.12 (8658.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:45.903342: step 54400, loss = 2.15 (8745.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:47.343996: step 54500, loss = 2.05 (8884.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:09:48.766249: step 54600, loss = 2.17 (8999.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:09:50.214864: step 54700, loss = 2.10 (8836.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:09:51.649313: step 54800, loss = 2.01 (8923.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:09:53.121196: step 54900, loss = 2.08 (8696.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:54.574878: step 55000, loss = 2.04 (8805.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:56.013007: step 55100, loss = 2.05 (8900.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:09:57.488018: step 55200, loss = 2.12 (8677.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:09:58.908425: step 55300, loss = 2.14 (9011.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:10:00.849717: step 55400, loss = 2.09 (6593.5 examples/sec; 0.019 sec/batch)
2018-02-01 15:10:03.531072: step 55500, loss = 2.06 (4773.7 examples/sec; 0.027 sec/batch)
2018-02-01 15:10:13.028955: step 55600, loss = 2.08 (1347.7 examples/sec; 0.095 sec/batch)
2018-02-01 15:10:14.480809: step 55700, loss = 2.06 (8816.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:10:15.950349: step 55800, loss = 2.02 (8710.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:10:17.397854: step 55900, loss = 2.07 (8842.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:10:18.860748: step 56000, loss = 1.99 (8749.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:10:20.286912: step 56100, loss = 2.01 (8975.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:10:21.732735: step 56200, loss = 2.12 (8853.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:10:23.189734: step 56300, loss = 2.11 (8785.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:10:24.658625: step 56400, loss = 2.02 (8714.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:10:26.123928: step 56500, loss = 2.06 (8735.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:10:27.569651: step 56600, loss = 2.08 (8853.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:10:28.991248: step 56700, loss = 2.12 (9004.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:10:30.437946: step 56800, loss = 2.02 (8847.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:10:31.876573: step 56900, loss = 2.10 (8897.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:10:33.324109: step 57000, loss = 2.24 (8842.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:10:34.745271: step 57100, loss = 2.16 (9006.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:10:37.812805: step 57200, loss = 2.09 (4172.7 examples/sec; 0.031 sec/batch)
2018-02-01 15:10:39.260379: step 57300, loss = 2.07 (8842.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:10:40.711514: step 57400, loss = 2.14 (8820.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:10:42.151615: step 57500, loss = 2.08 (8888.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:10:44.541925: step 57600, loss = 2.12 (5355.0 examples/sec; 0.024 sec/batch)
2018-02-01 15:10:47.178900: step 57700, loss = 2.16 (4854.0 examples/sec; 0.026 sec/batch)
2018-02-01 15:10:49.920519: step 57800, loss = 2.05 (4668.8 examples/sec; 0.027 sec/batch)
2018-02-01 15:10:52.485357: step 57900, loss = 2.09 (4990.6 examples/sec; 0.026 sec/batch)
2018-02-01 15:10:55.256475: step 58000, loss = 2.04 (4619.1 examples/sec; 0.028 sec/batch)
2018-02-01 15:10:57.995186: step 58100, loss = 2.16 (4673.7 examples/sec; 0.027 sec/batch)
2018-02-01 15:11:00.104086: step 58200, loss = 2.09 (6069.5 examples/sec; 0.021 sec/batch)
2018-02-01 15:11:01.547934: step 58300, loss = 2.07 (8865.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:11:03.017464: step 58400, loss = 2.08 (8710.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:11:04.484377: step 58500, loss = 2.21 (8725.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:11:07.470813: step 58600, loss = 2.00 (4286.0 examples/sec; 0.030 sec/batch)
2018-02-01 15:11:08.917544: step 58700, loss = 1.95 (8847.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:11:10.355376: step 58800, loss = 2.14 (8902.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:11:11.789366: step 58900, loss = 2.05 (8926.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:11:13.235111: step 59000, loss = 2.09 (8853.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:11:14.672874: step 59100, loss = 2.06 (8902.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:11:16.141748: step 59200, loss = 2.12 (8714.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:11:17.594965: step 59300, loss = 2.05 (8808.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:11:19.024509: step 59400, loss = 2.15 (8953.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:11:20.501509: step 59500, loss = 2.04 (8666.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:11:21.970448: step 59600, loss = 2.07 (8713.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:11:23.407812: step 59700, loss = 2.04 (8905.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:11:24.861646: step 59800, loss = 2.15 (8804.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:11:26.297194: step 59900, loss = 2.09 (8916.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:11:27.763337: step 60000, loss = 2.02 (8730.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:11:29.197953: step 60100, loss = 2.11 (8922.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:11:31.281858: step 60200, loss = 2.14 (6142.3 examples/sec; 0.021 sec/batch)
2018-02-01 15:11:33.957072: step 60300, loss = 2.04 (4784.7 examples/sec; 0.027 sec/batch)
2018-02-01 15:11:43.778497: step 60400, loss = 2.11 (1303.3 examples/sec; 0.098 sec/batch)
2018-02-01 15:11:45.289166: step 60500, loss = 2.03 (8473.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:11:46.791552: step 60600, loss = 2.05 (8519.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:11:48.285950: step 60700, loss = 2.10 (8565.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:11:49.923030: step 60800, loss = 2.00 (7818.8 examples/sec; 0.016 sec/batch)
2018-02-01 15:11:51.543339: step 60900, loss = 2.02 (7899.7 examples/sec; 0.016 sec/batch)
2018-02-01 15:11:53.154624: step 61000, loss = 2.04 (7944.0 examples/sec; 0.016 sec/batch)
2018-02-01 15:11:54.679680: step 61100, loss = 2.04 (8393.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:11:56.459414: step 61200, loss = 2.18 (7192.1 examples/sec; 0.018 sec/batch)
2018-02-01 15:11:58.280256: step 61300, loss = 2.05 (7029.7 examples/sec; 0.018 sec/batch)
2018-02-01 15:12:00.022891: step 61400, loss = 2.06 (7345.2 examples/sec; 0.017 sec/batch)
2018-02-01 15:12:01.779563: step 61500, loss = 1.99 (7286.5 examples/sec; 0.018 sec/batch)
2018-02-01 15:12:03.458027: step 61600, loss = 2.14 (7626.0 examples/sec; 0.017 sec/batch)
2018-02-01 15:12:04.936823: step 61700, loss = 2.19 (8655.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:12:07.942678: step 61800, loss = 2.06 (4258.4 examples/sec; 0.030 sec/batch)
2018-02-01 15:12:09.378395: step 61900, loss = 2.11 (8915.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:10.818027: step 62000, loss = 2.09 (8891.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:12.278606: step 62100, loss = 2.13 (8763.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:12:14.404327: step 62200, loss = 2.10 (6021.5 examples/sec; 0.021 sec/batch)
2018-02-01 15:12:16.883636: step 62300, loss = 1.95 (5162.7 examples/sec; 0.025 sec/batch)
2018-02-01 15:12:19.435756: step 62400, loss = 2.05 (5015.4 examples/sec; 0.026 sec/batch)
2018-02-01 15:12:22.024919: step 62500, loss = 2.10 (4943.7 examples/sec; 0.026 sec/batch)
2018-02-01 15:12:24.588448: step 62600, loss = 2.02 (4993.1 examples/sec; 0.026 sec/batch)
2018-02-01 15:12:27.274280: step 62700, loss = 2.08 (4765.7 examples/sec; 0.027 sec/batch)
2018-02-01 15:12:29.930389: step 62800, loss = 2.20 (4819.1 examples/sec; 0.027 sec/batch)
2018-02-01 15:12:31.516067: step 62900, loss = 2.07 (8072.3 examples/sec; 0.016 sec/batch)
2018-02-01 15:12:32.966316: step 63000, loss = 2.10 (8826.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:12:34.386711: step 63100, loss = 2.02 (9011.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:37.364353: step 63200, loss = 2.11 (4298.7 examples/sec; 0.030 sec/batch)
2018-02-01 15:12:38.837260: step 63300, loss = 2.08 (8690.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:12:40.288681: step 63400, loss = 2.00 (8818.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:12:41.737558: step 63500, loss = 2.03 (8834.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:43.191993: step 63600, loss = 2.08 (8800.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:12:44.632533: step 63700, loss = 1.99 (8885.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:46.059177: step 63800, loss = 2.13 (8972.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:47.496645: step 63900, loss = 2.17 (8904.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:48.930135: step 64000, loss = 2.07 (8929.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:50.368945: step 64100, loss = 2.14 (8896.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:51.803932: step 64200, loss = 2.11 (8919.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:53.244935: step 64300, loss = 2.25 (8882.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:54.681244: step 64400, loss = 2.10 (8911.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:56.132530: step 64500, loss = 2.09 (8819.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:12:57.576116: step 64600, loss = 2.06 (8866.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:12:59.032741: step 64700, loss = 2.04 (8787.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:13:00.494491: step 64800, loss = 2.13 (8756.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:13:02.713714: step 64900, loss = 2.06 (5767.8 examples/sec; 0.022 sec/batch)
2018-02-01 15:13:13.235637: step 65000, loss = 2.02 (1216.5 examples/sec; 0.105 sec/batch)
2018-02-01 15:13:14.690864: step 65100, loss = 2.08 (8795.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:13:16.120521: step 65200, loss = 2.15 (8953.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:13:17.577412: step 65300, loss = 2.12 (8785.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:13:19.035069: step 65400, loss = 2.10 (8781.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:13:20.484227: step 65500, loss = 2.03 (8832.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:13:21.906675: step 65600, loss = 2.04 (8998.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:13:23.379214: step 65700, loss = 1.97 (8692.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:13:24.813235: step 65800, loss = 2.17 (8926.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:13:26.268704: step 65900, loss = 2.10 (8794.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:13:27.708431: step 66000, loss = 2.08 (8890.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:13:29.156382: step 66100, loss = 2.13 (8840.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:13:30.611268: step 66200, loss = 2.05 (8797.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:13:32.066620: step 66300, loss = 2.10 (8795.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:13:33.515321: step 66400, loss = 2.12 (8835.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:13:34.953359: step 66500, loss = 2.11 (8901.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:13:37.936252: step 66600, loss = 2.08 (4291.1 examples/sec; 0.030 sec/batch)
2018-02-01 15:13:39.388229: step 66700, loss = 2.11 (8815.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:13:40.866633: step 66800, loss = 2.14 (8658.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:13:42.318756: step 66900, loss = 2.12 (8814.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:13:44.476795: step 67000, loss = 2.12 (5931.3 examples/sec; 0.022 sec/batch)
2018-02-01 15:13:47.043669: step 67100, loss = 2.11 (4986.6 examples/sec; 0.026 sec/batch)
2018-02-01 15:13:49.626263: step 67200, loss = 2.17 (4956.3 examples/sec; 0.026 sec/batch)
2018-02-01 15:13:52.169110: step 67300, loss = 2.16 (5033.7 examples/sec; 0.025 sec/batch)
2018-02-01 15:13:54.782520: step 67400, loss = 2.15 (4897.8 examples/sec; 0.026 sec/batch)
2018-02-01 15:13:57.763617: step 67500, loss = 2.12 (4293.7 examples/sec; 0.030 sec/batch)
2018-02-01 15:14:00.186851: step 67600, loss = 2.09 (5282.2 examples/sec; 0.024 sec/batch)
2018-02-01 15:14:01.663375: step 67700, loss = 2.09 (8669.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:03.126633: step 67800, loss = 2.19 (8747.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:04.563188: step 67900, loss = 2.01 (8910.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:07.587558: step 68000, loss = 2.19 (4232.3 examples/sec; 0.030 sec/batch)
2018-02-01 15:14:09.051489: step 68100, loss = 2.05 (8743.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:10.498313: step 68200, loss = 2.15 (8847.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:11.953975: step 68300, loss = 2.15 (8793.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:13.390821: step 68400, loss = 2.10 (8908.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:14.807778: step 68500, loss = 2.05 (9033.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:16.280679: step 68600, loss = 2.02 (8690.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:17.739684: step 68700, loss = 2.18 (8773.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:19.182185: step 68800, loss = 2.13 (8873.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:20.628183: step 68900, loss = 2.16 (8852.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:22.069977: step 69000, loss = 2.13 (8877.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:23.515330: step 69100, loss = 2.05 (8856.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:24.977474: step 69200, loss = 2.09 (8754.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:26.441929: step 69300, loss = 2.08 (8740.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:27.900189: step 69400, loss = 2.13 (8777.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:29.349890: step 69500, loss = 2.07 (8829.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:31.013834: step 69600, loss = 2.09 (7692.6 examples/sec; 0.017 sec/batch)
2018-02-01 15:14:33.420620: step 69700, loss = 2.11 (5318.3 examples/sec; 0.024 sec/batch)
2018-02-01 15:14:43.559170: step 69800, loss = 2.14 (1262.5 examples/sec; 0.101 sec/batch)
2018-02-01 15:14:44.997690: step 69900, loss = 2.04 (8898.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:46.463535: step 70000, loss = 2.15 (8732.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:47.890747: step 70100, loss = 2.19 (8968.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:49.337725: step 70200, loss = 2.08 (8846.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:50.776833: step 70300, loss = 2.06 (8894.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:52.218522: step 70400, loss = 2.02 (8878.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:53.678949: step 70500, loss = 2.11 (8764.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:55.146295: step 70600, loss = 2.09 (8723.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:56.567739: step 70700, loss = 2.02 (9004.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:14:58.051902: step 70800, loss = 2.11 (8624.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:14:59.505398: step 70900, loss = 2.17 (8806.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:15:00.951707: step 71000, loss = 2.14 (8850.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:02.400059: step 71100, loss = 2.05 (8837.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:03.873230: step 71200, loss = 2.05 (8688.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:15:05.333700: step 71300, loss = 2.03 (8764.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:15:08.296355: step 71400, loss = 2.13 (4320.4 examples/sec; 0.030 sec/batch)
2018-02-01 15:15:09.742882: step 71500, loss = 2.10 (8848.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:11.196193: step 71600, loss = 2.09 (8807.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:15:12.658764: step 71700, loss = 2.07 (8751.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:15:14.933722: step 71800, loss = 2.13 (5626.5 examples/sec; 0.023 sec/batch)
2018-02-01 15:15:17.883571: step 71900, loss = 2.13 (4339.2 examples/sec; 0.029 sec/batch)
2018-02-01 15:15:20.561698: step 72000, loss = 2.08 (4779.5 examples/sec; 0.027 sec/batch)
2018-02-01 15:15:23.022764: step 72100, loss = 2.18 (5201.0 examples/sec; 0.025 sec/batch)
2018-02-01 15:15:25.687443: step 72200, loss = 2.09 (4803.6 examples/sec; 0.027 sec/batch)
2018-02-01 15:15:28.273241: step 72300, loss = 2.05 (4950.1 examples/sec; 0.026 sec/batch)
2018-02-01 15:15:30.573573: step 72400, loss = 2.08 (5564.4 examples/sec; 0.023 sec/batch)
2018-02-01 15:15:32.008386: step 72500, loss = 2.17 (8921.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:33.442184: step 72600, loss = 2.13 (8927.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:34.910667: step 72700, loss = 2.05 (8716.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:15:37.963728: step 72800, loss = 1.99 (4192.5 examples/sec; 0.031 sec/batch)
2018-02-01 15:15:39.420618: step 72900, loss = 2.10 (8785.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:15:40.862320: step 73000, loss = 2.08 (8878.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:42.281845: step 73100, loss = 2.06 (9017.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:43.743702: step 73200, loss = 2.22 (8756.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:15:45.172739: step 73300, loss = 2.11 (8957.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:46.606830: step 73400, loss = 2.11 (8925.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:48.053851: step 73500, loss = 2.08 (8845.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:49.500756: step 73600, loss = 2.09 (8846.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:50.948732: step 73700, loss = 2.11 (8839.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:52.406399: step 73800, loss = 2.13 (8781.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:15:53.830729: step 73900, loss = 2.02 (8986.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:55.268686: step 74000, loss = 2.12 (8901.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:56.717294: step 74100, loss = 2.00 (8836.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:58.156578: step 74200, loss = 2.04 (8893.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:15:59.596263: step 74300, loss = 2.08 (8890.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:16:01.235178: step 74400, loss = 2.04 (7810.0 examples/sec; 0.016 sec/batch)
2018-02-01 15:16:03.799901: step 74500, loss = 2.11 (4990.8 examples/sec; 0.026 sec/batch)
2018-02-01 15:16:13.798832: step 74600, loss = 2.07 (1280.1 examples/sec; 0.100 sec/batch)
2018-02-01 15:16:15.262000: step 74700, loss = 2.02 (8748.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:16:16.722322: step 74800, loss = 2.06 (8765.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:16:18.191221: step 74900, loss = 2.03 (8714.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:16:19.629466: step 75000, loss = 2.08 (8899.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:16:21.064407: step 75100, loss = 2.08 (8920.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:16:22.506462: step 75200, loss = 2.19 (8876.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:16:23.945306: step 75300, loss = 2.10 (8896.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:16:25.417089: step 75400, loss = 2.08 (8696.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:16:26.851143: step 75500, loss = 2.13 (8925.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:16:28.303949: step 75600, loss = 2.06 (8810.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:16:29.767513: step 75700, loss = 2.07 (8745.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:16:31.208098: step 75800, loss = 1.98 (8885.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:16:32.666878: step 75900, loss = 2.12 (8774.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:16:34.120112: step 76000, loss = 2.08 (8807.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:16:37.151125: step 76100, loss = 2.10 (4223.0 examples/sec; 0.030 sec/batch)
2018-02-01 15:16:38.610258: step 76200, loss = 2.17 (8772.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:16:40.041558: step 76300, loss = 2.21 (8942.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:16:41.505549: step 76400, loss = 2.06 (8743.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:16:42.959094: step 76500, loss = 2.10 (8806.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:16:45.351362: step 76600, loss = 2.02 (5350.6 examples/sec; 0.024 sec/batch)
2018-02-01 15:16:47.943058: step 76700, loss = 1.99 (4938.8 examples/sec; 0.026 sec/batch)
2018-02-01 15:16:50.697518: step 76800, loss = 2.13 (4647.0 examples/sec; 0.028 sec/batch)
2018-02-01 15:16:53.490331: step 76900, loss = 1.96 (4583.2 examples/sec; 0.028 sec/batch)
2018-02-01 15:16:56.269762: step 77000, loss = 2.22 (4605.3 examples/sec; 0.028 sec/batch)
2018-02-01 15:16:58.637218: step 77100, loss = 2.08 (5406.6 examples/sec; 0.024 sec/batch)
2018-02-01 15:17:00.862897: step 77200, loss = 2.13 (5751.1 examples/sec; 0.022 sec/batch)
2018-02-01 15:17:02.316541: step 77300, loss = 2.04 (8805.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:17:03.751260: step 77400, loss = 2.11 (8921.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:05.177307: step 77500, loss = 2.10 (8975.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:08.245687: step 77600, loss = 2.15 (4171.6 examples/sec; 0.031 sec/batch)
2018-02-01 15:17:09.704231: step 77700, loss = 2.17 (8775.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:17:11.133826: step 77800, loss = 2.15 (8953.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:12.565878: step 77900, loss = 2.06 (8938.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:14.027012: step 78000, loss = 2.10 (8760.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:17:15.462609: step 78100, loss = 2.06 (8916.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:16.897082: step 78200, loss = 2.08 (8923.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:18.360703: step 78300, loss = 2.18 (8745.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:17:19.824040: step 78400, loss = 2.11 (8747.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:17:21.289211: step 78500, loss = 2.21 (8736.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:17:22.733990: step 78600, loss = 2.09 (8859.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:24.184976: step 78700, loss = 2.12 (8821.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:17:25.658605: step 78800, loss = 2.13 (8686.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:17:27.108109: step 78900, loss = 1.99 (8830.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:28.555241: step 79000, loss = 2.13 (8845.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:29.997303: step 79100, loss = 2.08 (8876.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:31.828779: step 79200, loss = 2.11 (6988.9 examples/sec; 0.018 sec/batch)
2018-02-01 15:17:34.485879: step 79300, loss = 2.04 (4817.3 examples/sec; 0.027 sec/batch)
2018-02-01 15:17:44.264366: step 79400, loss = 2.08 (1309.0 examples/sec; 0.098 sec/batch)
2018-02-01 15:17:45.701538: step 79500, loss = 2.06 (8906.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:47.143415: step 79600, loss = 2.10 (8877.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:48.587386: step 79700, loss = 2.10 (8864.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:50.040465: step 79800, loss = 2.06 (8808.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:17:51.458420: step 79900, loss = 2.12 (9027.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:52.902005: step 80000, loss = 2.11 (8866.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:54.339402: step 80100, loss = 2.19 (8905.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:55.788123: step 80200, loss = 2.07 (8835.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:57.212726: step 80300, loss = 2.10 (8985.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:17:58.661367: step 80400, loss = 2.13 (8835.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:00.125956: step 80500, loss = 2.22 (8739.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:18:01.586729: step 80600, loss = 2.24 (8762.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:18:03.016153: step 80700, loss = 2.19 (8954.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:04.459819: step 80800, loss = 2.18 (8866.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:07.431687: step 80900, loss = 2.06 (4307.1 examples/sec; 0.030 sec/batch)
2018-02-01 15:18:08.885188: step 81000, loss = 2.13 (8806.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:18:10.301808: step 81100, loss = 2.16 (9035.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:11.744139: step 81200, loss = 2.08 (8874.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:13.187704: step 81300, loss = 2.18 (8866.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:15.580155: step 81400, loss = 2.15 (5350.2 examples/sec; 0.024 sec/batch)
2018-02-01 15:18:18.280960: step 81500, loss = 1.94 (4739.3 examples/sec; 0.027 sec/batch)
2018-02-01 15:18:20.875697: step 81600, loss = 2.03 (4933.1 examples/sec; 0.026 sec/batch)
2018-02-01 15:18:23.662797: step 81700, loss = 2.06 (4592.6 examples/sec; 0.028 sec/batch)
2018-02-01 15:18:26.026104: step 81800, loss = 2.13 (5416.1 examples/sec; 0.024 sec/batch)
2018-02-01 15:18:28.709088: step 81900, loss = 1.96 (4770.8 examples/sec; 0.027 sec/batch)
2018-02-01 15:18:31.004596: step 82000, loss = 2.06 (5576.1 examples/sec; 0.023 sec/batch)
2018-02-01 15:18:32.460679: step 82100, loss = 2.04 (8790.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:18:33.897969: step 82200, loss = 2.17 (8905.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:35.335154: step 82300, loss = 2.09 (8906.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:38.361273: step 82400, loss = 2.09 (4229.8 examples/sec; 0.030 sec/batch)
2018-02-01 15:18:39.816826: step 82500, loss = 2.09 (8793.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:18:41.279252: step 82600, loss = 2.08 (8752.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:18:42.693074: step 82700, loss = 2.09 (9053.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:44.142589: step 82800, loss = 2.09 (8830.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:45.602865: step 82900, loss = 2.09 (8765.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:18:47.033174: step 83000, loss = 2.06 (8949.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:48.471498: step 83100, loss = 2.12 (8899.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:49.912715: step 83200, loss = 2.12 (8881.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:51.372513: step 83300, loss = 2.13 (8768.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:18:52.835296: step 83400, loss = 2.08 (8750.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:18:54.298026: step 83500, loss = 2.05 (8750.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:18:55.730591: step 83600, loss = 2.07 (8935.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:18:57.189347: step 83700, loss = 2.05 (8774.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:18:58.635734: step 83800, loss = 2.17 (8849.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:19:00.089314: step 83900, loss = 2.18 (8805.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:19:01.718046: step 84000, loss = 2.05 (7858.9 examples/sec; 0.016 sec/batch)
2018-02-01 15:19:04.360121: step 84100, loss = 2.15 (4844.7 examples/sec; 0.026 sec/batch)
2018-02-01 15:19:14.280877: step 84200, loss = 2.11 (1290.2 examples/sec; 0.099 sec/batch)
2018-02-01 15:19:15.714390: step 84300, loss = 2.19 (8929.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:19:17.158187: step 84400, loss = 2.18 (8865.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:19:18.607386: step 84500, loss = 2.14 (8832.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:19:20.020256: step 84600, loss = 2.04 (9059.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:19:21.460446: step 84700, loss = 2.10 (8887.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:19:22.900111: step 84800, loss = 2.13 (8891.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:19:24.360277: step 84900, loss = 2.17 (8766.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:19:25.811570: step 85000, loss = 2.11 (8819.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:19:27.267085: step 85100, loss = 2.07 (8794.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:19:28.695702: step 85200, loss = 2.10 (8959.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:19:30.160176: step 85300, loss = 2.09 (8740.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:19:31.616748: step 85400, loss = 2.08 (8787.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:19:33.067043: step 85500, loss = 2.10 (8825.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:19:34.505006: step 85600, loss = 2.08 (8901.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:19:37.524433: step 85700, loss = 2.19 (4239.2 examples/sec; 0.030 sec/batch)
2018-02-01 15:19:38.983579: step 85800, loss = 2.16 (8772.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:19:40.439431: step 85900, loss = 1.97 (8792.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:19:41.899615: step 86000, loss = 2.07 (8766.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:19:43.372485: step 86100, loss = 2.03 (8690.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:19:46.088249: step 86200, loss = 2.03 (4713.2 examples/sec; 0.027 sec/batch)
2018-02-01 15:19:48.754232: step 86300, loss = 2.05 (4801.2 examples/sec; 0.027 sec/batch)
2018-02-01 15:19:51.635945: step 86400, loss = 2.06 (4441.8 examples/sec; 0.029 sec/batch)
2018-02-01 15:19:54.327039: step 86500, loss = 2.08 (4756.4 examples/sec; 0.027 sec/batch)
2018-02-01 15:19:57.000542: step 86600, loss = 2.12 (4787.7 examples/sec; 0.027 sec/batch)
2018-02-01 15:19:59.480923: step 86700, loss = 2.12 (5160.5 examples/sec; 0.025 sec/batch)
2018-02-01 15:20:01.260497: step 86800, loss = 2.09 (7192.7 examples/sec; 0.018 sec/batch)
2018-02-01 15:20:02.724671: step 86900, loss = 2.10 (8742.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:20:04.248299: step 87000, loss = 2.21 (8401.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:20:07.268779: step 87100, loss = 2.07 (4237.7 examples/sec; 0.030 sec/batch)
2018-02-01 15:20:08.716611: step 87200, loss = 2.11 (8840.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:10.163325: step 87300, loss = 2.15 (8847.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:11.586143: step 87400, loss = 2.05 (8996.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:13.066985: step 87500, loss = 2.13 (8643.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:20:14.512307: step 87600, loss = 2.09 (8856.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:15.949559: step 87700, loss = 2.13 (8905.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:17.417759: step 87800, loss = 2.13 (8718.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:20:18.851838: step 87900, loss = 2.20 (8925.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:20.292116: step 88000, loss = 2.10 (8887.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:21.741721: step 88100, loss = 2.10 (8830.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:23.194825: step 88200, loss = 2.02 (8808.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:20:24.633883: step 88300, loss = 2.16 (8894.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:26.102939: step 88400, loss = 1.97 (8713.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:20:27.540761: step 88500, loss = 2.03 (8902.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:28.978412: step 88600, loss = 2.08 (8903.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:30.428005: step 88700, loss = 2.15 (8830.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:32.466729: step 88800, loss = 2.17 (6278.4 examples/sec; 0.020 sec/batch)
2018-02-01 15:20:35.102310: step 88900, loss = 2.06 (4856.6 examples/sec; 0.026 sec/batch)
2018-02-01 15:20:44.541275: step 89000, loss = 2.04 (1356.1 examples/sec; 0.094 sec/batch)
2018-02-01 15:20:45.973762: step 89100, loss = 2.16 (8935.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:47.421566: step 89200, loss = 2.14 (8841.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:48.860464: step 89300, loss = 2.09 (8895.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:50.333598: step 89400, loss = 1.98 (8689.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:20:51.790721: step 89500, loss = 2.07 (8784.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:20:53.216299: step 89600, loss = 2.13 (8978.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:54.661369: step 89700, loss = 2.03 (8857.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:56.093385: step 89800, loss = 2.04 (8938.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:57.521466: step 89900, loss = 2.10 (8963.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:20:58.978188: step 90000, loss = 2.05 (8786.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:00.422821: step 90100, loss = 2.09 (8860.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:21:01.856290: step 90200, loss = 2.12 (8929.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:21:03.314710: step 90300, loss = 1.98 (8776.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:04.788569: step 90400, loss = 2.16 (8684.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:07.849673: step 90500, loss = 2.08 (4181.5 examples/sec; 0.031 sec/batch)
2018-02-01 15:21:09.307978: step 90600, loss = 2.07 (8777.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:10.751149: step 90700, loss = 2.12 (8869.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:21:12.192052: step 90800, loss = 2.09 (8883.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:21:14.022875: step 90900, loss = 2.04 (6991.4 examples/sec; 0.018 sec/batch)
2018-02-01 15:21:16.743479: step 91000, loss = 2.01 (4704.8 examples/sec; 0.027 sec/batch)
2018-02-01 15:21:19.431594: step 91100, loss = 2.09 (4761.7 examples/sec; 0.027 sec/batch)
2018-02-01 15:21:22.194163: step 91200, loss = 2.18 (4633.4 examples/sec; 0.028 sec/batch)
2018-02-01 15:21:24.898596: step 91300, loss = 2.12 (4733.0 examples/sec; 0.027 sec/batch)
2018-02-01 15:21:27.570220: step 91400, loss = 2.07 (4791.1 examples/sec; 0.027 sec/batch)
2018-02-01 15:21:30.091624: step 91500, loss = 2.05 (5076.5 examples/sec; 0.025 sec/batch)
2018-02-01 15:21:31.553703: step 91600, loss = 2.15 (8754.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:33.014192: step 91700, loss = 2.05 (8764.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:34.471556: step 91800, loss = 2.12 (8783.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:37.461886: step 91900, loss = 2.12 (4280.5 examples/sec; 0.030 sec/batch)
2018-02-01 15:21:38.927617: step 92000, loss = 2.13 (8732.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:40.398153: step 92100, loss = 2.04 (8704.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:41.838849: step 92200, loss = 2.12 (8884.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:21:43.286721: step 92300, loss = 1.95 (8840.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:21:44.721966: step 92400, loss = 2.05 (8918.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:21:46.201197: step 92500, loss = 2.11 (8653.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:47.657851: step 92600, loss = 2.05 (8787.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:49.091184: step 92700, loss = 2.15 (8930.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:21:50.543364: step 92800, loss = 2.03 (8814.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:52.016950: step 92900, loss = 2.11 (8686.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:53.461029: step 93000, loss = 1.99 (8863.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:21:54.907547: step 93100, loss = 2.11 (8848.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:21:56.359111: step 93200, loss = 2.13 (8818.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:21:57.788261: step 93300, loss = 1.98 (8956.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:21:59.232542: step 93400, loss = 2.15 (8862.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:22:00.692292: step 93500, loss = 2.04 (8768.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:22:03.472308: step 93600, loss = 2.19 (4604.3 examples/sec; 0.028 sec/batch)
2018-02-01 15:22:13.446541: step 93700, loss = 2.15 (1283.3 examples/sec; 0.100 sec/batch)
2018-02-01 15:22:14.886201: step 93800, loss = 2.11 (8891.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:22:16.354307: step 93900, loss = 2.01 (8718.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:22:17.818001: step 94000, loss = 2.12 (8745.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:22:19.260712: step 94100, loss = 2.14 (8872.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:22:20.695438: step 94200, loss = 2.23 (8921.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:22:22.128423: step 94300, loss = 2.11 (8932.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:22:23.570297: step 94400, loss = 2.10 (8877.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:22:25.010169: step 94500, loss = 2.21 (8889.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:22:26.469591: step 94600, loss = 1.96 (8770.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:22:27.922350: step 94700, loss = 2.00 (8810.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:22:29.354411: step 94800, loss = 2.04 (8938.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:22:30.812263: step 94900, loss = 2.08 (8780.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:22:32.253128: step 95000, loss = 2.08 (8883.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:22:33.703561: step 95100, loss = 2.06 (8825.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:22:35.144804: step 95200, loss = 2.07 (8881.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:22:38.134103: step 95300, loss = 2.13 (4281.9 examples/sec; 0.030 sec/batch)
2018-02-01 15:22:39.575412: step 95400, loss = 2.03 (8880.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:22:41.035894: step 95500, loss = 2.12 (8764.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:22:42.470854: step 95600, loss = 2.19 (8920.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:22:44.684795: step 95700, loss = 2.19 (5781.5 examples/sec; 0.022 sec/batch)
2018-02-01 15:22:47.296519: step 95800, loss = 2.10 (4901.0 examples/sec; 0.026 sec/batch)
2018-02-01 15:22:50.024469: step 95900, loss = 2.17 (4692.2 examples/sec; 0.027 sec/batch)
2018-02-01 15:22:52.862060: step 96000, loss = 2.11 (4510.9 examples/sec; 0.028 sec/batch)
2018-02-01 15:22:55.343185: step 96100, loss = 2.13 (5158.9 examples/sec; 0.025 sec/batch)
2018-02-01 15:22:58.407756: step 96200, loss = 2.09 (4176.8 examples/sec; 0.031 sec/batch)
2018-02-01 15:23:00.414265: step 96300, loss = 2.07 (6379.2 examples/sec; 0.020 sec/batch)
2018-02-01 15:23:01.843808: step 96400, loss = 2.14 (8953.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:03.291819: step 96500, loss = 2.01 (8839.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:04.746729: step 96600, loss = 2.07 (8797.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:23:07.759075: step 96700, loss = 2.09 (4249.2 examples/sec; 0.030 sec/batch)
2018-02-01 15:23:09.234735: step 96800, loss = 2.00 (8674.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:23:10.673411: step 96900, loss = 2.11 (8897.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:12.115309: step 97000, loss = 2.01 (8877.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:13.539755: step 97100, loss = 2.15 (8985.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:14.995563: step 97200, loss = 2.05 (8792.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:23:16.440076: step 97300, loss = 2.16 (8861.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:17.879202: step 97400, loss = 2.05 (8894.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:19.346686: step 97500, loss = 2.07 (8722.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:23:20.814240: step 97600, loss = 2.11 (8722.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:23:22.247339: step 97700, loss = 2.07 (8931.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:23.679735: step 97800, loss = 2.21 (8936.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:25.109825: step 97900, loss = 2.13 (8950.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:26.562206: step 98000, loss = 2.13 (8813.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:23:28.021140: step 98100, loss = 2.03 (8773.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:23:29.465352: step 98200, loss = 2.04 (8863.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:31.311462: step 98300, loss = 2.18 (6933.5 examples/sec; 0.018 sec/batch)
2018-02-01 15:23:33.862562: step 98400, loss = 2.04 (5017.4 examples/sec; 0.026 sec/batch)
2018-02-01 15:23:43.548462: step 98500, loss = 2.06 (1321.5 examples/sec; 0.097 sec/batch)
2018-02-01 15:23:45.033358: step 98600, loss = 2.12 (8620.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:23:46.469752: step 98700, loss = 2.20 (8911.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:47.900233: step 98800, loss = 2.13 (8948.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:49.342542: step 98900, loss = 2.20 (8874.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:50.777371: step 99000, loss = 2.11 (8920.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:52.221745: step 99100, loss = 2.02 (8862.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:53.649243: step 99200, loss = 2.04 (8966.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:55.117264: step 99300, loss = 2.17 (8719.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:23:56.553725: step 99400, loss = 2.13 (8910.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:57.999330: step 99500, loss = 2.14 (8854.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:23:59.434353: step 99600, loss = 2.12 (8919.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:00.887343: step 99700, loss = 2.16 (8809.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:24:02.322798: step 99800, loss = 2.10 (8917.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:03.754981: step 99900, loss = 2.14 (8937.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:05.197673: step 100000, loss = 2.03 (8872.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:08.157495: step 100100, loss = 2.14 (4324.6 examples/sec; 0.030 sec/batch)
2018-02-01 15:24:09.605244: step 100200, loss = 2.04 (8841.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:11.047543: step 100300, loss = 2.08 (8874.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:12.491299: step 100400, loss = 2.10 (8865.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:14.603360: step 100500, loss = 2.13 (6060.4 examples/sec; 0.021 sec/batch)
2018-02-01 15:24:17.579250: step 100600, loss = 2.13 (4301.2 examples/sec; 0.030 sec/batch)
2018-02-01 15:24:20.300317: step 100700, loss = 2.10 (4704.0 examples/sec; 0.027 sec/batch)
2018-02-01 15:24:22.951616: step 100800, loss = 2.14 (4827.8 examples/sec; 0.027 sec/batch)
2018-02-01 15:24:25.724260: step 100900, loss = 2.07 (4616.5 examples/sec; 0.028 sec/batch)
2018-02-01 15:24:28.872907: step 101000, loss = 2.19 (4065.2 examples/sec; 0.031 sec/batch)
2018-02-01 15:24:30.554535: step 101100, loss = 2.22 (7611.7 examples/sec; 0.017 sec/batch)
2018-02-01 15:24:31.985696: step 101200, loss = 2.07 (8943.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:33.431620: step 101300, loss = 2.10 (8852.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:34.883346: step 101400, loss = 2.15 (8817.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:24:37.952896: step 101500, loss = 2.09 (4170.0 examples/sec; 0.031 sec/batch)
2018-02-01 15:24:39.387989: step 101600, loss = 2.09 (8919.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:40.813983: step 101700, loss = 2.05 (8976.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:42.281130: step 101800, loss = 2.10 (8724.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:24:43.733218: step 101900, loss = 2.06 (8814.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:24:45.178540: step 102000, loss = 2.08 (8856.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:46.587013: step 102100, loss = 2.09 (9087.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:48.028511: step 102200, loss = 2.12 (8879.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:49.476519: step 102300, loss = 2.20 (8839.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:50.916863: step 102400, loss = 2.06 (8886.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:52.348754: step 102500, loss = 2.11 (8939.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:53.811872: step 102600, loss = 2.03 (8748.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:24:55.247774: step 102700, loss = 2.05 (8914.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:56.677371: step 102800, loss = 2.17 (8953.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:24:58.145841: step 102900, loss = 2.05 (8716.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:24:59.600554: step 103000, loss = 2.15 (8799.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:25:01.884008: step 103100, loss = 2.15 (5605.5 examples/sec; 0.023 sec/batch)
2018-02-01 15:25:04.575116: step 103200, loss = 2.08 (4756.4 examples/sec; 0.027 sec/batch)
2018-02-01 15:25:13.772150: step 103300, loss = 2.09 (1391.8 examples/sec; 0.092 sec/batch)
2018-02-01 15:25:15.219721: step 103400, loss = 2.03 (8842.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:16.659793: step 103500, loss = 2.05 (8888.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:18.104160: step 103600, loss = 2.10 (8862.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:19.541017: step 103700, loss = 2.17 (8908.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:20.981939: step 103800, loss = 2.18 (8883.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:22.436356: step 103900, loss = 2.07 (8800.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:25:23.904691: step 104000, loss = 2.06 (8717.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:25:25.354010: step 104100, loss = 2.20 (8831.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:26.809350: step 104200, loss = 2.09 (8795.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:25:28.248688: step 104300, loss = 1.99 (8893.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:29.678747: step 104400, loss = 2.11 (8950.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:31.124794: step 104500, loss = 2.15 (8851.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:32.575695: step 104600, loss = 2.05 (8822.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:25:34.022859: step 104700, loss = 2.06 (8844.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:35.464246: step 104800, loss = 2.07 (8880.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:38.440462: step 104900, loss = 2.11 (4300.8 examples/sec; 0.030 sec/batch)
2018-02-01 15:25:39.879570: step 105000, loss = 2.04 (8894.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:41.320402: step 105100, loss = 2.10 (8883.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:25:42.784983: step 105200, loss = 1.99 (8739.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:25:45.384858: step 105300, loss = 2.11 (4923.3 examples/sec; 0.026 sec/batch)
2018-02-01 15:25:48.122541: step 105400, loss = 2.13 (4675.5 examples/sec; 0.027 sec/batch)
2018-02-01 15:25:50.920906: step 105500, loss = 2.05 (4574.1 examples/sec; 0.028 sec/batch)
2018-02-01 15:25:53.443857: step 105600, loss = 2.03 (5073.4 examples/sec; 0.025 sec/batch)
2018-02-01 15:25:56.151396: step 105700, loss = 2.04 (4727.5 examples/sec; 0.027 sec/batch)
2018-02-01 15:25:59.025757: step 105800, loss = 2.14 (4453.2 examples/sec; 0.029 sec/batch)
2018-02-01 15:26:00.823278: step 105900, loss = 2.16 (7120.9 examples/sec; 0.018 sec/batch)
2018-02-01 15:26:02.281364: step 106000, loss = 2.06 (8778.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:26:03.739239: step 106100, loss = 2.01 (8779.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:26:05.169013: step 106200, loss = 2.06 (8952.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:08.213277: step 106300, loss = 2.07 (4204.6 examples/sec; 0.030 sec/batch)
2018-02-01 15:26:09.670935: step 106400, loss = 2.07 (8781.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:26:11.113438: step 106500, loss = 2.01 (8873.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:12.550641: step 106600, loss = 2.03 (8906.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:13.995307: step 106700, loss = 2.03 (8860.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:15.436230: step 106800, loss = 2.11 (8883.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:16.893839: step 106900, loss = 2.03 (8781.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:26:18.328586: step 107000, loss = 2.16 (8921.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:19.773766: step 107100, loss = 2.13 (8857.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:21.220768: step 107200, loss = 2.09 (8845.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:22.652404: step 107300, loss = 2.18 (8940.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:24.077485: step 107400, loss = 2.06 (8981.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:25.548131: step 107500, loss = 2.12 (8703.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:26:26.990874: step 107600, loss = 2.11 (8872.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:28.419373: step 107700, loss = 2.14 (8960.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:29.875437: step 107800, loss = 2.08 (8790.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:26:32.138105: step 107900, loss = 2.10 (5657.0 examples/sec; 0.023 sec/batch)
2018-02-01 15:26:34.889997: step 108000, loss = 2.05 (4651.3 examples/sec; 0.028 sec/batch)
2018-02-01 15:26:44.062510: step 108100, loss = 2.08 (1395.5 examples/sec; 0.092 sec/batch)
2018-02-01 15:26:45.491214: step 108200, loss = 2.13 (8959.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:46.942473: step 108300, loss = 2.18 (8819.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:26:48.403451: step 108400, loss = 2.02 (8761.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:26:49.848287: step 108500, loss = 2.06 (8859.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:51.305370: step 108600, loss = 2.08 (8784.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:26:52.750703: step 108700, loss = 2.02 (8856.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:26:54.225727: step 108800, loss = 2.15 (8677.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:26:55.681472: step 108900, loss = 2.12 (8792.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:26:57.133081: step 109000, loss = 2.15 (8817.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:26:58.582398: step 109100, loss = 2.04 (8831.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:00.039451: step 109200, loss = 2.14 (8784.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:27:01.505093: step 109300, loss = 2.21 (8733.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:27:02.968032: step 109400, loss = 2.11 (8749.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:27:04.410274: step 109500, loss = 2.09 (8875.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:07.451611: step 109600, loss = 2.09 (4208.7 examples/sec; 0.030 sec/batch)
2018-02-01 15:27:08.885372: step 109700, loss = 2.10 (8927.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:10.331063: step 109800, loss = 2.08 (8853.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:11.778943: step 109900, loss = 2.14 (8840.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:13.251182: step 110000, loss = 2.06 (8694.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:27:15.744059: step 110100, loss = 2.12 (5134.6 examples/sec; 0.025 sec/batch)
2018-02-01 15:27:18.251075: step 110200, loss = 2.08 (5105.7 examples/sec; 0.025 sec/batch)
2018-02-01 15:27:20.851506: step 110300, loss = 2.07 (4922.3 examples/sec; 0.026 sec/batch)
2018-02-01 15:27:23.271468: step 110400, loss = 2.11 (5289.3 examples/sec; 0.024 sec/batch)
2018-02-01 15:27:25.698050: step 110500, loss = 2.04 (5274.9 examples/sec; 0.024 sec/batch)
2018-02-01 15:27:28.448601: step 110600, loss = 2.00 (4653.6 examples/sec; 0.028 sec/batch)
2018-02-01 15:27:30.999676: step 110700, loss = 2.17 (5017.5 examples/sec; 0.026 sec/batch)
2018-02-01 15:27:32.462062: step 110800, loss = 2.12 (8752.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:27:33.909136: step 110900, loss = 2.15 (8845.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:35.353848: step 111000, loss = 2.13 (8859.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:38.415458: step 111100, loss = 2.11 (4180.8 examples/sec; 0.031 sec/batch)
2018-02-01 15:27:39.877752: step 111200, loss = 2.07 (8753.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:27:41.383012: step 111300, loss = 2.11 (8503.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:27:42.826853: step 111400, loss = 2.07 (8865.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:44.270672: step 111500, loss = 2.21 (8865.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:45.705514: step 111600, loss = 2.15 (8920.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:47.164279: step 111700, loss = 2.09 (8774.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:27:48.567835: step 111800, loss = 2.02 (9119.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:50.033272: step 111900, loss = 2.11 (8734.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:27:51.486585: step 112000, loss = 2.09 (8807.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:27:52.917280: step 112100, loss = 2.04 (8946.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:54.366899: step 112200, loss = 2.07 (8829.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:55.790616: step 112300, loss = 2.02 (8990.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:27:57.254763: step 112400, loss = 2.05 (8742.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:27:58.694646: step 112500, loss = 2.09 (8889.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:28:00.122340: step 112600, loss = 2.12 (8965.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:28:01.591367: step 112700, loss = 1.95 (8713.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:28:03.937310: step 112800, loss = 2.09 (5456.2 examples/sec; 0.023 sec/batch)
2018-02-01 15:28:14.284424: step 112900, loss = 2.07 (1237.1 examples/sec; 0.103 sec/batch)
2018-02-01 15:28:15.732395: step 113000, loss = 2.04 (8840.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:28:17.166034: step 113100, loss = 2.13 (8928.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:28:18.626733: step 113200, loss = 2.18 (8762.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:28:20.079697: step 113300, loss = 2.19 (8809.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:28:21.511316: step 113400, loss = 2.13 (8940.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:28:22.945779: step 113500, loss = 2.14 (8923.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:28:24.385429: step 113600, loss = 2.05 (8891.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:28:25.827811: step 113700, loss = 2.06 (8874.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:28:27.267774: step 113800, loss = 2.09 (8889.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:28:28.718873: step 113900, loss = 2.05 (8820.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:28:30.168931: step 114000, loss = 2.15 (8827.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:28:31.606779: step 114100, loss = 2.19 (8902.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:28:33.077745: step 114200, loss = 2.14 (8701.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:28:34.627066: step 114300, loss = 2.05 (8261.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:28:37.708156: step 114400, loss = 2.11 (4154.4 examples/sec; 0.031 sec/batch)
2018-02-01 15:28:39.222306: step 114500, loss = 2.04 (8453.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:28:40.811403: step 114600, loss = 2.00 (8054.9 examples/sec; 0.016 sec/batch)
2018-02-01 15:28:42.509109: step 114700, loss = 1.95 (7539.6 examples/sec; 0.017 sec/batch)
2018-02-01 15:28:44.166778: step 114800, loss = 2.06 (7721.7 examples/sec; 0.017 sec/batch)
2018-02-01 15:28:46.992110: step 114900, loss = 2.10 (4530.4 examples/sec; 0.028 sec/batch)
2018-02-01 15:28:49.509051: step 115000, loss = 2.04 (5085.5 examples/sec; 0.025 sec/batch)
2018-02-01 15:28:52.136338: step 115100, loss = 2.09 (4871.9 examples/sec; 0.026 sec/batch)
2018-02-01 15:28:54.918825: step 115200, loss = 2.17 (4600.2 examples/sec; 0.028 sec/batch)
2018-02-01 15:28:57.718334: step 115300, loss = 2.10 (4572.2 examples/sec; 0.028 sec/batch)
2018-02-01 15:29:00.345325: step 115400, loss = 2.24 (4872.5 examples/sec; 0.026 sec/batch)
2018-02-01 15:29:02.090070: step 115500, loss = 2.11 (7336.3 examples/sec; 0.017 sec/batch)
2018-02-01 15:29:03.519644: step 115600, loss = 2.06 (8953.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:29:04.947705: step 115700, loss = 2.03 (8963.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:29:08.020793: step 115800, loss = 2.11 (4165.2 examples/sec; 0.031 sec/batch)
2018-02-01 15:29:09.504880: step 115900, loss = 2.17 (8624.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:10.929603: step 116000, loss = 2.08 (8984.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:29:12.386854: step 116100, loss = 2.05 (8783.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:13.837592: step 116200, loss = 2.21 (8823.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:15.279769: step 116300, loss = 2.05 (8875.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:29:16.750049: step 116400, loss = 2.13 (8705.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:18.225746: step 116500, loss = 2.06 (8673.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:19.678636: step 116600, loss = 2.17 (8810.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:21.129809: step 116700, loss = 2.02 (8820.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:22.588658: step 116800, loss = 2.10 (8774.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:24.050345: step 116900, loss = 2.10 (8757.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:25.501290: step 117000, loss = 2.09 (8821.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:26.956002: step 117100, loss = 2.15 (8799.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:28.413010: step 117200, loss = 2.06 (8785.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:29.868289: step 117300, loss = 2.03 (8795.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:31.324600: step 117400, loss = 2.10 (8789.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:33.490199: step 117500, loss = 2.11 (5910.6 examples/sec; 0.022 sec/batch)
2018-02-01 15:29:44.198400: step 117600, loss = 2.05 (1195.3 examples/sec; 0.107 sec/batch)
2018-02-01 15:29:45.640804: step 117700, loss = 2.06 (8874.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:29:47.099956: step 117800, loss = 2.08 (8772.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:48.537693: step 117900, loss = 2.05 (8902.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:29:50.001215: step 118000, loss = 2.04 (8746.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:51.443958: step 118100, loss = 2.14 (8872.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:29:52.893838: step 118200, loss = 2.05 (8828.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:29:54.363504: step 118300, loss = 2.07 (8709.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:55.798468: step 118400, loss = 2.13 (8920.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:29:57.257739: step 118500, loss = 2.02 (8771.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:29:58.702783: step 118600, loss = 2.10 (8857.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:30:00.151777: step 118700, loss = 2.17 (8833.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:30:01.610010: step 118800, loss = 2.15 (8777.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:03.083896: step 118900, loss = 2.08 (8684.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:04.532537: step 119000, loss = 2.18 (8835.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:30:07.524194: step 119100, loss = 2.19 (4278.6 examples/sec; 0.030 sec/batch)
2018-02-01 15:30:08.995699: step 119200, loss = 2.11 (8698.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:10.468914: step 119300, loss = 2.12 (8688.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:11.919155: step 119400, loss = 2.13 (8826.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:13.390402: step 119500, loss = 2.07 (8700.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:15.619271: step 119600, loss = 2.07 (5742.8 examples/sec; 0.022 sec/batch)
2018-02-01 15:30:18.285807: step 119700, loss = 2.09 (4800.2 examples/sec; 0.027 sec/batch)
2018-02-01 15:30:21.196312: step 119800, loss = 2.12 (4397.9 examples/sec; 0.029 sec/batch)
2018-02-01 15:30:24.055641: step 119900, loss = 2.05 (4476.6 examples/sec; 0.029 sec/batch)
2018-02-01 15:30:26.830427: step 120000, loss = 2.11 (4613.0 examples/sec; 0.028 sec/batch)
2018-02-01 15:30:29.507206: step 120100, loss = 2.07 (4781.9 examples/sec; 0.027 sec/batch)
2018-02-01 15:30:31.397307: step 120200, loss = 2.08 (6772.1 examples/sec; 0.019 sec/batch)
2018-02-01 15:30:32.863719: step 120300, loss = 2.05 (8728.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:34.333742: step 120400, loss = 2.07 (8707.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:35.790221: step 120500, loss = 2.07 (8788.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:38.786165: step 120600, loss = 2.00 (4272.4 examples/sec; 0.030 sec/batch)
2018-02-01 15:30:40.240215: step 120700, loss = 1.99 (8803.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:41.702224: step 120800, loss = 2.01 (8755.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:43.165184: step 120900, loss = 2.15 (8749.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:44.634561: step 121000, loss = 2.11 (8711.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:46.096360: step 121100, loss = 2.05 (8756.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:47.550973: step 121200, loss = 2.14 (8799.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:49.004678: step 121300, loss = 2.09 (8805.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:50.462510: step 121400, loss = 2.02 (8780.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:51.914298: step 121500, loss = 2.10 (8816.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:53.355577: step 121600, loss = 2.10 (8881.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:30:54.818942: step 121700, loss = 2.16 (8747.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:30:56.266002: step 121800, loss = 2.03 (8845.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:30:57.706810: step 121900, loss = 2.21 (8883.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:30:59.152608: step 122000, loss = 2.05 (8853.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:31:00.624916: step 122100, loss = 2.06 (8693.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:02.732703: step 122200, loss = 2.13 (6072.7 examples/sec; 0.021 sec/batch)
2018-02-01 15:31:05.322607: step 122300, loss = 2.07 (4942.3 examples/sec; 0.026 sec/batch)
2018-02-01 15:31:14.734039: step 122400, loss = 2.18 (1360.0 examples/sec; 0.094 sec/batch)
2018-02-01 15:31:16.201619: step 122500, loss = 2.16 (8721.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:17.676067: step 122600, loss = 2.01 (8681.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:19.132016: step 122700, loss = 2.04 (8791.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:20.575591: step 122800, loss = 2.05 (8866.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:31:22.031806: step 122900, loss = 2.05 (8789.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:23.481124: step 123000, loss = 2.17 (8831.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:31:24.966655: step 123100, loss = 2.02 (8616.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:26.441472: step 123200, loss = 2.13 (8679.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:27.918640: step 123300, loss = 2.10 (8665.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:29.374042: step 123400, loss = 2.01 (8794.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:30.844066: step 123500, loss = 2.08 (8707.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:32.284580: step 123600, loss = 2.06 (8885.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:31:33.772467: step 123700, loss = 2.11 (8602.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:35.200918: step 123800, loss = 2.15 (8960.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:31:38.290800: step 123900, loss = 2.16 (4142.6 examples/sec; 0.031 sec/batch)
2018-02-01 15:31:39.769490: step 124000, loss = 2.18 (8656.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:41.227390: step 124100, loss = 2.04 (8779.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:42.681618: step 124200, loss = 2.17 (8801.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:31:44.666052: step 124300, loss = 2.09 (6450.2 examples/sec; 0.020 sec/batch)
2018-02-01 15:31:47.610353: step 124400, loss = 2.00 (4347.4 examples/sec; 0.029 sec/batch)
2018-02-01 15:31:50.434509: step 124500, loss = 2.15 (4532.3 examples/sec; 0.028 sec/batch)
2018-02-01 15:31:53.195176: step 124600, loss = 2.11 (4636.6 examples/sec; 0.028 sec/batch)
2018-02-01 15:31:56.010295: step 124700, loss = 2.03 (4546.9 examples/sec; 0.028 sec/batch)
2018-02-01 15:31:58.458507: step 124800, loss = 2.09 (5228.3 examples/sec; 0.024 sec/batch)
2018-02-01 15:32:00.644941: step 124900, loss = 2.17 (5854.3 examples/sec; 0.022 sec/batch)
2018-02-01 15:32:02.102505: step 125000, loss = 2.13 (8781.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:03.546164: step 125100, loss = 2.04 (8866.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:32:04.991598: step 125200, loss = 2.11 (8855.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:32:07.976516: step 125300, loss = 2.10 (4288.2 examples/sec; 0.030 sec/batch)
2018-02-01 15:32:09.421132: step 125400, loss = 2.16 (8860.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:32:10.851886: step 125500, loss = 2.14 (8946.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:32:12.300573: step 125600, loss = 2.05 (8835.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:32:13.761220: step 125700, loss = 2.10 (8763.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:15.210192: step 125800, loss = 2.14 (8833.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:32:16.679107: step 125900, loss = 2.12 (8713.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:18.131991: step 126000, loss = 2.15 (8810.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:19.594412: step 126100, loss = 2.14 (8752.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:21.042336: step 126200, loss = 2.10 (8840.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:32:22.489900: step 126300, loss = 2.12 (8842.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:32:23.946055: step 126400, loss = 2.05 (8790.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:25.405952: step 126500, loss = 2.10 (8767.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:26.896895: step 126600, loss = 2.10 (8585.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:28.372720: step 126700, loss = 2.04 (8673.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:29.841055: step 126800, loss = 2.17 (8717.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:31.452429: step 126900, loss = 2.00 (7943.5 examples/sec; 0.016 sec/batch)
2018-02-01 15:32:33.983348: step 127000, loss = 2.03 (5057.5 examples/sec; 0.025 sec/batch)
2018-02-01 15:32:44.166939: step 127100, loss = 2.18 (1256.9 examples/sec; 0.102 sec/batch)
2018-02-01 15:32:45.633040: step 127200, loss = 2.04 (8730.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:47.140212: step 127300, loss = 2.13 (8492.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:48.640058: step 127400, loss = 2.20 (8534.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:50.114218: step 127500, loss = 2.25 (8682.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:51.561086: step 127600, loss = 2.14 (8846.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:32:53.001129: step 127700, loss = 2.11 (8888.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:32:54.443451: step 127800, loss = 2.10 (8874.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:32:55.893864: step 127900, loss = 2.13 (8825.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:32:57.341337: step 128000, loss = 2.08 (8843.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:32:58.808988: step 128100, loss = 2.07 (8721.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:00.286402: step 128200, loss = 2.13 (8663.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:01.727813: step 128300, loss = 2.05 (8880.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:33:03.156215: step 128400, loss = 2.10 (8961.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:33:04.602658: step 128500, loss = 2.05 (8849.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:33:07.632413: step 128600, loss = 2.15 (4224.8 examples/sec; 0.030 sec/batch)
2018-02-01 15:33:09.116862: step 128700, loss = 2.04 (8622.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:10.560540: step 128800, loss = 2.20 (8866.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:33:12.032622: step 128900, loss = 2.05 (8695.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:13.497330: step 129000, loss = 2.08 (8738.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:16.211159: step 129100, loss = 2.09 (4716.6 examples/sec; 0.027 sec/batch)
2018-02-01 15:33:18.810135: step 129200, loss = 2.09 (4925.0 examples/sec; 0.026 sec/batch)
2018-02-01 15:33:21.564523: step 129300, loss = 2.08 (4647.1 examples/sec; 0.028 sec/batch)
2018-02-01 15:33:23.872432: step 129400, loss = 2.11 (5546.1 examples/sec; 0.023 sec/batch)
2018-02-01 15:33:26.812371: step 129500, loss = 2.05 (4353.8 examples/sec; 0.029 sec/batch)
2018-02-01 15:33:29.348653: step 129600, loss = 2.19 (5046.8 examples/sec; 0.025 sec/batch)
2018-02-01 15:33:31.400617: step 129700, loss = 2.10 (6237.9 examples/sec; 0.021 sec/batch)
2018-02-01 15:33:32.864984: step 129800, loss = 2.06 (8741.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:34.319796: step 129900, loss = 2.10 (8798.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:35.760845: step 130000, loss = 2.03 (8882.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:33:38.780265: step 130100, loss = 2.14 (4239.2 examples/sec; 0.030 sec/batch)
2018-02-01 15:33:40.241760: step 130200, loss = 2.01 (8758.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:41.691099: step 130300, loss = 2.17 (8831.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:33:43.159412: step 130400, loss = 2.20 (8717.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:44.608605: step 130500, loss = 2.04 (8832.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:33:46.067508: step 130600, loss = 2.09 (8773.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:47.503680: step 130700, loss = 2.02 (8912.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:33:48.971988: step 130800, loss = 2.05 (8717.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:50.434927: step 130900, loss = 2.18 (8749.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:51.893022: step 131000, loss = 2.19 (8778.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:53.362224: step 131100, loss = 2.14 (8712.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:54.789114: step 131200, loss = 2.19 (8970.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:33:56.264189: step 131300, loss = 2.16 (8677.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:57.714305: step 131400, loss = 2.01 (8826.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:33:59.167154: step 131500, loss = 2.03 (8810.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:34:00.614632: step 131600, loss = 2.10 (8843.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:34:02.650992: step 131700, loss = 2.18 (6285.7 examples/sec; 0.020 sec/batch)
2018-02-01 15:34:05.448750: step 131800, loss = 2.21 (4575.1 examples/sec; 0.028 sec/batch)
2018-02-01 15:34:14.745536: step 131900, loss = 2.09 (1376.8 examples/sec; 0.093 sec/batch)
2018-02-01 15:34:16.175049: step 132000, loss = 2.12 (8954.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:34:17.632682: step 132100, loss = 2.03 (8781.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:34:19.083411: step 132200, loss = 2.13 (8823.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:34:20.524630: step 132300, loss = 2.12 (8881.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:34:21.995134: step 132400, loss = 2.14 (8704.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:34:23.430266: step 132500, loss = 2.10 (8919.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:34:24.875429: step 132600, loss = 2.11 (8857.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:34:26.336243: step 132700, loss = 2.21 (8762.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:34:27.781204: step 132800, loss = 2.09 (8858.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:34:29.243700: step 132900, loss = 2.04 (8752.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:34:30.720148: step 133000, loss = 2.06 (8669.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:34:32.164532: step 133100, loss = 2.15 (8861.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:34:33.615547: step 133200, loss = 2.06 (8821.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:34:35.046654: step 133300, loss = 2.08 (8944.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:34:38.038818: step 133400, loss = 2.06 (4277.8 examples/sec; 0.030 sec/batch)
2018-02-01 15:34:39.483922: step 133500, loss = 2.09 (8857.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:34:40.940425: step 133600, loss = 2.14 (8788.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:34:42.418045: step 133700, loss = 2.12 (8662.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:34:44.096138: step 133800, loss = 2.13 (7627.7 examples/sec; 0.017 sec/batch)
2018-02-01 15:34:46.784815: step 133900, loss = 2.07 (4760.7 examples/sec; 0.027 sec/batch)
2018-02-01 15:34:49.327854: step 134000, loss = 2.10 (5033.3 examples/sec; 0.025 sec/batch)
2018-02-01 15:34:52.376900: step 134100, loss = 2.05 (4198.0 examples/sec; 0.030 sec/batch)
2018-02-01 15:34:55.140622: step 134200, loss = 2.09 (4631.4 examples/sec; 0.028 sec/batch)
2018-02-01 15:34:57.651473: step 134300, loss = 1.99 (5097.9 examples/sec; 0.025 sec/batch)
2018-02-01 15:35:00.280583: step 134400, loss = 2.23 (4868.6 examples/sec; 0.026 sec/batch)
2018-02-01 15:35:01.887341: step 134500, loss = 2.09 (7966.3 examples/sec; 0.016 sec/batch)
2018-02-01 15:35:03.356293: step 134600, loss = 2.15 (8713.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:04.849492: step 134700, loss = 2.12 (8572.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:07.895131: step 134800, loss = 2.19 (4202.7 examples/sec; 0.030 sec/batch)
2018-02-01 15:35:09.370539: step 134900, loss = 2.08 (8675.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:10.837343: step 135000, loss = 2.14 (8726.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:12.273509: step 135100, loss = 2.15 (8912.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:35:13.729724: step 135200, loss = 2.08 (8789.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:15.181692: step 135300, loss = 2.11 (8815.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:16.641620: step 135400, loss = 2.07 (8767.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:18.087435: step 135500, loss = 2.01 (8853.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:35:19.533095: step 135600, loss = 2.00 (8854.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:35:21.002084: step 135700, loss = 2.07 (8713.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:22.454615: step 135800, loss = 2.10 (8812.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:23.899493: step 135900, loss = 2.04 (8858.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:35:25.371391: step 136000, loss = 2.09 (8696.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:26.829936: step 136100, loss = 2.09 (8775.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:28.289771: step 136200, loss = 2.08 (8768.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:29.735732: step 136300, loss = 2.15 (8852.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:35:31.196393: step 136400, loss = 2.08 (8763.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:33.817574: step 136500, loss = 2.10 (4883.3 examples/sec; 0.026 sec/batch)
2018-02-01 15:35:44.069163: step 136600, loss = 1.99 (1248.6 examples/sec; 0.103 sec/batch)
2018-02-01 15:35:45.518655: step 136700, loss = 2.12 (8830.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:35:46.973195: step 136800, loss = 1.98 (8800.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:48.440654: step 136900, loss = 2.07 (8722.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:49.892907: step 137000, loss = 2.09 (8813.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:51.330792: step 137100, loss = 2.10 (8902.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:35:52.783496: step 137200, loss = 2.10 (8811.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:54.231029: step 137300, loss = 2.12 (8842.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:35:55.683713: step 137400, loss = 2.09 (8811.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:57.153261: step 137500, loss = 2.10 (8710.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:35:58.629140: step 137600, loss = 2.08 (8672.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:00.073013: step 137700, loss = 2.04 (8865.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:36:01.509452: step 137800, loss = 2.07 (8910.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:36:02.965285: step 137900, loss = 2.04 (8792.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:04.418739: step 138000, loss = 2.10 (8806.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:05.865273: step 138100, loss = 2.15 (8848.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:36:08.873597: step 138200, loss = 2.09 (4254.9 examples/sec; 0.030 sec/batch)
2018-02-01 15:36:10.330720: step 138300, loss = 2.04 (8784.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:11.785678: step 138400, loss = 2.10 (8797.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:13.278884: step 138500, loss = 2.10 (8572.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:15.679144: step 138600, loss = 2.13 (5332.8 examples/sec; 0.024 sec/batch)
2018-02-01 15:36:18.205126: step 138700, loss = 2.07 (5067.3 examples/sec; 0.025 sec/batch)
2018-02-01 15:36:20.898974: step 138800, loss = 2.02 (4751.6 examples/sec; 0.027 sec/batch)
2018-02-01 15:36:23.589574: step 138900, loss = 2.08 (4757.3 examples/sec; 0.027 sec/batch)
2018-02-01 15:36:26.241642: step 139000, loss = 2.17 (4826.4 examples/sec; 0.027 sec/batch)
2018-02-01 15:36:28.763409: step 139100, loss = 2.07 (5075.8 examples/sec; 0.025 sec/batch)
2018-02-01 15:36:31.220866: step 139200, loss = 1.96 (5208.6 examples/sec; 0.025 sec/batch)
2018-02-01 15:36:32.681337: step 139300, loss = 2.06 (8764.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:34.143493: step 139400, loss = 2.08 (8754.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:35.611609: step 139500, loss = 2.16 (8718.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:38.721607: step 139600, loss = 2.10 (4115.8 examples/sec; 0.031 sec/batch)
2018-02-01 15:36:40.204657: step 139700, loss = 2.02 (8630.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:41.667082: step 139800, loss = 2.14 (8752.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:43.131549: step 139900, loss = 2.04 (8740.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:44.622249: step 140000, loss = 2.11 (8586.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:46.081794: step 140100, loss = 2.08 (8769.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:47.535429: step 140200, loss = 2.05 (8805.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:49.002952: step 140300, loss = 2.05 (8722.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:50.449571: step 140400, loss = 2.13 (8848.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:36:51.905117: step 140500, loss = 2.04 (8794.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:53.375378: step 140600, loss = 2.12 (8705.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:54.827065: step 140700, loss = 2.01 (8817.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:56.302402: step 140800, loss = 2.09 (8676.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:36:57.749649: step 140900, loss = 2.09 (8844.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:36:59.192340: step 141000, loss = 1.99 (8872.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:37:00.670849: step 141100, loss = 2.09 (8657.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:02.694089: step 141200, loss = 2.07 (6326.5 examples/sec; 0.020 sec/batch)
2018-02-01 15:37:05.390069: step 141300, loss = 2.07 (4747.8 examples/sec; 0.027 sec/batch)
2018-02-01 15:37:14.857984: step 141400, loss = 2.11 (1351.9 examples/sec; 0.095 sec/batch)
2018-02-01 15:37:16.331184: step 141500, loss = 2.07 (8688.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:17.806951: step 141600, loss = 2.08 (8673.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:19.274929: step 141700, loss = 2.17 (8719.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:20.738184: step 141800, loss = 2.14 (8747.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:22.201580: step 141900, loss = 2.13 (8746.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:23.647649: step 142000, loss = 2.01 (8851.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:37:25.098525: step 142100, loss = 2.06 (8822.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:26.557112: step 142200, loss = 2.01 (8775.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:28.019281: step 142300, loss = 2.09 (8754.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:29.466574: step 142400, loss = 2.11 (8844.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:37:30.928809: step 142500, loss = 2.08 (8753.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:32.410500: step 142600, loss = 2.04 (8638.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:33.889122: step 142700, loss = 2.12 (8656.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:35.343627: step 142800, loss = 2.06 (8800.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:38.329512: step 142900, loss = 2.14 (4286.8 examples/sec; 0.030 sec/batch)
2018-02-01 15:37:39.777934: step 143000, loss = 2.12 (8837.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:37:41.253063: step 143100, loss = 2.09 (8677.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:42.715670: step 143200, loss = 2.03 (8751.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:37:44.577836: step 143300, loss = 2.00 (6873.7 examples/sec; 0.019 sec/batch)
2018-02-01 15:37:47.249938: step 143400, loss = 2.03 (4790.2 examples/sec; 0.027 sec/batch)
2018-02-01 15:37:49.842442: step 143500, loss = 2.06 (4937.3 examples/sec; 0.026 sec/batch)
2018-02-01 15:37:52.545140: step 143600, loss = 2.12 (4736.0 examples/sec; 0.027 sec/batch)
2018-02-01 15:37:54.929403: step 143700, loss = 2.06 (5368.5 examples/sec; 0.024 sec/batch)
2018-02-01 15:37:57.399610: step 143800, loss = 2.14 (5181.8 examples/sec; 0.025 sec/batch)
2018-02-01 15:38:00.079346: step 143900, loss = 2.04 (4776.6 examples/sec; 0.027 sec/batch)
2018-02-01 15:38:02.053945: step 144000, loss = 2.16 (6482.3 examples/sec; 0.020 sec/batch)
2018-02-01 15:38:03.509837: step 144100, loss = 2.23 (8791.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:04.976612: step 144200, loss = 2.09 (8726.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:07.960240: step 144300, loss = 2.06 (4290.1 examples/sec; 0.030 sec/batch)
2018-02-01 15:38:09.438851: step 144400, loss = 2.03 (8656.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:10.892097: step 144500, loss = 2.13 (8807.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:12.314609: step 144600, loss = 2.14 (8998.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:38:13.772415: step 144700, loss = 2.04 (8780.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:15.233101: step 144800, loss = 2.09 (8763.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:16.703725: step 144900, loss = 2.19 (8703.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:18.159414: step 145000, loss = 2.15 (8793.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:19.601750: step 145100, loss = 2.05 (8874.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:38:21.065697: step 145200, loss = 2.11 (8743.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:22.527767: step 145300, loss = 2.02 (8754.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:23.986192: step 145400, loss = 2.04 (8776.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:25.430986: step 145500, loss = 2.03 (8859.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:38:26.885790: step 145600, loss = 2.08 (8798.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:28.348466: step 145700, loss = 2.05 (8751.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:29.815635: step 145800, loss = 2.07 (8724.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:31.299785: step 145900, loss = 2.06 (8624.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:33.423166: step 146000, loss = 2.07 (6028.1 examples/sec; 0.021 sec/batch)
2018-02-01 15:38:35.998856: step 146100, loss = 2.06 (4969.5 examples/sec; 0.026 sec/batch)
2018-02-01 15:38:45.578412: step 146200, loss = 2.19 (1336.2 examples/sec; 0.096 sec/batch)
2018-02-01 15:38:47.038645: step 146300, loss = 2.01 (8765.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:48.513851: step 146400, loss = 2.09 (8676.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:49.938524: step 146500, loss = 2.09 (8984.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:38:51.396112: step 146600, loss = 2.01 (8781.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:52.838153: step 146700, loss = 2.04 (8876.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:38:54.310506: step 146800, loss = 2.13 (8693.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:38:55.753062: step 146900, loss = 2.07 (8873.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:38:57.194449: step 147000, loss = 2.09 (8880.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:38:58.646002: step 147100, loss = 2.07 (8818.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:00.100887: step 147200, loss = 2.25 (8797.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:01.582014: step 147300, loss = 2.21 (8642.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:03.021326: step 147400, loss = 2.00 (8893.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:39:04.468596: step 147500, loss = 1.96 (8844.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:39:05.925022: step 147600, loss = 2.11 (8788.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:08.921947: step 147700, loss = 2.12 (4271.0 examples/sec; 0.030 sec/batch)
2018-02-01 15:39:10.366658: step 147800, loss = 2.13 (8859.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:39:11.828736: step 147900, loss = 2.17 (8754.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:13.290047: step 148000, loss = 2.00 (8759.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:15.166838: step 148100, loss = 2.10 (6820.2 examples/sec; 0.019 sec/batch)
2018-02-01 15:39:17.828638: step 148200, loss = 2.18 (4808.8 examples/sec; 0.027 sec/batch)
2018-02-01 15:39:20.491222: step 148300, loss = 2.06 (4807.4 examples/sec; 0.027 sec/batch)
2018-02-01 15:39:23.146526: step 148400, loss = 2.18 (4820.5 examples/sec; 0.027 sec/batch)
2018-02-01 15:39:25.842659: step 148500, loss = 2.09 (4747.5 examples/sec; 0.027 sec/batch)
2018-02-01 15:39:28.634661: step 148600, loss = 2.04 (4584.5 examples/sec; 0.028 sec/batch)
2018-02-01 15:39:31.259796: step 148700, loss = 2.06 (4875.9 examples/sec; 0.026 sec/batch)
2018-02-01 15:39:32.728164: step 148800, loss = 2.08 (8717.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:34.175906: step 148900, loss = 2.08 (8841.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:39:35.614608: step 149000, loss = 2.08 (8896.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:39:38.583702: step 149100, loss = 2.07 (4311.1 examples/sec; 0.030 sec/batch)
2018-02-01 15:39:40.048243: step 149200, loss = 2.16 (8739.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:41.499374: step 149300, loss = 2.11 (8820.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:42.951999: step 149400, loss = 2.12 (8811.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:44.404162: step 149500, loss = 2.05 (8814.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:45.862207: step 149600, loss = 1.98 (8778.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:47.317376: step 149700, loss = 2.07 (8796.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:48.765136: step 149800, loss = 2.13 (8841.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:39:50.224158: step 149900, loss = 2.08 (8773.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:51.683214: step 150000, loss = 2.16 (8772.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:53.169291: step 150100, loss = 2.05 (8613.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:54.626880: step 150200, loss = 1.98 (8781.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:56.099254: step 150300, loss = 2.02 (8693.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:39:57.528580: step 150400, loss = 2.14 (8955.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:39:59.006109: step 150500, loss = 1.98 (8663.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:00.451441: step 150600, loss = 2.03 (8856.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:40:01.915425: step 150700, loss = 2.11 (8743.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:04.140122: step 150800, loss = 2.03 (5753.6 examples/sec; 0.022 sec/batch)
2018-02-01 15:40:14.685655: step 150900, loss = 2.12 (1213.8 examples/sec; 0.105 sec/batch)
2018-02-01 15:40:16.142378: step 151000, loss = 2.02 (8786.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:17.583301: step 151100, loss = 2.04 (8883.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:40:19.032606: step 151200, loss = 2.14 (8831.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:40:20.474590: step 151300, loss = 2.10 (8876.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:40:21.933586: step 151400, loss = 2.11 (8773.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:23.377866: step 151500, loss = 2.10 (8862.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:40:24.843129: step 151600, loss = 2.06 (8735.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:26.300955: step 151700, loss = 2.08 (8780.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:27.775630: step 151800, loss = 2.16 (8679.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:29.249168: step 151900, loss = 2.06 (8686.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:30.689842: step 152000, loss = 2.01 (8884.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:40:32.140009: step 152100, loss = 2.16 (8826.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:33.587300: step 152200, loss = 2.02 (8844.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:40:35.045118: step 152300, loss = 2.00 (8780.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:38.138436: step 152400, loss = 2.09 (4138.0 examples/sec; 0.031 sec/batch)
2018-02-01 15:40:39.608918: step 152500, loss = 2.15 (8704.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:41.081542: step 152600, loss = 2.09 (8692.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:42.521670: step 152700, loss = 2.11 (8888.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:40:43.976508: step 152800, loss = 2.07 (8798.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:40:46.520927: step 152900, loss = 2.12 (5030.6 examples/sec; 0.025 sec/batch)
2018-02-01 15:40:49.501227: step 153000, loss = 2.22 (4294.9 examples/sec; 0.030 sec/batch)
2018-02-01 15:40:52.212759: step 153100, loss = 2.10 (4720.6 examples/sec; 0.027 sec/batch)
2018-02-01 15:40:54.838538: step 153200, loss = 2.08 (4874.7 examples/sec; 0.026 sec/batch)
2018-02-01 15:40:57.579316: step 153300, loss = 2.12 (4670.2 examples/sec; 0.027 sec/batch)
2018-02-01 15:41:00.209006: step 153400, loss = 2.08 (4867.5 examples/sec; 0.026 sec/batch)
2018-02-01 15:41:01.887028: step 153500, loss = 2.09 (7628.0 examples/sec; 0.017 sec/batch)
2018-02-01 15:41:03.333364: step 153600, loss = 2.17 (8849.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:41:04.786667: step 153700, loss = 2.08 (8807.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:07.779819: step 153800, loss = 2.06 (4276.4 examples/sec; 0.030 sec/batch)
2018-02-01 15:41:09.227040: step 153900, loss = 2.08 (8844.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:41:10.696816: step 154000, loss = 2.17 (8708.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:12.165282: step 154100, loss = 2.17 (8716.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:13.613400: step 154200, loss = 2.01 (8839.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:41:15.065424: step 154300, loss = 2.00 (8815.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:16.534252: step 154400, loss = 2.12 (8714.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:17.984187: step 154500, loss = 2.11 (8828.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:41:19.445951: step 154600, loss = 2.18 (8756.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:20.884290: step 154700, loss = 2.06 (8899.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:41:22.333631: step 154800, loss = 2.14 (8831.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:41:23.758647: step 154900, loss = 2.07 (8982.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:41:25.207545: step 155000, loss = 2.17 (8834.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:41:26.669938: step 155100, loss = 2.11 (8752.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:28.101481: step 155200, loss = 2.07 (8941.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:41:29.557284: step 155300, loss = 2.14 (8792.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:31.029115: step 155400, loss = 2.27 (8696.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:33.227354: step 155500, loss = 2.11 (5822.8 examples/sec; 0.022 sec/batch)
2018-02-01 15:41:35.984901: step 155600, loss = 2.05 (4641.8 examples/sec; 0.028 sec/batch)
2018-02-01 15:41:45.236921: step 155700, loss = 2.12 (1383.5 examples/sec; 0.093 sec/batch)
2018-02-01 15:41:46.701570: step 155800, loss = 2.07 (8739.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:48.140345: step 155900, loss = 2.02 (8896.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:41:49.591383: step 156000, loss = 2.15 (8821.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:51.050648: step 156100, loss = 1.95 (8771.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:52.485085: step 156200, loss = 2.06 (8923.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:41:53.925066: step 156300, loss = 2.04 (8889.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:41:55.382283: step 156400, loss = 2.14 (8783.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:56.844960: step 156500, loss = 2.11 (8751.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:58.303248: step 156600, loss = 2.05 (8777.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:41:59.738059: step 156700, loss = 2.17 (8921.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:42:01.197607: step 156800, loss = 2.05 (8769.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:02.652481: step 156900, loss = 2.10 (8798.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:04.118204: step 157000, loss = 2.13 (8732.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:05.601223: step 157100, loss = 2.06 (8631.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:08.644158: step 157200, loss = 2.06 (4206.5 examples/sec; 0.030 sec/batch)
2018-02-01 15:42:10.110078: step 157300, loss = 2.02 (8731.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:11.565298: step 157400, loss = 2.05 (8795.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:13.009056: step 157500, loss = 2.10 (8865.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:42:15.014018: step 157600, loss = 2.08 (6384.2 examples/sec; 0.020 sec/batch)
2018-02-01 15:42:17.620537: step 157700, loss = 2.11 (4910.8 examples/sec; 0.026 sec/batch)
2018-02-01 15:42:20.265529: step 157800, loss = 2.07 (4839.3 examples/sec; 0.026 sec/batch)
2018-02-01 15:42:22.673112: step 157900, loss = 2.02 (5316.5 examples/sec; 0.024 sec/batch)
2018-02-01 15:42:25.078161: step 158000, loss = 1.99 (5322.1 examples/sec; 0.024 sec/batch)
2018-02-01 15:42:27.859707: step 158100, loss = 2.09 (4601.8 examples/sec; 0.028 sec/batch)
2018-02-01 15:42:30.188401: step 158200, loss = 2.06 (5496.6 examples/sec; 0.023 sec/batch)
2018-02-01 15:42:32.393283: step 158300, loss = 2.04 (5805.3 examples/sec; 0.022 sec/batch)
2018-02-01 15:42:33.876825: step 158400, loss = 2.12 (8628.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:35.319832: step 158500, loss = 2.15 (8870.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:42:38.296671: step 158600, loss = 2.12 (4299.9 examples/sec; 0.030 sec/batch)
2018-02-01 15:42:39.804391: step 158700, loss = 2.15 (8489.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:41.244087: step 158800, loss = 2.10 (8890.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:42:42.696256: step 158900, loss = 2.07 (8814.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:44.162974: step 159000, loss = 2.12 (8727.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:45.604426: step 159100, loss = 2.09 (8879.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:42:47.067796: step 159200, loss = 2.10 (8746.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:48.518682: step 159300, loss = 2.10 (8822.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:49.959085: step 159400, loss = 1.93 (8886.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:42:51.414871: step 159500, loss = 2.02 (8792.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:52.867745: step 159600, loss = 2.13 (8810.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:54.316708: step 159700, loss = 2.14 (8833.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:42:55.761944: step 159800, loss = 2.09 (8856.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:42:57.219441: step 159900, loss = 2.04 (8782.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:42:58.655557: step 160000, loss = 2.13 (8912.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:43:00.117459: step 160100, loss = 2.12 (8755.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:01.563390: step 160200, loss = 2.06 (8852.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:43:03.225995: step 160300, loss = 2.07 (7698.8 examples/sec; 0.017 sec/batch)
2018-02-01 15:43:05.731796: step 160400, loss = 2.09 (5108.1 examples/sec; 0.025 sec/batch)
2018-02-01 15:43:15.797244: step 160500, loss = 2.04 (1271.7 examples/sec; 0.101 sec/batch)
2018-02-01 15:43:17.275569: step 160600, loss = 2.12 (8658.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:19.068525: step 160700, loss = 2.05 (7139.0 examples/sec; 0.018 sec/batch)
2018-02-01 15:43:20.517765: step 160800, loss = 2.19 (8832.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:43:21.998696: step 160900, loss = 2.11 (8643.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:23.454816: step 161000, loss = 2.10 (8790.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:24.920450: step 161100, loss = 2.12 (8733.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:26.371539: step 161200, loss = 2.10 (8821.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:27.827664: step 161300, loss = 2.05 (8790.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:29.278071: step 161400, loss = 2.04 (8825.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:30.736799: step 161500, loss = 2.02 (8774.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:32.224263: step 161600, loss = 2.12 (8605.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:33.700163: step 161700, loss = 2.12 (8672.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:35.149507: step 161800, loss = 2.11 (8831.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:43:38.232587: step 161900, loss = 2.05 (4151.7 examples/sec; 0.031 sec/batch)
2018-02-01 15:43:39.690024: step 162000, loss = 2.13 (8782.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:41.152606: step 162100, loss = 2.03 (8751.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:42.612606: step 162200, loss = 2.09 (8767.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:43:44.057705: step 162300, loss = 2.05 (8857.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:43:46.208594: step 162400, loss = 2.05 (5951.0 examples/sec; 0.022 sec/batch)
2018-02-01 15:43:48.711446: step 162500, loss = 2.07 (5114.2 examples/sec; 0.025 sec/batch)
2018-02-01 15:43:51.594176: step 162600, loss = 2.12 (4440.2 examples/sec; 0.029 sec/batch)
2018-02-01 15:43:54.067376: step 162700, loss = 1.99 (5175.5 examples/sec; 0.025 sec/batch)
2018-02-01 15:43:56.762499: step 162800, loss = 2.17 (4749.3 examples/sec; 0.027 sec/batch)
2018-02-01 15:43:59.406007: step 162900, loss = 2.07 (4842.1 examples/sec; 0.026 sec/batch)
2018-02-01 15:44:01.954722: step 163000, loss = 2.00 (5022.1 examples/sec; 0.025 sec/batch)
2018-02-01 15:44:03.428179: step 163100, loss = 2.06 (8687.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:04.879566: step 163200, loss = 2.16 (8819.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:07.873329: step 163300, loss = 2.02 (4275.6 examples/sec; 0.030 sec/batch)
2018-02-01 15:44:09.337770: step 163400, loss = 2.06 (8740.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:10.781368: step 163500, loss = 2.06 (8866.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:44:12.245097: step 163600, loss = 2.13 (8744.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:13.689119: step 163700, loss = 2.13 (8864.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:44:15.142684: step 163800, loss = 1.97 (8805.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:16.591864: step 163900, loss = 2.10 (8832.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:44:18.046029: step 164000, loss = 2.03 (8802.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:19.486482: step 164100, loss = 2.06 (8886.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:44:20.937744: step 164200, loss = 2.10 (8819.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:22.393591: step 164300, loss = 2.13 (8792.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:23.860059: step 164400, loss = 2.11 (8728.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:25.317676: step 164500, loss = 2.15 (8781.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:26.761945: step 164600, loss = 2.05 (8862.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:44:28.194920: step 164700, loss = 2.02 (8932.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:44:29.658816: step 164800, loss = 2.05 (8743.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:31.113702: step 164900, loss = 1.99 (8797.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:32.564187: step 165000, loss = 2.02 (8824.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:35.007064: step 165100, loss = 2.13 (5239.7 examples/sec; 0.024 sec/batch)
2018-02-01 15:44:45.484005: step 165200, loss = 1.96 (1221.7 examples/sec; 0.105 sec/batch)
2018-02-01 15:44:46.907895: step 165300, loss = 2.09 (8989.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:44:48.373294: step 165400, loss = 2.07 (8734.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:49.810365: step 165500, loss = 2.03 (8907.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:44:51.261998: step 165600, loss = 2.06 (8817.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:52.701362: step 165700, loss = 2.01 (8892.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:44:54.155989: step 165800, loss = 2.05 (8799.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:55.607785: step 165900, loss = 2.06 (8816.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:57.070349: step 166000, loss = 2.07 (8751.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:58.539799: step 166100, loss = 2.06 (8710.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:44:59.982143: step 166200, loss = 2.01 (8874.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:45:01.442012: step 166300, loss = 2.11 (8767.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:02.892509: step 166400, loss = 2.03 (8824.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:04.343745: step 166500, loss = 2.01 (8820.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:05.783365: step 166600, loss = 2.05 (8891.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:45:08.778104: step 166700, loss = 2.09 (4274.2 examples/sec; 0.030 sec/batch)
2018-02-01 15:45:10.235882: step 166800, loss = 2.16 (8780.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:11.706726: step 166900, loss = 2.04 (8702.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:13.141128: step 167000, loss = 2.06 (8923.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:45:14.620522: step 167100, loss = 1.99 (8652.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:16.997453: step 167200, loss = 2.06 (5385.1 examples/sec; 0.024 sec/batch)
2018-02-01 15:45:19.889221: step 167300, loss = 2.14 (4426.4 examples/sec; 0.029 sec/batch)
2018-02-01 15:45:22.541551: step 167400, loss = 2.11 (4825.9 examples/sec; 0.027 sec/batch)
2018-02-01 15:45:25.290034: step 167500, loss = 2.07 (4657.1 examples/sec; 0.027 sec/batch)
2018-02-01 15:45:27.754670: step 167600, loss = 2.07 (5193.5 examples/sec; 0.025 sec/batch)
2018-02-01 15:45:30.612688: step 167700, loss = 2.08 (4478.6 examples/sec; 0.029 sec/batch)
2018-02-01 15:45:32.571487: step 167800, loss = 2.03 (6534.6 examples/sec; 0.020 sec/batch)
2018-02-01 15:45:34.017538: step 167900, loss = 2.02 (8851.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:45:35.466909: step 168000, loss = 2.05 (8831.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:45:38.549911: step 168100, loss = 2.15 (4151.8 examples/sec; 0.031 sec/batch)
2018-02-01 15:45:40.007847: step 168200, loss = 2.19 (8779.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:41.458685: step 168300, loss = 2.15 (8822.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:42.902007: step 168400, loss = 2.11 (8868.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:45:44.337548: step 168500, loss = 2.11 (8916.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:45:45.824323: step 168600, loss = 2.06 (8609.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:47.292084: step 168700, loss = 2.14 (8720.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:48.741181: step 168800, loss = 2.07 (8833.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:45:50.188130: step 168900, loss = 2.07 (8846.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:45:51.634923: step 169000, loss = 2.06 (8847.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:45:53.093234: step 169100, loss = 2.10 (8777.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:54.527829: step 169200, loss = 2.16 (8922.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:45:56.016236: step 169300, loss = 2.08 (8599.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:57.470734: step 169400, loss = 2.14 (8800.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:45:58.927556: step 169500, loss = 1.98 (8786.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:46:00.380554: step 169600, loss = 2.02 (8809.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:46:01.817394: step 169700, loss = 2.01 (8908.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:46:03.737736: step 169800, loss = 2.12 (6665.5 examples/sec; 0.019 sec/batch)
2018-02-01 15:46:14.605895: step 169900, loss = 2.05 (1177.8 examples/sec; 0.109 sec/batch)
2018-02-01 15:46:16.061616: step 170000, loss = 2.10 (8792.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:46:17.506255: step 170100, loss = 2.01 (8860.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:46:18.996876: step 170200, loss = 2.04 (8587.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:46:20.443057: step 170300, loss = 2.16 (8850.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:46:21.882412: step 170400, loss = 2.09 (8892.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:46:23.330241: step 170500, loss = 1.98 (8840.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:46:24.766892: step 170600, loss = 1.99 (8909.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:46:26.227433: step 170700, loss = 2.06 (8763.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:46:27.710202: step 170800, loss = 2.02 (8632.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:46:29.168646: step 170900, loss = 2.05 (8776.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:46:30.608519: step 171000, loss = 2.16 (8889.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:46:32.036467: step 171100, loss = 2.08 (8963.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:46:33.471929: step 171200, loss = 2.16 (8917.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:46:34.931371: step 171300, loss = 2.07 (8770.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:46:37.937762: step 171400, loss = 2.13 (4257.6 examples/sec; 0.030 sec/batch)
2018-02-01 15:46:39.413769: step 171500, loss = 2.11 (8672.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:46:40.884967: step 171600, loss = 2.15 (8700.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:46:42.327193: step 171700, loss = 1.99 (8875.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:46:43.768300: step 171800, loss = 2.10 (8882.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:46:45.648761: step 171900, loss = 2.02 (6806.8 examples/sec; 0.019 sec/batch)
2018-02-01 15:46:48.181828: step 172000, loss = 2.08 (5053.2 examples/sec; 0.025 sec/batch)
2018-02-01 15:46:50.835924: step 172100, loss = 2.05 (4822.7 examples/sec; 0.027 sec/batch)
2018-02-01 15:46:53.756473: step 172200, loss = 2.05 (4382.7 examples/sec; 0.029 sec/batch)
2018-02-01 15:46:56.435759: step 172300, loss = 2.10 (4777.4 examples/sec; 0.027 sec/batch)
2018-02-01 15:46:59.174064: step 172400, loss = 2.20 (4674.4 examples/sec; 0.027 sec/batch)
2018-02-01 15:47:01.692811: step 172500, loss = 2.07 (5081.9 examples/sec; 0.025 sec/batch)
2018-02-01 15:47:03.150229: step 172600, loss = 2.14 (8782.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:04.601230: step 172700, loss = 2.11 (8821.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:06.051748: step 172800, loss = 2.06 (8824.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:09.045014: step 172900, loss = 2.06 (4276.3 examples/sec; 0.030 sec/batch)
2018-02-01 15:47:10.485099: step 173000, loss = 2.18 (8888.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:47:11.937202: step 173100, loss = 2.15 (8814.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:13.406169: step 173200, loss = 2.11 (8713.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:14.844084: step 173300, loss = 2.14 (8901.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:47:16.288302: step 173400, loss = 2.06 (8862.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:47:17.765347: step 173500, loss = 2.23 (8666.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:19.212906: step 173600, loss = 1.99 (8842.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:47:20.655076: step 173700, loss = 2.04 (8875.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:47:22.137314: step 173800, loss = 2.06 (8635.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:23.603006: step 173900, loss = 2.14 (8733.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:25.074238: step 174000, loss = 2.07 (8700.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:26.519134: step 174100, loss = 2.10 (8858.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:47:28.000443: step 174200, loss = 2.14 (8641.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:29.445656: step 174300, loss = 2.13 (8856.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:47:30.900929: step 174400, loss = 2.04 (8795.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:32.637192: step 174500, loss = 2.17 (7372.2 examples/sec; 0.017 sec/batch)
2018-02-01 15:47:35.544507: step 174600, loss = 2.04 (4402.7 examples/sec; 0.029 sec/batch)
2018-02-01 15:47:45.289646: step 174700, loss = 2.12 (1313.5 examples/sec; 0.097 sec/batch)
2018-02-01 15:47:46.751150: step 174800, loss = 2.12 (8758.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:48.208103: step 174900, loss = 2.10 (8785.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:49.656087: step 175000, loss = 2.13 (8839.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:47:51.123156: step 175100, loss = 2.09 (8724.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:52.580397: step 175200, loss = 2.04 (8783.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:54.019309: step 175300, loss = 2.13 (8895.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:47:55.469847: step 175400, loss = 2.03 (8824.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:47:56.914666: step 175500, loss = 2.05 (8859.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:47:58.358789: step 175600, loss = 2.01 (8863.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:47:59.802301: step 175700, loss = 2.09 (8867.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:48:01.383622: step 175800, loss = 2.12 (8094.5 examples/sec; 0.016 sec/batch)
2018-02-01 15:48:02.853682: step 175900, loss = 2.03 (8707.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:04.314889: step 176000, loss = 1.99 (8759.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:05.761432: step 176100, loss = 2.13 (8848.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:48:08.825577: step 176200, loss = 2.10 (4177.3 examples/sec; 0.031 sec/batch)
2018-02-01 15:48:10.283079: step 176300, loss = 2.11 (8782.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:11.740979: step 176400, loss = 2.02 (8779.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:13.186002: step 176500, loss = 2.01 (8858.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:48:14.807950: step 176600, loss = 2.10 (7891.7 examples/sec; 0.016 sec/batch)
2018-02-01 15:48:17.339996: step 176700, loss = 2.03 (5055.2 examples/sec; 0.025 sec/batch)
2018-02-01 15:48:20.071722: step 176800, loss = 2.17 (4685.7 examples/sec; 0.027 sec/batch)
2018-02-01 15:48:22.854427: step 176900, loss = 1.99 (4599.8 examples/sec; 0.028 sec/batch)
2018-02-01 15:48:25.410625: step 177000, loss = 2.00 (5007.4 examples/sec; 0.026 sec/batch)
2018-02-01 15:48:27.909468: step 177100, loss = 2.08 (5122.4 examples/sec; 0.025 sec/batch)
2018-02-01 15:48:30.400567: step 177200, loss = 2.11 (5138.3 examples/sec; 0.025 sec/batch)
2018-02-01 15:48:32.529190: step 177300, loss = 2.11 (6013.3 examples/sec; 0.021 sec/batch)
2018-02-01 15:48:33.994834: step 177400, loss = 2.07 (8733.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:35.461174: step 177500, loss = 2.05 (8729.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:38.455362: step 177600, loss = 2.06 (4274.9 examples/sec; 0.030 sec/batch)
2018-02-01 15:48:39.904032: step 177700, loss = 2.08 (8835.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:48:41.377778: step 177800, loss = 2.11 (8685.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:42.817126: step 177900, loss = 2.12 (8892.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:48:44.273707: step 178000, loss = 2.15 (8787.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:45.721328: step 178100, loss = 2.11 (8842.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:48:47.166720: step 178200, loss = 2.08 (8855.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:48:48.608773: step 178300, loss = 2.07 (8876.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:48:50.093708: step 178400, loss = 2.09 (8619.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:51.552316: step 178500, loss = 2.05 (8775.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:53.039191: step 178600, loss = 2.09 (8608.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:54.493138: step 178700, loss = 2.16 (8803.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:55.938976: step 178800, loss = 2.14 (8853.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:48:57.417300: step 178900, loss = 2.03 (8658.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:48:58.866988: step 179000, loss = 2.09 (8829.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:49:00.314020: step 179100, loss = 2.22 (8845.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:49:01.768807: step 179200, loss = 2.11 (8798.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:03.860409: step 179300, loss = 2.13 (6119.7 examples/sec; 0.021 sec/batch)
2018-02-01 15:49:14.526948: step 179400, loss = 2.13 (1200.0 examples/sec; 0.107 sec/batch)
2018-02-01 15:49:15.990855: step 179500, loss = 2.19 (8743.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:17.443358: step 179600, loss = 2.05 (8812.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:18.907318: step 179700, loss = 2.09 (8743.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:20.400836: step 179800, loss = 1.99 (8570.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:21.926467: step 179900, loss = 2.12 (8390.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:23.407593: step 180000, loss = 1.98 (8642.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:24.857355: step 180100, loss = 2.13 (8829.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:49:26.311401: step 180200, loss = 2.03 (8803.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:27.779435: step 180300, loss = 2.00 (8719.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:29.250028: step 180400, loss = 2.16 (8704.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:30.725482: step 180500, loss = 2.27 (8675.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:32.220660: step 180600, loss = 2.10 (8560.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:33.693220: step 180700, loss = 2.11 (8692.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:35.137314: step 180800, loss = 2.05 (8863.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:49:38.193648: step 180900, loss = 2.04 (4188.0 examples/sec; 0.031 sec/batch)
2018-02-01 15:49:39.674039: step 181000, loss = 2.04 (8646.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:41.133701: step 181100, loss = 2.13 (8769.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:42.592752: step 181200, loss = 2.16 (8772.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:49:44.039274: step 181300, loss = 2.03 (8848.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:49:46.318679: step 181400, loss = 2.03 (5615.5 examples/sec; 0.023 sec/batch)
2018-02-01 15:49:49.114797: step 181500, loss = 2.03 (4577.8 examples/sec; 0.028 sec/batch)
2018-02-01 15:49:51.913202: step 181600, loss = 2.11 (4574.0 examples/sec; 0.028 sec/batch)
2018-02-01 15:49:54.579966: step 181700, loss = 2.07 (4799.8 examples/sec; 0.027 sec/batch)
2018-02-01 15:49:56.893928: step 181800, loss = 2.05 (5531.6 examples/sec; 0.023 sec/batch)
2018-02-01 15:49:59.786911: step 181900, loss = 2.09 (4424.5 examples/sec; 0.029 sec/batch)
2018-02-01 15:50:01.941214: step 182000, loss = 2.05 (5941.6 examples/sec; 0.022 sec/batch)
2018-02-01 15:50:03.409631: step 182100, loss = 2.03 (8716.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:04.856033: step 182200, loss = 2.15 (8849.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:50:07.997546: step 182300, loss = 2.05 (4074.5 examples/sec; 0.031 sec/batch)
2018-02-01 15:50:09.492003: step 182400, loss = 2.11 (8565.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:10.945633: step 182500, loss = 2.00 (8805.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:12.408267: step 182600, loss = 2.03 (8751.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:13.888522: step 182700, loss = 2.16 (8647.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:15.329236: step 182800, loss = 2.01 (8884.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:50:16.793946: step 182900, loss = 2.12 (8738.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:18.229185: step 183000, loss = 2.08 (8918.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:50:19.694803: step 183100, loss = 2.00 (8733.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:21.150906: step 183200, loss = 1.92 (8790.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:22.602998: step 183300, loss = 2.09 (8814.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:24.064078: step 183400, loss = 2.15 (8760.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:25.504516: step 183500, loss = 2.14 (8886.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:50:26.962428: step 183600, loss = 2.09 (8779.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:28.415991: step 183700, loss = 2.06 (8805.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:29.885260: step 183800, loss = 2.13 (8711.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:31.516261: step 183900, loss = 2.09 (7847.9 examples/sec; 0.016 sec/batch)
2018-02-01 15:50:34.162017: step 184000, loss = 2.08 (4837.9 examples/sec; 0.026 sec/batch)
2018-02-01 15:50:44.901917: step 184100, loss = 1.95 (1191.8 examples/sec; 0.107 sec/batch)
2018-02-01 15:50:46.367920: step 184200, loss = 2.18 (8731.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:47.818251: step 184300, loss = 2.04 (8825.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:49.279702: step 184400, loss = 2.08 (8758.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:50.749274: step 184500, loss = 2.11 (8710.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:52.217276: step 184600, loss = 2.07 (8719.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:53.668996: step 184700, loss = 1.93 (8817.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:55.145204: step 184800, loss = 2.03 (8670.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:56.594057: step 184900, loss = 2.16 (8834.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:50:58.045572: step 185000, loss = 2.08 (8818.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:50:59.491455: step 185100, loss = 2.05 (8852.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:51:00.965560: step 185200, loss = 2.04 (8683.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:02.435204: step 185300, loss = 2.17 (8709.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:03.866731: step 185400, loss = 2.07 (8941.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:51:05.319828: step 185500, loss = 1.98 (8808.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:08.308566: step 185600, loss = 2.03 (4282.7 examples/sec; 0.030 sec/batch)
2018-02-01 15:51:09.771222: step 185700, loss = 2.19 (8751.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:11.213104: step 185800, loss = 2.00 (8877.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:51:12.687300: step 185900, loss = 2.09 (8682.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:14.145008: step 186000, loss = 2.09 (8780.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:16.370030: step 186100, loss = 2.09 (5752.8 examples/sec; 0.022 sec/batch)
2018-02-01 15:51:19.064650: step 186200, loss = 2.07 (4750.2 examples/sec; 0.027 sec/batch)
2018-02-01 15:51:21.656910: step 186300, loss = 2.11 (4937.8 examples/sec; 0.026 sec/batch)
2018-02-01 15:51:24.547908: step 186400, loss = 2.17 (4427.5 examples/sec; 0.029 sec/batch)
2018-02-01 15:51:27.071821: step 186500, loss = 2.05 (5071.5 examples/sec; 0.025 sec/batch)
2018-02-01 15:51:29.714045: step 186600, loss = 2.20 (4844.4 examples/sec; 0.026 sec/batch)
2018-02-01 15:51:32.101806: step 186700, loss = 2.07 (5360.7 examples/sec; 0.024 sec/batch)
2018-02-01 15:51:33.579018: step 186800, loss = 2.05 (8665.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:35.026392: step 186900, loss = 2.17 (8843.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:51:38.067820: step 187000, loss = 2.02 (4208.5 examples/sec; 0.030 sec/batch)
2018-02-01 15:51:39.530646: step 187100, loss = 2.04 (8750.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:40.976740: step 187200, loss = 2.04 (8851.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:51:42.425275: step 187300, loss = 1.97 (8836.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:51:43.865627: step 187400, loss = 2.17 (8886.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:51:45.310941: step 187500, loss = 2.16 (8856.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:51:46.759300: step 187600, loss = 2.03 (8837.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:51:48.217165: step 187700, loss = 2.18 (8780.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:49.668969: step 187800, loss = 2.14 (8816.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:51.134461: step 187900, loss = 2.19 (8734.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:52.600063: step 188000, loss = 2.15 (8733.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:54.052491: step 188100, loss = 2.07 (8812.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:55.505404: step 188200, loss = 2.14 (8809.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:56.972784: step 188300, loss = 2.04 (8723.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:58.454422: step 188400, loss = 1.99 (8639.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:51:59.906575: step 188500, loss = 2.12 (8814.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:01.367382: step 188600, loss = 2.05 (8762.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:03.202197: step 188700, loss = 2.05 (6976.2 examples/sec; 0.018 sec/batch)
2018-02-01 15:52:05.762994: step 188800, loss = 1.94 (4998.4 examples/sec; 0.026 sec/batch)
2018-02-01 15:52:15.610048: step 188900, loss = 2.20 (1299.9 examples/sec; 0.098 sec/batch)
2018-02-01 15:52:17.055524: step 189000, loss = 1.95 (8855.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:52:18.507326: step 189100, loss = 2.14 (8816.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:19.948038: step 189200, loss = 2.13 (8884.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:52:21.424396: step 189300, loss = 2.11 (8670.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:22.877434: step 189400, loss = 2.12 (8809.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:24.334718: step 189500, loss = 2.10 (8783.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:25.780893: step 189600, loss = 2.04 (8850.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:52:27.238746: step 189700, loss = 2.05 (8780.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:28.690208: step 189800, loss = 2.09 (8818.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:30.142643: step 189900, loss = 2.11 (8812.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:31.651233: step 190000, loss = 2.02 (8484.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:33.168955: step 190100, loss = 2.11 (8433.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:34.610401: step 190200, loss = 2.12 (8880.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:52:36.116480: step 190300, loss = 2.06 (8498.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:39.480464: step 190400, loss = 2.05 (3805.0 examples/sec; 0.034 sec/batch)
2018-02-01 15:52:40.962871: step 190500, loss = 2.18 (8634.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:52:42.616621: step 190600, loss = 2.07 (7740.0 examples/sec; 0.017 sec/batch)
2018-02-01 15:52:44.061028: step 190700, loss = 2.06 (8861.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:52:46.482420: step 190800, loss = 2.14 (5286.2 examples/sec; 0.024 sec/batch)
2018-02-01 15:52:49.290226: step 190900, loss = 2.09 (4558.7 examples/sec; 0.028 sec/batch)
2018-02-01 15:52:52.076745: step 191000, loss = 2.11 (4593.5 examples/sec; 0.028 sec/batch)
2018-02-01 15:52:54.790325: step 191100, loss = 2.07 (4717.0 examples/sec; 0.027 sec/batch)
2018-02-01 15:52:57.695310: step 191200, loss = 2.05 (4406.2 examples/sec; 0.029 sec/batch)
2018-02-01 15:53:00.547763: step 191300, loss = 2.07 (4487.4 examples/sec; 0.029 sec/batch)
2018-02-01 15:53:02.163776: step 191400, loss = 2.10 (7920.7 examples/sec; 0.016 sec/batch)
2018-02-01 15:53:03.592671: step 191500, loss = 2.11 (8958.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:53:05.044516: step 191600, loss = 1.93 (8816.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:08.113935: step 191700, loss = 2.04 (4170.2 examples/sec; 0.031 sec/batch)
2018-02-01 15:53:09.564756: step 191800, loss = 2.19 (8822.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:11.035399: step 191900, loss = 2.15 (8703.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:12.500657: step 192000, loss = 1.92 (8735.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:13.949510: step 192100, loss = 2.06 (8834.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:53:15.394844: step 192200, loss = 2.12 (8856.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:53:16.868959: step 192300, loss = 2.05 (8683.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:18.342956: step 192400, loss = 2.06 (8683.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:19.795536: step 192500, loss = 2.08 (8811.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:21.280013: step 192600, loss = 2.05 (8622.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:22.755766: step 192700, loss = 2.06 (8673.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:24.213505: step 192800, loss = 2.06 (8780.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:25.674034: step 192900, loss = 2.09 (8763.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:27.132126: step 193000, loss = 2.11 (8778.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:28.604147: step 193100, loss = 2.14 (8695.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:30.043239: step 193200, loss = 2.10 (8894.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:53:31.524385: step 193300, loss = 2.09 (8642.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:34.003810: step 193400, loss = 2.13 (5162.5 examples/sec; 0.025 sec/batch)
2018-02-01 15:53:44.295058: step 193500, loss = 2.08 (1243.8 examples/sec; 0.103 sec/batch)
2018-02-01 15:53:45.741724: step 193600, loss = 2.01 (8847.9 examples/sec; 0.014 sec/batch)
2018-02-01 15:53:47.224960: step 193700, loss = 2.09 (8629.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:48.692826: step 193800, loss = 2.12 (8720.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:50.201732: step 193900, loss = 2.03 (8483.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:51.659681: step 194000, loss = 2.20 (8779.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:53.098527: step 194100, loss = 2.11 (8896.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:53:54.538738: step 194200, loss = 2.05 (8887.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:53:55.985396: step 194300, loss = 2.03 (8848.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:53:57.462126: step 194400, loss = 2.09 (8667.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:53:58.921751: step 194500, loss = 2.00 (8769.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:00.378507: step 194600, loss = 2.11 (8786.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:01.831748: step 194700, loss = 1.98 (8807.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:03.308470: step 194800, loss = 2.10 (8667.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:04.758466: step 194900, loss = 2.01 (8827.6 examples/sec; 0.014 sec/batch)
2018-02-01 15:54:06.205884: step 195000, loss = 2.05 (8843.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:54:09.259344: step 195100, loss = 2.13 (4192.0 examples/sec; 0.031 sec/batch)
2018-02-01 15:54:10.697179: step 195200, loss = 2.13 (8902.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:54:12.174216: step 195300, loss = 2.10 (8666.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:13.661543: step 195400, loss = 2.15 (8606.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:15.686474: step 195500, loss = 1.93 (6321.2 examples/sec; 0.020 sec/batch)
2018-02-01 15:54:18.323370: step 195600, loss = 2.03 (4854.2 examples/sec; 0.026 sec/batch)
2018-02-01 15:54:20.875303: step 195700, loss = 2.11 (5015.8 examples/sec; 0.026 sec/batch)
2018-02-01 15:54:23.678356: step 195800, loss = 1.99 (4566.4 examples/sec; 0.028 sec/batch)
2018-02-01 15:54:26.426351: step 195900, loss = 1.99 (4657.9 examples/sec; 0.027 sec/batch)
2018-02-01 15:54:28.943400: step 196000, loss = 2.16 (5085.3 examples/sec; 0.025 sec/batch)
2018-02-01 15:54:31.562647: step 196100, loss = 2.18 (4886.9 examples/sec; 0.026 sec/batch)
2018-02-01 15:54:33.032934: step 196200, loss = 2.05 (8705.8 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:34.495422: step 196300, loss = 2.12 (8752.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:35.969854: step 196400, loss = 1.98 (8681.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:38.971026: step 196500, loss = 2.07 (4265.0 examples/sec; 0.030 sec/batch)
2018-02-01 15:54:40.443454: step 196600, loss = 2.12 (8693.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:41.893885: step 196700, loss = 2.19 (8825.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:43.331079: step 196800, loss = 1.99 (8906.2 examples/sec; 0.014 sec/batch)
2018-02-01 15:54:44.795531: step 196900, loss = 2.14 (8740.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:46.258444: step 197000, loss = 2.04 (8749.7 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:47.708410: step 197100, loss = 2.12 (8827.8 examples/sec; 0.014 sec/batch)
2018-02-01 15:54:49.167953: step 197200, loss = 2.10 (8769.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:50.618938: step 197300, loss = 2.14 (8821.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:52.067021: step 197400, loss = 2.17 (8839.3 examples/sec; 0.014 sec/batch)
2018-02-01 15:54:53.530463: step 197500, loss = 2.11 (8746.5 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:54.983301: step 197600, loss = 2.11 (8810.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:56.453115: step 197700, loss = 2.12 (8708.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:57.920274: step 197800, loss = 2.07 (8724.3 examples/sec; 0.015 sec/batch)
2018-02-01 15:54:59.359974: step 197900, loss = 2.06 (8890.7 examples/sec; 0.014 sec/batch)
2018-02-01 15:55:00.837584: step 198000, loss = 2.11 (8662.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:55:02.638509: step 198100, loss = 2.13 (7107.5 examples/sec; 0.018 sec/batch)
2018-02-01 15:55:05.599181: step 198200, loss = 2.08 (4323.3 examples/sec; 0.030 sec/batch)
2018-02-01 15:55:15.123264: step 198300, loss = 2.11 (1344.0 examples/sec; 0.095 sec/batch)
2018-02-01 15:55:16.570882: step 198400, loss = 2.00 (8842.1 examples/sec; 0.014 sec/batch)
2018-02-01 15:55:18.035012: step 198500, loss = 2.07 (8742.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:55:19.498200: step 198600, loss = 2.09 (8748.0 examples/sec; 0.015 sec/batch)
2018-02-01 15:55:20.966388: step 198700, loss = 2.05 (8718.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:55:22.423764: step 198800, loss = 2.04 (8782.9 examples/sec; 0.015 sec/batch)
2018-02-01 15:55:23.869438: step 198900, loss = 2.02 (8854.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:55:25.334116: step 199000, loss = 2.19 (8739.1 examples/sec; 0.015 sec/batch)
2018-02-01 15:55:26.769575: step 199100, loss = 2.04 (8917.0 examples/sec; 0.014 sec/batch)
2018-02-01 15:55:28.214197: step 199200, loss = 2.08 (8860.5 examples/sec; 0.014 sec/batch)
2018-02-01 15:55:29.666405: step 199300, loss = 2.11 (8814.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:55:31.122206: step 199400, loss = 2.05 (8792.4 examples/sec; 0.015 sec/batch)
2018-02-01 15:55:32.596418: step 199500, loss = 2.15 (8682.6 examples/sec; 0.015 sec/batch)
2018-02-01 15:55:34.070367: step 199600, loss = 2.05 (8684.2 examples/sec; 0.015 sec/batch)
2018-02-01 15:55:35.518585: step 199700, loss = 2.09 (8838.4 examples/sec; 0.014 sec/batch)
2018-02-01 15:55:38.594804: step 199800, loss = 2.07 (4161.0 examples/sec; 0.031 sec/batch)
2018-02-01 15:55:40.069622: step 199900, loss = 2.13 (8679.0 examples/sec; 0.015 sec/batch)
