Images -> gris
pas de distored_inputs




EVALUATION


2018-01-30 12:12:05.922190: precision @ 1 = 0.105
2018-01-30 12:13:12.905948: precision @ 1 = 0.285
2018-01-30 12:14:20.639942: precision @ 1 = 0.284
2018-01-30 12:15:27.670642: precision @ 1 = 0.285
2018-01-30 12:16:34.150212: precision @ 1 = 0.287
2018-01-30 12:17:39.654136: precision @ 1 = 0.281
2018-01-30 12:18:46.963936: precision @ 1 = 0.282
2018-01-30 12:19:53.039398: precision @ 1 = 0.279
2018-01-30 12:21:00.209760: precision @ 1 = 0.279
2018-01-30 12:22:06.560755: precision @ 1 = 0.279
2018-01-30 12:23:12.778369: precision @ 1 = 0.278
2018-01-30 12:24:19.411216: precision @ 1 = 0.279
2018-01-30 12:25:25.864986: precision @ 1 = 0.278
2018-01-30 12:26:31.761687: precision @ 1 = 0.280
2018-01-30 12:27:38.397790: precision @ 1 = 0.277
2018-01-30 12:28:33.715785: precision @ 1 = 0.280
2018-01-30 12:28:58.311314: precision @ 1 = 0.279
2018-01-30 12:29:23.313111: precision @ 1 = 0.279
2018-01-30 12:29:48.107678: precision @ 1 = 0.279
2018-01-30 12:30:11.933858: precision @ 1 = 0.278
2018-01-30 12:30:37.045873: precision @ 1 = 0.278
2018-01-30 12:30:59.905025: precision @ 1 = 0.278
2018-01-30 12:31:24.710667: precision @ 1 = 0.277
2018-01-30 12:31:49.575294: precision @ 1 = 0.277
2018-01-30 12:32:14.700231: precision @ 1 = 0.275
2018-01-30 12:32:39.621177: precision @ 1 = 0.275
2018-01-30 12:33:02.824511: precision @ 1 = 0.275
2018-01-30 12:33:27.745303: precision @ 1 = 0.276
2018-01-30 12:33:52.873406: precision @ 1 = 0.276
2018-01-30 12:34:18.121807: precision @ 1 = 0.277
2018-01-30 12:34:43.130400: precision @ 1 = 0.277
2018-01-30 12:35:06.236106: precision @ 1 = 0.277
2018-01-30 12:35:30.950273: precision @ 1 = 0.276
2018-01-30 12:35:56.170180: precision @ 1 = 0.276
2018-01-30 12:36:21.236212: precision @ 1 = 0.277
2018-01-30 12:36:46.811151: precision @ 1 = 0.277
2018-01-30 12:37:09.710670: precision @ 1 = 0.277
2018-01-30 12:37:34.720900: precision @ 1 = 0.277
2018-01-30 12:37:58.819826: precision @ 1 = 0.277
2018-01-30 12:38:23.773692: precision @ 1 = 0.276
2018-01-30 12:38:48.539572: precision @ 1 = 0.276
2018-01-30 12:39:13.447611: precision @ 1 = 0.277
2018-01-30 12:39:38.142450: precision @ 1 = 0.277
2018-01-30 12:40:01.299016: precision @ 1 = 0.277
2018-01-30 12:40:26.714733: precision @ 1 = 0.277
2018-01-30 12:40:51.677511: precision @ 1 = 0.277
2018-01-30 12:41:16.440188: precision @ 1 = 0.277
2018-01-30 12:41:41.496831: precision @ 1 = 0.277
2018-01-30 12:42:04.553515: precision @ 1 = 0.277
2018-01-30 12:42:29.352923: precision @ 1 = 0.277
2018-01-30 12:42:53.995278: precision @ 1 = 0.277
2018-01-30 12:43:18.736471: precision @ 1 = 0.276
2018-01-30 12:43:43.729065: precision @ 1 = 0.276
2018-01-30 12:44:07.764862: precision @ 1 = 0.276
2018-01-30 12:44:33.235205: precision @ 1 = 0.277
2018-01-30 12:44:57.593184: precision @ 1 = 0.277
2018-01-30 12:45:22.718301: precision @ 1 = 0.276
2018-01-30 12:45:47.299109: precision @ 1 = 0.276
2018-01-30 12:46:09.902336: precision @ 1 = 0.276
2018-01-30 12:46:34.874553: precision @ 1 = 0.278
2018-01-30 12:46:59.189703: precision @ 1 = 0.278
2018-01-30 12:47:24.049399: precision @ 1 = 0.277
2018-01-30 12:47:49.371058: precision @ 1 = 0.277
2018-01-30 12:48:13.922564: precision @ 1 = 0.277
2018-01-30 12:48:38.892989: precision @ 1 = 0.277
2018-01-30 12:49:01.314848: precision @ 1 = 0.277
2018-01-30 12:49:26.235713: precision @ 1 = 0.276
2018-01-30 12:49:51.132004: precision @ 1 = 0.276
2018-01-30 12:50:16.042565: precision @ 1 = 0.277
2018-01-30 12:50:40.533112: precision @ 1 = 0.277
2018-01-30 12:51:02.939457: precision @ 1 = 0.277
2018-01-30 12:51:28.071915: precision @ 1 = 0.276
2018-01-30 12:51:52.971025: precision @ 1 = 0.276
2018-01-30 12:52:17.527831: precision @ 1 = 0.276
2018-01-30 12:52:42.391347: precision @ 1 = 0.276
2018-01-30 12:53:05.908803: precision @ 1 = 0.276
2018-01-30 12:53:30.686665: precision @ 1 = 0.276
2018-01-30 12:53:55.262148: precision @ 1 = 0.276
2018-01-30 12:54:19.784891: precision @ 1 = 0.276
2018-01-30 12:54:44.456304: precision @ 1 = 0.276
2018-01-30 12:55:08.096576: precision @ 1 = 0.276
2018-01-30 12:55:32.619458: precision @ 1 = 0.276
2018-01-30 12:55:57.401513: precision @ 1 = 0.276
2018-01-30 12:56:22.111313: precision @ 1 = 0.278
2018-01-30 12:56:46.522656: precision @ 1 = 0.278
2018-01-30 12:57:09.810934: precision @ 1 = 0.278
2018-01-30 12:57:34.861690: precision @ 1 = 0.278
2018-01-30 12:57:59.387248: precision @ 1 = 0.278
2018-01-30 12:58:24.528192: precision @ 1 = 0.278
2018-01-30 12:58:49.846267: precision @ 1 = 0.278
2018-01-30 12:59:15.121847: precision @ 1 = 0.277
2018-01-30 12:59:40.182866: precision @ 1 = 0.277
2018-01-30 13:00:02.405170: precision @ 1 = 0.277
2018-01-30 13:00:27.783183: precision @ 1 = 0.277
2018-01-30 13:00:53.343038: precision @ 1 = 0.277
2018-01-30 13:01:18.234656: precision @ 1 = 0.277
2018-01-30 13:01:43.282983: precision @ 1 = 0.277
2018-01-30 13:02:06.555304: precision @ 1 = 0.277



LOSS (Train)


2018-01-30 12:10:58.205076: step 0, loss = 2.30 (2918.6 examples/sec; 0.044 sec/batch)
2018-01-30 12:11:05.652569: step 200, loss = 2.03 (3437.4 examples/sec; 0.037 sec/batch)
2018-01-30 12:11:17.748046: step 400, loss = 2.23 (2116.5 examples/sec; 0.060 sec/batch)
2018-01-30 12:11:33.208558: step 600, loss = 2.05 (1655.8 examples/sec; 0.077 sec/batch)
2018-01-30 12:11:48.651302: step 800, loss = 2.06 (1657.7 examples/sec; 0.077 sec/batch)
2018-01-30 12:12:07.078707: step 1000, loss = 2.11 (1389.2 examples/sec; 0.092 sec/batch)
2018-01-30 12:12:14.580241: step 1200, loss = 2.09 (3412.6 examples/sec; 0.038 sec/batch)
2018-01-30 12:12:27.701934: step 1400, loss = 1.98 (1951.0 examples/sec; 0.066 sec/batch)
2018-01-30 12:12:42.550456: step 1600, loss = 1.97 (1724.1 examples/sec; 0.074 sec/batch)
2018-01-30 12:12:59.794781: step 1800, loss = 2.09 (1484.5 examples/sec; 0.086 sec/batch)
2018-01-30 12:13:13.948066: step 2000, loss = 2.07 (1808.8 examples/sec; 0.071 sec/batch)
2018-01-30 12:13:21.184997: step 2200, loss = 2.05 (3537.4 examples/sec; 0.036 sec/batch)
2018-01-30 12:13:33.438377: step 2400, loss = 1.98 (2089.2 examples/sec; 0.061 sec/batch)
2018-01-30 12:13:48.701892: step 2600, loss = 1.97 (1677.2 examples/sec; 0.076 sec/batch)
2018-01-30 12:14:06.286785: step 2800, loss = 2.21 (1455.8 examples/sec; 0.088 sec/batch)
2018-01-30 12:14:21.182768: step 3000, loss = 2.07 (1718.6 examples/sec; 0.074 sec/batch)
2018-01-30 12:14:28.517806: step 3200, loss = 1.97 (3490.1 examples/sec; 0.037 sec/batch)
2018-01-30 12:14:39.962315: step 3400, loss = 2.04 (2236.9 examples/sec; 0.057 sec/batch)
2018-01-30 12:14:55.402919: step 3600, loss = 2.00 (1658.0 examples/sec; 0.077 sec/batch)
2018-01-30 12:15:13.194212: step 3800, loss = 1.99 (1438.9 examples/sec; 0.089 sec/batch)
2018-01-30 12:15:28.110642: step 4000, loss = 1.94 (1716.2 examples/sec; 0.075 sec/batch)
2018-01-30 12:15:35.333084: step 4200, loss = 2.16 (3544.5 examples/sec; 0.036 sec/batch)
2018-01-30 12:15:46.446881: step 4400, loss = 2.03 (2303.4 examples/sec; 0.056 sec/batch)
2018-01-30 12:16:04.935716: step 4600, loss = 2.13 (1384.6 examples/sec; 0.092 sec/batch)
2018-01-30 12:16:20.058314: step 4800, loss = 2.10 (1692.8 examples/sec; 0.076 sec/batch)
2018-01-30 12:16:34.590212: step 5000, loss = 1.93 (1761.6 examples/sec; 0.073 sec/batch)
2018-01-30 12:16:41.737090: step 5200, loss = 1.98 (3582.0 examples/sec; 0.036 sec/batch)
2018-01-30 12:16:53.109393: step 5400, loss = 2.13 (2251.1 examples/sec; 0.057 sec/batch)
2018-01-30 12:17:11.959440: step 5600, loss = 1.96 (1358.1 examples/sec; 0.094 sec/batch)
2018-01-30 12:17:27.230720: step 5800, loss = 2.00 (1676.3 examples/sec; 0.076 sec/batch)
2018-01-30 12:17:41.118135: step 6000, loss = 2.17 (1843.4 examples/sec; 0.069 sec/batch)
2018-01-30 12:17:48.352914: step 6200, loss = 2.04 (3538.5 examples/sec; 0.036 sec/batch)
2018-01-30 12:18:04.293766: step 6400, loss = 2.00 (1605.9 examples/sec; 0.080 sec/batch)
2018-01-30 12:18:19.559291: step 6600, loss = 2.07 (1677.0 examples/sec; 0.076 sec/batch)
2018-01-30 12:18:34.719073: step 6800, loss = 2.03 (1688.7 examples/sec; 0.076 sec/batch)
2018-01-30 12:18:48.578351: step 7000, loss = 2.07 (1847.1 examples/sec; 0.069 sec/batch)
2018-01-30 12:18:55.965198: step 7200, loss = 2.02 (3465.6 examples/sec; 0.037 sec/batch)
2018-01-30 12:19:12.419404: step 7400, loss = 2.05 (1555.8 examples/sec; 0.082 sec/batch)
2018-01-30 12:19:27.542857: step 7600, loss = 2.12 (1692.7 examples/sec; 0.076 sec/batch)
2018-01-30 12:19:42.770436: step 7800, loss = 1.91 (1681.2 examples/sec; 0.076 sec/batch)
2018-01-30 12:19:55.570893: step 8000, loss = 2.09 (1999.9 examples/sec; 0.064 sec/batch)
2018-01-30 12:20:03.809141: step 8200, loss = 2.02 (3107.5 examples/sec; 0.041 sec/batch)
2018-01-30 12:20:18.669362: step 8400, loss = 2.08 (1722.7 examples/sec; 0.074 sec/batch)
2018-01-30 12:20:33.728487: step 8600, loss = 2.06 (1700.0 examples/sec; 0.075 sec/batch)
2018-01-30 12:20:48.800475: step 8800, loss = 2.11 (1698.5 examples/sec; 0.075 sec/batch)
2018-01-30 12:21:03.465232: step 9000, loss = 1.93 (1745.7 examples/sec; 0.073 sec/batch)
2018-01-30 12:21:10.765817: step 9200, loss = 2.10 (3506.6 examples/sec; 0.037 sec/batch)
2018-01-30 12:21:25.050253: step 9400, loss = 2.13 (1792.2 examples/sec; 0.071 sec/batch)
2018-01-30 12:21:40.287193: step 9600, loss = 2.21 (1680.1 examples/sec; 0.076 sec/batch)
2018-01-30 12:21:55.122592: step 9800, loss = 2.20 (1725.6 examples/sec; 0.074 sec/batch)
2018-01-30 12:22:10.333166: step 10000, loss = 1.87 (1683.0 examples/sec; 0.076 sec/batch)
2018-01-30 12:22:17.677015: step 10200, loss = 2.07 (3485.9 examples/sec; 0.037 sec/batch)
2018-01-30 12:22:32.764253: step 10400, loss = 1.91 (1696.8 examples/sec; 0.075 sec/batch)
2018-01-30 12:22:47.499703: step 10600, loss = 2.04 (1737.3 examples/sec; 0.074 sec/batch)
2018-01-30 12:23:05.832632: step 10800, loss = 2.07 (1396.4 examples/sec; 0.092 sec/batch)
2018-01-30 12:23:16.834451: step 11000, loss = 2.02 (2326.9 examples/sec; 0.055 sec/batch)
2018-01-30 12:23:24.281043: step 11200, loss = 1.98 (3437.8 examples/sec; 0.037 sec/batch)
2018-01-30 12:23:39.797371: step 11400, loss = 2.21 (1649.9 examples/sec; 0.078 sec/batch)
2018-01-30 12:23:54.629280: step 11600, loss = 1.96 (1726.0 examples/sec; 0.074 sec/batch)
2018-01-30 12:24:12.542160: step 11800, loss = 1.98 (1429.1 examples/sec; 0.090 sec/batch)
2018-01-30 12:24:23.367346: step 12000, loss = 2.04 (2365.7 examples/sec; 0.054 sec/batch)
2018-01-30 12:24:30.760546: step 12200, loss = 2.00 (3460.8 examples/sec; 0.037 sec/batch)
2018-01-30 12:24:45.764720: step 12400, loss = 2.16 (1706.2 examples/sec; 0.075 sec/batch)
2018-01-30 12:25:03.690288: step 12600, loss = 2.15 (1428.1 examples/sec; 0.090 sec/batch)
2018-01-30 12:25:19.128315: step 12800, loss = 2.19 (1658.2 examples/sec; 0.077 sec/batch)
2018-01-30 12:25:29.989444: step 13000, loss = 1.99 (2357.0 examples/sec; 0.054 sec/batch)
2018-01-30 12:25:37.649895: step 13200, loss = 2.05 (3341.8 examples/sec; 0.038 sec/batch)
2018-01-30 12:25:52.674521: step 13400, loss = 1.97 (1703.9 examples/sec; 0.075 sec/batch)
2018-01-30 12:26:11.405698: step 13600, loss = 2.09 (1366.7 examples/sec; 0.094 sec/batch)
2018-01-30 12:26:26.363303: step 13800, loss = 2.11 (1711.5 examples/sec; 0.075 sec/batch)
2018-01-30 12:26:36.467293: step 14000, loss = 2.06 (2533.7 examples/sec; 0.051 sec/batch)
2018-01-30 12:26:45.072045: step 14200, loss = 2.06 (2975.1 examples/sec; 0.043 sec/batch)
2018-01-30 12:27:02.887738: step 14400, loss = 2.13 (1436.9 examples/sec; 0.089 sec/batch)
2018-01-30 12:27:17.968336: step 14600, loss = 1.89 (1697.5 examples/sec; 0.075 sec/batch)
2018-01-30 12:27:32.874018: step 14800, loss = 2.07 (1717.5 examples/sec; 0.075 sec/batch)
2018-01-30 12:27:43.102205: step 15000, loss = 2.16 (2502.9 examples/sec; 0.051 sec/batch)
2018-01-30 12:27:51.165177: step 15200, loss = 2.01 (3175.0 examples/sec; 0.040 sec/batch)
2018-01-30 12:28:09.898142: step 15400, loss = 1.83 (1366.6 examples/sec; 0.094 sec/batch)
2018-01-30 12:28:25.169324: step 15600, loss = 2.08 (1676.4 examples/sec; 0.076 sec/batch)
2018-01-30 12:28:32.575039: step 15800, loss = 1.91 (3456.8 examples/sec; 0.037 sec/batch)
2018-01-30 12:28:35.059679: step 16000, loss = 2.19 (10303.3 examples/sec; 0.012 sec/batch)
2018-01-30 12:28:36.950505: step 16200, loss = 2.08 (13539.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:28:38.778826: step 16400, loss = 2.02 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:28:40.615611: step 16600, loss = 2.08 (13937.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:28:42.470539: step 16800, loss = 2.10 (13801.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:28:44.564893: step 17000, loss = 1.96 (12223.3 examples/sec; 0.010 sec/batch)
2018-01-30 12:28:48.309643: step 17200, loss = 1.98 (6836.2 examples/sec; 0.019 sec/batch)
2018-01-30 12:28:52.121519: step 17400, loss = 2.00 (6715.9 examples/sec; 0.019 sec/batch)
2018-01-30 12:28:55.919954: step 17600, loss = 2.06 (6739.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:28:59.289517: step 17800, loss = 2.23 (7597.4 examples/sec; 0.017 sec/batch)
2018-01-30 12:29:01.133464: step 18000, loss = 1.85 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:02.986417: step 18200, loss = 2.04 (13815.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:04.805707: step 18400, loss = 2.08 (14071.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:06.665282: step 18600, loss = 2.19 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:08.540482: step 18800, loss = 2.14 (13651.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:11.712695: step 19000, loss = 1.87 (8070.1 examples/sec; 0.016 sec/batch)
2018-01-30 12:29:15.619361: step 19200, loss = 2.00 (6552.9 examples/sec; 0.020 sec/batch)
2018-01-30 12:29:19.526030: step 19400, loss = 2.00 (6552.9 examples/sec; 0.020 sec/batch)
2018-01-30 12:29:23.327149: step 19600, loss = 1.99 (6734.9 examples/sec; 0.019 sec/batch)
2018-01-30 12:29:25.162871: step 19800, loss = 2.03 (13945.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:27.009131: step 20000, loss = 1.88 (13865.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:28.844734: step 20200, loss = 2.04 (13946.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:30.719934: step 20400, loss = 2.20 (13651.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:32.592849: step 20600, loss = 2.04 (13668.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:34.968102: step 20800, loss = 1.94 (10777.8 examples/sec; 0.012 sec/batch)
2018-01-30 12:29:38.843515: step 21000, loss = 2.12 (6605.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:29:42.890823: step 21200, loss = 2.12 (6325.2 examples/sec; 0.020 sec/batch)
2018-01-30 12:29:46.598665: step 21400, loss = 1.95 (6904.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:29:49.240731: step 21600, loss = 2.12 (9689.4 examples/sec; 0.013 sec/batch)
2018-01-30 12:29:51.066654: step 21800, loss = 2.01 (14020.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:52.892902: step 22000, loss = 2.20 (14017.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:54.732912: step 22200, loss = 1.93 (13913.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:56.575029: step 22400, loss = 1.86 (13897.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:29:59.718265: step 22600, loss = 2.05 (8144.5 examples/sec; 0.016 sec/batch)
2018-01-30 12:30:03.421783: step 22800, loss = 2.07 (6912.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:30:07.205048: step 23000, loss = 2.04 (6766.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:30:10.999138: step 23200, loss = 1.94 (6747.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:30:13.323010: step 23400, loss = 2.14 (11016.1 examples/sec; 0.012 sec/batch)
2018-01-30 12:30:15.176685: step 23600, loss = 1.91 (13810.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:30:17.019338: step 23800, loss = 2.07 (13893.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:30:18.838683: step 24000, loss = 2.11 (14071.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:30:20.667002: step 24200, loss = 1.93 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:30:22.582136: step 24400, loss = 2.01 (13367.2 examples/sec; 0.010 sec/batch)
2018-01-30 12:30:26.082509: step 24600, loss = 2.02 (7313.5 examples/sec; 0.018 sec/batch)
2018-01-30 12:30:29.800602: step 24800, loss = 1.99 (6885.2 examples/sec; 0.019 sec/batch)
2018-01-30 12:30:33.883463: step 25000, loss = 1.90 (6270.1 examples/sec; 0.020 sec/batch)
2018-01-30 12:30:37.418865: step 25200, loss = 2.15 (7241.0 examples/sec; 0.018 sec/batch)
2018-01-30 12:30:39.262626: step 25400, loss = 2.08 (13884.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:30:41.129279: step 25600, loss = 2.07 (13714.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:30:42.938847: step 25800, loss = 1.86 (14147.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:30:44.767860: step 26000, loss = 2.17 (13996.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:30:46.627435: step 26200, loss = 1.98 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:30:49.846527: step 26400, loss = 2.21 (7952.6 examples/sec; 0.016 sec/batch)
2018-01-30 12:30:53.768821: step 26600, loss = 2.04 (6526.8 examples/sec; 0.020 sec/batch)
2018-01-30 12:30:57.538733: step 26800, loss = 2.12 (6790.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:31:01.523823: step 27000, loss = 1.84 (6423.9 examples/sec; 0.020 sec/batch)
2018-01-30 12:31:03.359414: step 27200, loss = 2.17 (13946.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:31:05.197728: step 27400, loss = 2.10 (13925.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:31:07.077228: step 27600, loss = 1.97 (13620.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:31:08.917837: step 27800, loss = 2.07 (13908.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:31:11.206000: step 28000, loss = 2.13 (11188.0 examples/sec; 0.011 sec/batch)
2018-01-30 12:31:14.878266: step 28200, loss = 2.06 (6971.2 examples/sec; 0.018 sec/batch)
2018-01-30 12:31:18.819941: step 28400, loss = 2.00 (6494.7 examples/sec; 0.020 sec/batch)
2018-01-30 12:31:22.600987: step 28600, loss = 2.11 (6770.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:31:25.545680: step 28800, loss = 2.15 (8693.6 examples/sec; 0.015 sec/batch)
2018-01-30 12:31:27.406689: step 29000, loss = 2.05 (13756.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:31:29.250298: step 29200, loss = 1.91 (13885.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:31:31.112153: step 29400, loss = 1.98 (13749.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:31:32.950358: step 29600, loss = 1.98 (13926.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:31:34.778678: step 29800, loss = 2.14 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:31:37.927153: step 30000, loss = 1.99 (8130.9 examples/sec; 0.016 sec/batch)
2018-01-30 12:31:41.776391: step 30200, loss = 2.02 (6650.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:31:45.684302: step 30400, loss = 2.10 (6550.8 examples/sec; 0.020 sec/batch)
2018-01-30 12:31:49.492073: step 30600, loss = 2.01 (6723.1 examples/sec; 0.019 sec/batch)
2018-01-30 12:31:51.405191: step 30800, loss = 2.13 (13381.3 examples/sec; 0.010 sec/batch)
2018-01-30 12:31:53.246983: step 31000, loss = 2.11 (13899.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:31:55.077572: step 31200, loss = 2.04 (13984.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:31:56.907889: step 31400, loss = 1.96 (13986.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:31:59.010450: step 31600, loss = 2.10 (12175.6 examples/sec; 0.011 sec/batch)
2018-01-30 12:32:01.431991: step 31800, loss = 2.08 (10571.8 examples/sec; 0.012 sec/batch)
2018-01-30 12:32:05.244129: step 32000, loss = 2.01 (6715.4 examples/sec; 0.019 sec/batch)
2018-01-30 12:32:09.114429: step 32200, loss = 2.12 (6614.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:32:12.925565: step 32400, loss = 1.99 (6717.2 examples/sec; 0.019 sec/batch)
2018-01-30 12:32:15.712183: step 32600, loss = 2.03 (9186.8 examples/sec; 0.014 sec/batch)
2018-01-30 12:32:17.556130: step 32800, loss = 2.08 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:32:19.400075: step 33000, loss = 2.05 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:32:21.260715: step 33200, loss = 2.17 (13758.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:32:23.104663: step 33400, loss = 2.08 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:32:24.955538: step 33600, loss = 1.98 (13831.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:32:28.225420: step 33800, loss = 1.94 (7829.0 examples/sec; 0.016 sec/batch)
2018-01-30 12:32:32.089869: step 34000, loss = 2.08 (6624.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:32:36.075448: step 34200, loss = 2.11 (6423.2 examples/sec; 0.020 sec/batch)
2018-01-30 12:32:39.824324: step 34400, loss = 2.00 (6828.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:32:41.681630: step 34600, loss = 2.07 (13783.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:32:43.541203: step 34800, loss = 2.02 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:32:45.385150: step 35000, loss = 2.03 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:32:47.229096: step 35200, loss = 2.03 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:32:49.057416: step 35400, loss = 2.00 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:32:51.354537: step 35600, loss = 2.24 (11144.4 examples/sec; 0.011 sec/batch)
2018-01-30 12:32:55.104937: step 35800, loss = 1.98 (6825.9 examples/sec; 0.019 sec/batch)
2018-01-30 12:33:00.730536: step 36000, loss = 1.93 (4550.6 examples/sec; 0.028 sec/batch)
2018-01-30 12:33:03.683949: step 36200, loss = 1.96 (8667.9 examples/sec; 0.015 sec/batch)
2018-01-30 12:33:05.550212: step 36400, loss = 1.99 (13717.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:33:07.394855: step 36600, loss = 2.11 (13878.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:33:09.223175: step 36800, loss = 2.10 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:33:11.083024: step 37000, loss = 2.07 (13764.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:33:12.911351: step 37200, loss = 2.06 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:33:16.188887: step 37400, loss = 1.93 (7810.7 examples/sec; 0.016 sec/batch)
2018-01-30 12:33:19.876779: step 37600, loss = 2.03 (6941.6 examples/sec; 0.018 sec/batch)
2018-01-30 12:33:23.682498: step 37800, loss = 2.09 (6726.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:33:27.511682: step 38000, loss = 1.95 (6685.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:33:29.482407: step 38200, loss = 2.03 (12990.1 examples/sec; 0.010 sec/batch)
2018-01-30 12:33:31.332353: step 38400, loss = 2.03 (13838.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:33:33.183112: step 38600, loss = 2.28 (13832.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:33:35.023641: step 38800, loss = 2.10 (13909.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:33:36.872769: step 39000, loss = 1.99 (13844.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:33:39.279276: step 39200, loss = 1.96 (10637.8 examples/sec; 0.012 sec/batch)
2018-01-30 12:33:43.076557: step 39400, loss = 1.92 (6741.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:33:46.764450: step 39600, loss = 2.06 (6941.6 examples/sec; 0.018 sec/batch)
2018-01-30 12:33:50.568276: step 39800, loss = 2.03 (6730.1 examples/sec; 0.019 sec/batch)
2018-01-30 12:33:53.652692: step 40000, loss = 2.11 (8299.8 examples/sec; 0.015 sec/batch)
2018-01-30 12:33:55.497879: step 40200, loss = 1.97 (13873.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:33:57.357453: step 40400, loss = 1.90 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:33:59.435800: step 40600, loss = 2.12 (12317.5 examples/sec; 0.010 sec/batch)
2018-01-30 12:34:01.332930: step 40800, loss = 2.08 (13494.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:34:03.177321: step 41000, loss = 1.85 (13879.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:34:06.472926: step 41200, loss = 2.03 (7767.9 examples/sec; 0.016 sec/batch)
2018-01-30 12:34:10.199088: step 41400, loss = 2.16 (6870.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:34:14.027620: step 41600, loss = 2.10 (6686.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:34:17.699887: step 41800, loss = 2.08 (6971.2 examples/sec; 0.018 sec/batch)
2018-01-30 12:34:19.813650: step 42000, loss = 1.93 (12111.1 examples/sec; 0.011 sec/batch)
2018-01-30 12:34:21.641971: step 42200, loss = 2.04 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:34:23.501545: step 42400, loss = 1.99 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:34:25.314238: step 42600, loss = 1.96 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:34:27.142557: step 42800, loss = 2.00 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:34:29.458667: step 43000, loss = 1.99 (11053.0 examples/sec; 0.012 sec/batch)
2018-01-30 12:34:33.220852: step 43200, loss = 2.14 (6804.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:34:37.075065: step 43400, loss = 2.01 (6642.1 examples/sec; 0.019 sec/batch)
2018-01-30 12:34:40.880416: step 43600, loss = 2.04 (6727.4 examples/sec; 0.019 sec/batch)
2018-01-30 12:34:43.966209: step 43800, loss = 2.03 (8296.1 examples/sec; 0.015 sec/batch)
2018-01-30 12:34:45.827465: step 44000, loss = 2.13 (13754.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:34:47.677779: step 44200, loss = 2.03 (13835.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:34:49.490473: step 44400, loss = 1.93 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:34:51.333748: step 44600, loss = 2.06 (13888.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:34:53.146443: step 44800, loss = 1.99 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:34:56.334282: step 45000, loss = 2.04 (8030.5 examples/sec; 0.016 sec/batch)
2018-01-30 12:35:02.133397: step 45200, loss = 2.10 (4414.5 examples/sec; 0.029 sec/batch)
2018-01-30 12:35:05.876693: step 45400, loss = 2.04 (6838.9 examples/sec; 0.019 sec/batch)
2018-01-30 12:35:07.933838: step 45600, loss = 2.11 (12444.4 examples/sec; 0.010 sec/batch)
2018-01-30 12:35:09.777784: step 45800, loss = 2.06 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:35:11.617185: step 46000, loss = 2.11 (13917.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:35:13.476759: step 46200, loss = 2.00 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:35:15.300267: step 46400, loss = 2.15 (14038.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:35:17.605101: step 46600, loss = 2.15 (11107.1 examples/sec; 0.012 sec/batch)
2018-01-30 12:35:21.605527: step 46800, loss = 2.10 (6399.3 examples/sec; 0.020 sec/batch)
2018-01-30 12:35:25.371556: step 47000, loss = 2.02 (6797.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:35:29.043820: step 47200, loss = 2.01 (6971.2 examples/sec; 0.018 sec/batch)
2018-01-30 12:35:31.919127: step 47400, loss = 1.93 (8903.4 examples/sec; 0.014 sec/batch)
2018-01-30 12:35:33.754794: step 47600, loss = 2.00 (13945.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:35:35.583113: step 47800, loss = 2.09 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:35:37.420330: step 48000, loss = 2.15 (13934.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:35:39.248651: step 48200, loss = 2.07 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:35:41.061344: step 48400, loss = 2.00 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:35:44.764864: step 48600, loss = 2.04 (6912.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:35:48.437130: step 48800, loss = 2.01 (6971.2 examples/sec; 0.018 sec/batch)
2018-01-30 12:35:52.175555: step 49000, loss = 2.15 (6847.8 examples/sec; 0.019 sec/batch)
2018-01-30 12:35:55.860355: step 49200, loss = 2.04 (6947.5 examples/sec; 0.018 sec/batch)
2018-01-30 12:35:57.894430: step 49400, loss = 2.04 (12585.6 examples/sec; 0.010 sec/batch)
2018-01-30 12:35:59.960568: step 49600, loss = 1.97 (12390.3 examples/sec; 0.010 sec/batch)
2018-01-30 12:36:01.788888: step 49800, loss = 1.93 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:36:03.601581: step 50000, loss = 2.00 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:36:05.447312: step 50200, loss = 2.09 (13869.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:36:07.916327: step 50400, loss = 2.13 (10368.5 examples/sec; 0.012 sec/batch)
2018-01-30 12:36:11.541713: step 50600, loss = 2.04 (7061.3 examples/sec; 0.018 sec/batch)
2018-01-30 12:36:15.288105: step 50800, loss = 2.10 (6833.2 examples/sec; 0.019 sec/batch)
2018-01-30 12:36:19.148372: step 51000, loss = 2.03 (6631.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:36:22.030724: step 51200, loss = 2.01 (8881.6 examples/sec; 0.014 sec/batch)
2018-01-30 12:36:23.850442: step 51400, loss = 2.07 (14068.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:36:25.694388: step 51600, loss = 2.14 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:36:27.531623: step 51800, loss = 2.11 (13934.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:36:29.372710: step 52000, loss = 2.00 (13904.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:36:31.201026: step 52200, loss = 1.92 (14002.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:36:34.232599: step 52400, loss = 2.05 (8444.5 examples/sec; 0.015 sec/batch)
2018-01-30 12:36:37.839144: step 52600, loss = 1.91 (7098.2 examples/sec; 0.018 sec/batch)
2018-01-30 12:36:41.625214: step 52800, loss = 2.19 (6761.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:36:45.342244: step 53000, loss = 2.11 (6887.2 examples/sec; 0.019 sec/batch)
2018-01-30 12:36:47.999673: step 53200, loss = 1.86 (9633.4 examples/sec; 0.013 sec/batch)
2018-01-30 12:36:49.824917: step 53400, loss = 1.98 (14025.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:36:51.670038: step 53600, loss = 1.93 (13874.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:36:53.498359: step 53800, loss = 2.05 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:36:55.342304: step 54000, loss = 1.97 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:36:57.233131: step 54200, loss = 1.94 (13539.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:37:03.128972: step 54400, loss = 1.98 (4342.0 examples/sec; 0.029 sec/batch)
2018-01-30 12:37:06.791906: step 54600, loss = 1.94 (6988.9 examples/sec; 0.018 sec/batch)
2018-01-30 12:37:10.058904: step 54800, loss = 1.97 (7835.9 examples/sec; 0.016 sec/batch)
2018-01-30 12:37:11.892146: step 55000, loss = 2.10 (13964.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:37:13.735285: step 55200, loss = 2.08 (13889.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:37:15.547978: step 55400, loss = 1.96 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:37:17.390985: step 55600, loss = 2.05 (13890.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:37:19.234932: step 55800, loss = 2.08 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:37:21.922718: step 56000, loss = 2.19 (9524.6 examples/sec; 0.013 sec/batch)
2018-01-30 12:37:25.759203: step 56200, loss = 2.00 (6672.8 examples/sec; 0.019 sec/batch)
2018-01-30 12:37:29.575675: step 56400, loss = 1.89 (6707.8 examples/sec; 0.019 sec/batch)
2018-01-30 12:37:33.425915: step 56600, loss = 2.04 (6648.9 examples/sec; 0.019 sec/batch)
2018-01-30 12:37:35.891230: step 56800, loss = 2.09 (10384.1 examples/sec; 0.012 sec/batch)
2018-01-30 12:37:37.719550: step 57000, loss = 2.11 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:37:39.547869: step 57200, loss = 1.99 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:37:41.404562: step 57400, loss = 1.99 (13788.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:37:43.224413: step 57600, loss = 1.97 (14067.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:37:45.115239: step 57800, loss = 1.99 (13539.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:37:48.365587: step 58000, loss = 2.07 (7876.1 examples/sec; 0.016 sec/batch)
2018-01-30 12:37:52.147240: step 58200, loss = 2.09 (6769.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:37:56.022653: step 58400, loss = 1.95 (6605.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:37:59.882439: step 58600, loss = 2.04 (6632.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:38:01.710760: step 58800, loss = 2.11 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:03.538776: step 59000, loss = 2.07 (14004.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:05.403299: step 59200, loss = 1.97 (13730.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:07.231618: step 59400, loss = 2.07 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:09.112569: step 59600, loss = 1.93 (13610.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:12.782278: step 59800, loss = 2.08 (6976.0 examples/sec; 0.018 sec/batch)
2018-01-30 12:38:16.792315: step 60000, loss = 1.86 (6384.0 examples/sec; 0.020 sec/batch)
2018-01-30 12:38:20.595239: step 60200, loss = 2.03 (6731.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:38:24.045704: step 60400, loss = 2.26 (7419.3 examples/sec; 0.017 sec/batch)
2018-01-30 12:38:25.842771: step 60600, loss = 1.98 (14245.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:27.702344: step 60800, loss = 2.04 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:29.530665: step 61000, loss = 1.93 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:31.354025: step 61200, loss = 2.01 (14040.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:33.197972: step 61400, loss = 1.95 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:35.823251: step 61600, loss = 2.08 (9751.3 examples/sec; 0.013 sec/batch)
2018-01-30 12:38:39.645639: step 61800, loss = 1.96 (6697.4 examples/sec; 0.019 sec/batch)
2018-01-30 12:38:43.474100: step 62000, loss = 2.03 (6686.8 examples/sec; 0.019 sec/batch)
2018-01-30 12:38:47.379487: step 62200, loss = 2.06 (6555.0 examples/sec; 0.020 sec/batch)
2018-01-30 12:38:49.866090: step 62400, loss = 2.08 (10295.2 examples/sec; 0.012 sec/batch)
2018-01-30 12:38:51.694410: step 62600, loss = 1.92 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:53.524104: step 62800, loss = 1.98 (13991.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:55.351140: step 63000, loss = 2.17 (14011.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:57.179460: step 63200, loss = 2.13 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:38:59.691904: step 63400, loss = 2.06 (10189.3 examples/sec; 0.013 sec/batch)
2018-01-30 12:39:03.561750: step 63600, loss = 2.09 (6615.2 examples/sec; 0.019 sec/batch)
2018-01-30 12:39:07.275663: step 63800, loss = 2.06 (6893.0 examples/sec; 0.019 sec/batch)
2018-01-30 12:39:10.929915: step 64000, loss = 2.00 (7005.5 examples/sec; 0.018 sec/batch)
2018-01-30 12:39:14.102937: step 64200, loss = 2.18 (8068.0 examples/sec; 0.016 sec/batch)
2018-01-30 12:39:16.028743: step 64400, loss = 2.11 (13293.1 examples/sec; 0.010 sec/batch)
2018-01-30 12:39:17.888317: step 64600, loss = 1.85 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:39:19.751239: step 64800, loss = 1.89 (13741.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:39:21.585510: step 65000, loss = 1.97 (13956.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:39:23.441282: step 65200, loss = 1.98 (13794.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:39:26.644748: step 65400, loss = 2.12 (7991.3 examples/sec; 0.016 sec/batch)
2018-01-30 12:39:30.457655: step 65600, loss = 1.97 (6714.0 examples/sec; 0.019 sec/batch)
2018-01-30 12:39:34.395575: step 65800, loss = 2.16 (6500.9 examples/sec; 0.020 sec/batch)
2018-01-30 12:39:38.199602: step 66000, loss = 2.15 (6729.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:39:39.993770: step 66200, loss = 2.10 (14268.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:39:41.858188: step 66400, loss = 1.90 (13730.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:39:43.693215: step 66600, loss = 1.98 (13950.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:39:45.524470: step 66800, loss = 2.01 (13979.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:39:47.350505: step 67000, loss = 1.93 (14019.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:39:49.597182: step 67200, loss = 1.86 (11394.6 examples/sec; 0.011 sec/batch)
2018-01-30 12:39:53.347582: step 67400, loss = 2.00 (6825.9 examples/sec; 0.019 sec/batch)
2018-01-30 12:39:57.004222: step 67600, loss = 2.00 (7001.0 examples/sec; 0.018 sec/batch)
2018-01-30 12:40:02.030301: step 67800, loss = 2.12 (5093.4 examples/sec; 0.025 sec/batch)
2018-01-30 12:40:03.858622: step 68000, loss = 2.01 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:05.731156: step 68200, loss = 1.90 (13671.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:07.575103: step 68400, loss = 2.20 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:09.411859: step 68600, loss = 1.77 (13937.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:11.240179: step 68800, loss = 2.10 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:14.002865: step 69000, loss = 2.02 (9266.3 examples/sec; 0.014 sec/batch)
2018-01-30 12:40:17.659507: step 69200, loss = 2.05 (7001.0 examples/sec; 0.018 sec/batch)
2018-01-30 12:40:21.403929: step 69400, loss = 2.25 (6836.8 examples/sec; 0.019 sec/batch)
2018-01-30 12:40:25.230199: step 69600, loss = 1.84 (6690.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:40:27.808600: step 69800, loss = 2.12 (9928.6 examples/sec; 0.013 sec/batch)
2018-01-30 12:40:29.628907: step 70000, loss = 2.04 (14063.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:31.473922: step 70200, loss = 2.11 (13875.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:33.317870: step 70400, loss = 2.03 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:35.130562: step 70600, loss = 2.06 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:36.978239: step 70800, loss = 1.91 (13855.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:40.650505: step 71000, loss = 2.03 (6971.2 examples/sec; 0.018 sec/batch)
2018-01-30 12:40:44.197759: step 71200, loss = 2.05 (7216.9 examples/sec; 0.018 sec/batch)
2018-01-30 12:40:48.182559: step 71400, loss = 1.94 (6424.4 examples/sec; 0.020 sec/batch)
2018-01-30 12:40:51.721629: step 71600, loss = 2.05 (7233.5 examples/sec; 0.018 sec/batch)
2018-01-30 12:40:53.522931: step 71800, loss = 2.20 (14211.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:55.381967: step 72000, loss = 2.04 (13770.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:57.214374: step 72200, loss = 1.98 (13970.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:40:59.299554: step 72400, loss = 1.97 (12277.1 examples/sec; 0.010 sec/batch)
2018-01-30 12:41:01.174754: step 72600, loss = 1.96 (13651.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:41:03.945795: step 72800, loss = 1.99 (9238.4 examples/sec; 0.014 sec/batch)
2018-01-30 12:41:07.935406: step 73000, loss = 2.02 (6416.7 examples/sec; 0.020 sec/batch)
2018-01-30 12:41:11.633300: step 73200, loss = 1.93 (6922.9 examples/sec; 0.018 sec/batch)
2018-01-30 12:41:15.455708: step 73400, loss = 2.11 (6697.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:41:17.772998: step 73600, loss = 2.06 (11047.4 examples/sec; 0.012 sec/batch)
2018-01-30 12:41:19.603977: step 73800, loss = 1.98 (13981.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:41:21.426708: step 74000, loss = 2.17 (14044.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:41:23.270656: step 74200, loss = 1.92 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:41:25.083348: step 74400, loss = 2.15 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:41:26.911668: step 74600, loss = 2.01 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:41:30.333908: step 74800, loss = 1.99 (7480.5 examples/sec; 0.017 sec/batch)
2018-01-30 12:41:34.087847: step 75000, loss = 1.94 (6819.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:41:37.718503: step 75200, loss = 2.03 (7051.1 examples/sec; 0.018 sec/batch)
2018-01-30 12:41:41.387444: step 75400, loss = 1.89 (6977.5 examples/sec; 0.018 sec/batch)
2018-01-30 12:41:43.292109: step 75600, loss = 2.08 (13440.7 examples/sec; 0.010 sec/batch)
2018-01-30 12:41:45.136055: step 75800, loss = 1.96 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:41:46.980002: step 76000, loss = 2.04 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:41:48.817914: step 76200, loss = 2.19 (13928.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:41:50.646235: step 76400, loss = 2.11 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:41:53.005861: step 76600, loss = 2.18 (10849.2 examples/sec; 0.012 sec/batch)
2018-01-30 12:41:56.733441: step 76800, loss = 1.97 (6867.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:42:02.350721: step 77000, loss = 2.12 (4557.4 examples/sec; 0.028 sec/batch)
2018-01-30 12:42:05.359531: step 77200, loss = 2.09 (8508.3 examples/sec; 0.015 sec/batch)
2018-01-30 12:42:07.218750: step 77400, loss = 2.11 (13769.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:42:09.031442: step 77600, loss = 1.99 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:42:10.889063: step 77800, loss = 2.14 (13781.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:42:12.748637: step 78000, loss = 2.13 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:42:14.576957: step 78200, loss = 1.90 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:42:17.656213: step 78400, loss = 2.16 (8313.7 examples/sec; 0.015 sec/batch)
2018-01-30 12:42:21.390986: step 78600, loss = 1.99 (6854.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:42:25.218241: step 78800, loss = 1.90 (6688.9 examples/sec; 0.019 sec/batch)
2018-01-30 12:42:29.056016: step 79000, loss = 1.96 (6670.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:42:31.098385: step 79200, loss = 2.04 (12534.5 examples/sec; 0.010 sec/batch)
2018-01-30 12:42:32.977027: step 79400, loss = 2.09 (13626.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:42:34.801078: step 79600, loss = 2.00 (14034.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:42:36.623924: step 79800, loss = 2.00 (14044.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:42:38.498143: step 80000, loss = 2.11 (13659.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:42:40.746049: step 80200, loss = 2.01 (11388.4 examples/sec; 0.011 sec/batch)
2018-01-30 12:42:44.399766: step 80400, loss = 2.16 (7006.6 examples/sec; 0.018 sec/batch)
2018-01-30 12:42:48.411435: step 80600, loss = 2.04 (6381.4 examples/sec; 0.020 sec/batch)
2018-01-30 12:42:52.122296: step 80800, loss = 1.97 (6898.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:42:54.941617: step 81000, loss = 2.21 (9080.2 examples/sec; 0.014 sec/batch)
2018-01-30 12:42:56.782926: step 81200, loss = 2.08 (13903.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:42:58.861534: step 81400, loss = 1.99 (12315.9 examples/sec; 0.010 sec/batch)
2018-01-30 12:43:00.716074: step 81600, loss = 2.04 (13804.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:43:02.549334: step 81800, loss = 1.99 (13964.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:43:04.596427: step 82000, loss = 2.01 (12505.5 examples/sec; 0.010 sec/batch)
2018-01-30 12:43:08.424960: step 82200, loss = 1.92 (6686.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:43:12.238707: step 82400, loss = 2.02 (6712.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:43:15.736152: step 82600, loss = 2.06 (7319.6 examples/sec; 0.017 sec/batch)
2018-01-30 12:43:19.241746: step 82800, loss = 2.02 (7302.6 examples/sec; 0.018 sec/batch)
2018-01-30 12:43:21.090585: step 83000, loss = 2.06 (13846.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:43:22.959005: step 83200, loss = 2.01 (13701.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:43:24.868959: step 83400, loss = 1.98 (13403.5 examples/sec; 0.010 sec/batch)
2018-01-30 12:43:26.693552: step 83600, loss = 2.06 (14030.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:43:28.514222: step 83800, loss = 2.01 (14060.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:43:31.312994: step 84000, loss = 1.96 (9146.9 examples/sec; 0.014 sec/batch)
2018-01-30 12:43:35.189947: step 84200, loss = 2.11 (6603.1 examples/sec; 0.019 sec/batch)
2018-01-30 12:43:38.893467: step 84400, loss = 2.07 (6912.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:43:42.601065: step 84600, loss = 2.00 (6904.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:43:45.050607: step 84800, loss = 2.02 (10450.9 examples/sec; 0.012 sec/batch)
2018-01-30 12:43:46.907983: step 85000, loss = 2.01 (13782.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:43:48.730760: step 85200, loss = 2.13 (14044.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:43:50.543453: step 85400, loss = 2.15 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:43:52.403026: step 85600, loss = 2.05 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:43:54.217116: step 85800, loss = 1.98 (14111.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:43:57.858128: step 86000, loss = 2.05 (7031.0 examples/sec; 0.018 sec/batch)
2018-01-30 12:44:03.078139: step 86200, loss = 2.02 (4904.2 examples/sec; 0.026 sec/batch)
2018-01-30 12:44:06.817872: step 86400, loss = 2.14 (6845.4 examples/sec; 0.019 sec/batch)
2018-01-30 12:44:09.092891: step 86600, loss = 1.91 (11252.7 examples/sec; 0.011 sec/batch)
2018-01-30 12:44:10.946933: step 86800, loss = 2.14 (13807.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:44:12.760337: step 87000, loss = 2.04 (14117.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:44:14.609140: step 87200, loss = 1.98 (13846.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:44:16.445131: step 87400, loss = 1.97 (13943.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:44:18.276976: step 87600, loss = 2.19 (13975.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:44:21.898294: step 87800, loss = 2.08 (7069.3 examples/sec; 0.018 sec/batch)
2018-01-30 12:44:25.712000: step 88000, loss = 2.09 (6712.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:44:29.437910: step 88200, loss = 1.92 (6870.8 examples/sec; 0.019 sec/batch)
2018-01-30 12:44:32.972506: step 88400, loss = 1.98 (7242.7 examples/sec; 0.018 sec/batch)
2018-01-30 12:44:34.962482: step 88600, loss = 2.08 (12864.5 examples/sec; 0.010 sec/batch)
2018-01-30 12:44:36.800752: step 88800, loss = 2.04 (13926.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:44:38.629072: step 89000, loss = 1.98 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:44:40.468814: step 89200, loss = 1.99 (13915.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:44:42.297134: step 89400, loss = 2.02 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:44:44.497976: step 89600, loss = 1.89 (11631.9 examples/sec; 0.011 sec/batch)
2018-01-30 12:44:48.420269: step 89800, loss = 1.90 (6526.8 examples/sec; 0.020 sec/batch)
2018-01-30 12:44:52.436323: step 90000, loss = 1.94 (6374.4 examples/sec; 0.020 sec/batch)
2018-01-30 12:44:56.267658: step 90200, loss = 2.00 (6681.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:44:59.033624: step 90400, loss = 1.81 (9255.4 examples/sec; 0.014 sec/batch)
2018-01-30 12:45:00.872133: step 90600, loss = 2.08 (13924.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:02.703380: step 90800, loss = 1.89 (13979.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:04.537111: step 91000, loss = 1.90 (13960.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:06.375770: step 91200, loss = 2.11 (13923.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:08.327785: step 91400, loss = 2.09 (13114.7 examples/sec; 0.010 sec/batch)
2018-01-30 12:45:12.093812: step 91600, loss = 1.96 (6797.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:45:15.676533: step 91800, loss = 2.09 (7145.4 examples/sec; 0.018 sec/batch)
2018-01-30 12:45:19.374196: step 92000, loss = 2.14 (6923.3 examples/sec; 0.018 sec/batch)
2018-01-30 12:45:22.904486: step 92200, loss = 1.83 (7251.5 examples/sec; 0.018 sec/batch)
2018-01-30 12:45:24.717177: step 92400, loss = 1.96 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:26.561124: step 92600, loss = 1.88 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:28.378516: step 92800, loss = 2.00 (14086.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:30.211461: step 93000, loss = 2.04 (13966.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:32.036155: step 93200, loss = 1.94 (14029.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:34.780235: step 93400, loss = 2.14 (9329.2 examples/sec; 0.014 sec/batch)
2018-01-30 12:45:38.486504: step 93600, loss = 2.05 (6907.2 examples/sec; 0.019 sec/batch)
2018-01-30 12:45:42.391891: step 93800, loss = 2.08 (6555.0 examples/sec; 0.020 sec/batch)
2018-01-30 12:45:46.252123: step 94000, loss = 1.97 (6631.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:45:48.641327: step 94200, loss = 1.88 (10714.9 examples/sec; 0.012 sec/batch)
2018-01-30 12:45:50.465401: step 94400, loss = 2.06 (14034.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:52.282274: step 94600, loss = 2.18 (14090.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:54.110699: step 94800, loss = 1.97 (14001.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:55.936232: step 95000, loss = 2.11 (14023.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:45:57.778485: step 95200, loss = 2.04 (13896.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:46:03.669538: step 95400, loss = 1.92 (4345.6 examples/sec; 0.029 sec/batch)
2018-01-30 12:46:07.393442: step 95600, loss = 2.07 (6874.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:46:10.544215: step 95800, loss = 1.99 (8125.0 examples/sec; 0.016 sec/batch)
2018-01-30 12:46:12.358073: step 96000, loss = 1.90 (14113.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:46:14.210690: step 96200, loss = 2.13 (13818.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:46:16.033090: step 96400, loss = 2.02 (14047.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:46:17.877038: step 96600, loss = 2.11 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:46:19.710261: step 96800, loss = 2.05 (13964.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:46:22.835595: step 97000, loss = 2.15 (8191.1 examples/sec; 0.016 sec/batch)
2018-01-30 12:46:26.523489: step 97200, loss = 1.96 (6941.6 examples/sec; 0.018 sec/batch)
2018-01-30 12:46:30.324689: step 97400, loss = 2.24 (6734.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:46:34.342137: step 97600, loss = 2.17 (6372.2 examples/sec; 0.020 sec/batch)
2018-01-30 12:46:36.423666: step 97800, loss = 2.10 (12298.7 examples/sec; 0.010 sec/batch)
2018-01-30 12:46:38.251984: step 98000, loss = 1.93 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:46:40.095932: step 98200, loss = 2.01 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:46:41.939879: step 98400, loss = 1.98 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:46:43.799451: step 98600, loss = 2.03 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:46:45.815290: step 98800, loss = 2.05 (12699.4 examples/sec; 0.010 sec/batch)
2018-01-30 12:46:49.315665: step 99000, loss = 2.15 (7313.5 examples/sec; 0.018 sec/batch)
2018-01-30 12:46:53.087256: step 99200, loss = 2.06 (6787.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:46:56.800130: step 99400, loss = 2.00 (6894.9 examples/sec; 0.019 sec/batch)
2018-01-30 12:47:00.424340: step 99600, loss = 2.27 (7063.6 examples/sec; 0.018 sec/batch)
2018-01-30 12:47:02.251552: step 99800, loss = 2.06 (14010.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:04.094885: step 100000, loss = 2.08 (13887.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:05.937404: step 100200, loss = 1.94 (13894.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:07.781351: step 100400, loss = 1.98 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:09.814889: step 100600, loss = 2.03 (12588.9 examples/sec; 0.010 sec/batch)
2018-01-30 12:47:13.622644: step 100800, loss = 1.98 (6723.1 examples/sec; 0.019 sec/batch)
2018-01-30 12:47:17.396178: step 101000, loss = 2.00 (6784.1 examples/sec; 0.019 sec/batch)
2018-01-30 12:47:21.142141: step 101200, loss = 2.14 (6834.0 examples/sec; 0.019 sec/batch)
2018-01-30 12:47:24.408813: step 101400, loss = 2.01 (7836.7 examples/sec; 0.016 sec/batch)
2018-01-30 12:47:26.252759: step 101600, loss = 1.92 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:28.112333: step 101800, loss = 2.01 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:29.925636: step 102000, loss = 2.12 (14117.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:31.773823: step 102200, loss = 2.08 (13851.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:33.602144: step 102400, loss = 2.06 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:36.164916: step 102600, loss = 2.17 (9989.2 examples/sec; 0.013 sec/batch)
2018-01-30 12:47:39.962196: step 102800, loss = 1.95 (6741.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:47:43.707843: step 103000, loss = 2.12 (6834.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:47:47.558365: step 103200, loss = 2.11 (6648.4 examples/sec; 0.019 sec/batch)
2018-01-30 12:47:50.288825: step 103400, loss = 1.86 (9375.7 examples/sec; 0.014 sec/batch)
2018-01-30 12:47:52.132772: step 103600, loss = 2.06 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:53.949101: step 103800, loss = 2.04 (14094.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:55.775945: step 104000, loss = 1.91 (14013.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:57.611540: step 104200, loss = 1.93 (13946.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:47:59.721139: step 104400, loss = 2.13 (12135.0 examples/sec; 0.011 sec/batch)
2018-01-30 12:48:03.502793: step 104600, loss = 2.00 (6769.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:48:07.463731: step 104800, loss = 2.05 (6463.1 examples/sec; 0.020 sec/batch)
2018-01-30 12:48:11.230297: step 105000, loss = 2.17 (6796.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:48:14.550233: step 105200, loss = 2.10 (7711.0 examples/sec; 0.017 sec/batch)
2018-01-30 12:48:16.401744: step 105400, loss = 2.04 (13826.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:48:18.243495: step 105600, loss = 2.05 (13899.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:48:20.049650: step 105800, loss = 2.04 (14173.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:48:21.887703: step 106000, loss = 2.03 (13927.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:48:23.728454: step 106200, loss = 2.17 (13907.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:48:26.635223: step 106400, loss = 2.16 (8807.0 examples/sec; 0.015 sec/batch)
2018-01-30 12:48:30.476439: step 106600, loss = 1.98 (6664.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:48:34.230445: step 106800, loss = 1.97 (6819.4 examples/sec; 0.019 sec/batch)
2018-01-30 12:48:37.998610: step 107000, loss = 2.19 (6793.8 examples/sec; 0.019 sec/batch)
2018-01-30 12:48:40.333180: step 107200, loss = 2.13 (10965.6 examples/sec; 0.012 sec/batch)
2018-01-30 12:48:42.147232: step 107400, loss = 2.00 (14112.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:48:44.012272: step 107600, loss = 2.08 (13726.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:48:45.823291: step 107800, loss = 2.04 (14135.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:48:47.651611: step 108000, loss = 1.91 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:48:49.517723: step 108200, loss = 1.98 (13718.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:48:53.064978: step 108400, loss = 2.08 (7216.8 examples/sec; 0.018 sec/batch)
2018-01-30 12:48:56.659111: step 108600, loss = 1.98 (7122.7 examples/sec; 0.018 sec/batch)
2018-01-30 12:49:02.214992: step 108800, loss = 2.01 (4607.7 examples/sec; 0.028 sec/batch)
2018-01-30 12:49:04.028974: step 109000, loss = 2.09 (14112.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:49:05.872920: step 109200, loss = 1.97 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:49:07.697652: step 109400, loss = 2.11 (14029.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:49:09.542418: step 109600, loss = 1.98 (13877.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:49:11.377803: step 109800, loss = 2.14 (13948.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:49:14.492766: step 110000, loss = 1.88 (8218.4 examples/sec; 0.016 sec/batch)
2018-01-30 12:49:18.391134: step 110200, loss = 1.97 (6566.9 examples/sec; 0.019 sec/batch)
2018-01-30 12:49:22.285291: step 110400, loss = 1.87 (6574.0 examples/sec; 0.019 sec/batch)
2018-01-30 12:49:25.985687: step 110600, loss = 2.11 (6918.2 examples/sec; 0.019 sec/batch)
2018-01-30 12:49:27.919993: step 110800, loss = 2.17 (13234.7 examples/sec; 0.010 sec/batch)
2018-01-30 12:49:29.763941: step 111000, loss = 1.93 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:49:31.623514: step 111200, loss = 1.96 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:49:33.451833: step 111400, loss = 1.96 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:49:35.264526: step 111600, loss = 2.13 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:49:37.499140: step 111800, loss = 1.91 (11456.1 examples/sec; 0.011 sec/batch)
2018-01-30 12:49:41.233913: step 112000, loss = 1.94 (6854.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:49:45.015567: step 112200, loss = 1.95 (6769.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:49:48.918116: step 112400, loss = 2.16 (6559.8 examples/sec; 0.020 sec/batch)
2018-01-30 12:49:51.891929: step 112600, loss = 2.11 (8608.5 examples/sec; 0.015 sec/batch)
2018-01-30 12:49:53.717324: step 112800, loss = 2.10 (14024.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:49:55.545643: step 113000, loss = 2.13 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:49:57.371983: step 113200, loss = 2.05 (14017.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:49:59.429608: step 113400, loss = 2.16 (12441.5 examples/sec; 0.010 sec/batch)
2018-01-30 12:50:01.283167: step 113600, loss = 2.03 (13811.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:50:04.628734: step 113800, loss = 1.88 (7651.9 examples/sec; 0.017 sec/batch)
2018-01-30 12:50:08.529108: step 114000, loss = 2.16 (6563.5 examples/sec; 0.020 sec/batch)
2018-01-30 12:50:12.248905: step 114200, loss = 2.05 (6882.1 examples/sec; 0.019 sec/batch)
2018-01-30 12:50:15.933178: step 114400, loss = 1.92 (6948.5 examples/sec; 0.018 sec/batch)
2018-01-30 12:50:17.846894: step 114600, loss = 2.01 (13377.1 examples/sec; 0.010 sec/batch)
2018-01-30 12:50:19.691792: step 114800, loss = 1.89 (13876.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:50:21.511198: step 115000, loss = 2.02 (14070.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:50:23.349221: step 115200, loss = 2.12 (13928.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:50:25.189530: step 115400, loss = 1.97 (13910.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:50:27.364003: step 115600, loss = 2.03 (11773.0 examples/sec; 0.011 sec/batch)
2018-01-30 12:50:31.161283: step 115800, loss = 2.09 (6741.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:50:35.182859: step 116000, loss = 2.04 (6365.7 examples/sec; 0.020 sec/batch)
2018-01-30 12:50:39.142339: step 116200, loss = 2.01 (6465.5 examples/sec; 0.020 sec/batch)
2018-01-30 12:50:41.679642: step 116400, loss = 1.99 (10089.5 examples/sec; 0.013 sec/batch)
2018-01-30 12:50:43.478551: step 116600, loss = 2.12 (14230.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:50:45.306871: step 116800, loss = 2.07 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:50:47.133622: step 117000, loss = 2.06 (14014.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:50:48.954048: step 117200, loss = 2.16 (14062.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:50:50.801931: step 117400, loss = 2.14 (13853.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:50:54.505450: step 117600, loss = 2.15 (6912.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:50:58.209902: step 117800, loss = 2.01 (6910.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:51:03.533934: step 118000, loss = 1.92 (4808.4 examples/sec; 0.027 sec/batch)
2018-01-30 12:51:05.396830: step 118200, loss = 2.08 (13742.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:51:07.210573: step 118400, loss = 1.86 (14114.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:51:09.044680: step 118600, loss = 2.18 (13957.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:51:10.884085: step 118800, loss = 1.96 (13917.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:51:12.728032: step 119000, loss = 2.12 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:51:15.788850: step 119200, loss = 1.93 (8363.8 examples/sec; 0.015 sec/batch)
2018-01-30 12:51:19.403632: step 119400, loss = 1.97 (7082.0 examples/sec; 0.018 sec/batch)
2018-01-30 12:51:23.059584: step 119600, loss = 1.94 (7002.3 examples/sec; 0.018 sec/batch)
2018-01-30 12:51:26.757419: step 119800, loss = 2.03 (6923.0 examples/sec; 0.018 sec/batch)
2018-01-30 12:51:29.259374: step 120000, loss = 2.14 (10232.0 examples/sec; 0.013 sec/batch)
2018-01-30 12:51:31.116699: step 120200, loss = 2.06 (13783.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:51:32.924302: step 120400, loss = 2.10 (14162.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:51:34.787618: step 120600, loss = 1.86 (13738.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:51:36.632650: step 120800, loss = 1.99 (13875.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:51:38.507851: step 121000, loss = 1.97 (13651.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:51:42.101984: step 121200, loss = 2.09 (7122.7 examples/sec; 0.018 sec/batch)
2018-01-30 12:51:45.805503: step 121400, loss = 2.07 (6912.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:51:49.865697: step 121600, loss = 1.98 (6305.1 examples/sec; 0.020 sec/batch)
2018-01-30 12:51:53.275262: step 121800, loss = 2.05 (7508.3 examples/sec; 0.017 sec/batch)
2018-01-30 12:51:55.119812: step 122000, loss = 2.09 (13878.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:51:56.952542: step 122200, loss = 2.00 (13968.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:51:59.079760: step 122400, loss = 2.00 (12034.5 examples/sec; 0.011 sec/batch)
2018-01-30 12:52:00.961122: step 122600, loss = 2.04 (13607.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:52:02.776492: step 122800, loss = 1.96 (14101.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:52:06.021163: step 123000, loss = 2.09 (7889.9 examples/sec; 0.016 sec/batch)
2018-01-30 12:52:10.001750: step 123200, loss = 2.16 (6431.2 examples/sec; 0.020 sec/batch)
2018-01-30 12:52:13.714926: step 123400, loss = 2.09 (6894.4 examples/sec; 0.019 sec/batch)
2018-01-30 12:52:17.527831: step 123600, loss = 2.03 (6714.0 examples/sec; 0.019 sec/batch)
2018-01-30 12:52:19.412782: step 123800, loss = 1.91 (13581.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:52:21.266059: step 124000, loss = 2.07 (13813.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:52:23.103447: step 124200, loss = 2.04 (13932.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:52:24.960361: step 124400, loss = 2.04 (13786.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:52:26.826900: step 124600, loss = 2.17 (13715.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:52:29.328387: step 124800, loss = 2.00 (10233.9 examples/sec; 0.013 sec/batch)
2018-01-30 12:52:33.083374: step 125000, loss = 2.06 (6817.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:52:36.824403: step 125200, loss = 2.09 (6843.0 examples/sec; 0.019 sec/batch)
2018-01-30 12:52:40.546441: step 125400, loss = 1.93 (6878.0 examples/sec; 0.019 sec/batch)
2018-01-30 12:52:43.356791: step 125600, loss = 2.04 (9109.2 examples/sec; 0.014 sec/batch)
2018-01-30 12:52:45.166562: step 125800, loss = 1.89 (14145.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:52:47.002220: step 126000, loss = 2.06 (13946.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:52:48.844759: step 126200, loss = 1.91 (13893.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:52:50.705227: step 126400, loss = 1.85 (13760.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:52:52.533547: step 126600, loss = 2.19 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:52:55.674507: step 126800, loss = 2.03 (8150.4 examples/sec; 0.016 sec/batch)
2018-01-30 12:53:01.024554: step 127000, loss = 1.99 (4785.0 examples/sec; 0.027 sec/batch)
2018-01-30 12:53:04.893071: step 127200, loss = 1.86 (6617.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:53:07.241838: step 127400, loss = 2.11 (10899.3 examples/sec; 0.012 sec/batch)
2018-01-30 12:53:09.109213: step 127600, loss = 2.07 (13709.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:53:10.949248: step 127800, loss = 1.93 (13912.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:53:12.793194: step 128000, loss = 2.14 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:53:14.621515: step 128200, loss = 2.01 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:53:16.684235: step 128400, loss = 1.97 (12410.8 examples/sec; 0.010 sec/batch)
2018-01-30 12:53:20.142195: step 128600, loss = 1.94 (7403.2 examples/sec; 0.017 sec/batch)
2018-01-30 12:53:23.852062: step 128800, loss = 2.01 (6900.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:53:27.762084: step 129000, loss = 1.96 (6547.3 examples/sec; 0.020 sec/batch)
2018-01-30 12:53:31.089794: step 129200, loss = 2.28 (7693.0 examples/sec; 0.017 sec/batch)
2018-01-30 12:53:32.925014: step 129400, loss = 2.14 (13949.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:53:34.748340: step 129600, loss = 1.97 (14040.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:53:36.561035: step 129800, loss = 2.07 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:53:38.368179: step 130000, loss = 1.95 (14166.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:53:40.227753: step 130200, loss = 2.11 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:53:43.103060: step 130400, loss = 1.94 (8903.4 examples/sec; 0.014 sec/batch)
2018-01-30 12:53:46.947219: step 130600, loss = 1.87 (6659.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:53:50.806816: step 130800, loss = 2.02 (6632.8 examples/sec; 0.019 sec/batch)
2018-01-30 12:53:54.590201: step 131000, loss = 2.08 (6766.4 examples/sec; 0.019 sec/batch)
2018-01-30 12:53:56.731055: step 131200, loss = 2.07 (11957.8 examples/sec; 0.011 sec/batch)
2018-01-30 12:53:58.850719: step 131400, loss = 1.98 (12077.4 examples/sec; 0.011 sec/batch)
2018-01-30 12:54:00.688282: step 131600, loss = 2.01 (13931.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:02.507827: step 131800, loss = 2.00 (14069.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:04.344921: step 132000, loss = 1.88 (13935.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:06.485774: step 132200, loss = 2.25 (11957.9 examples/sec; 0.011 sec/batch)
2018-01-30 12:54:10.251802: step 132400, loss = 2.13 (6797.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:54:14.092752: step 132600, loss = 2.10 (6665.0 examples/sec; 0.019 sec/batch)
2018-01-30 12:54:17.868795: step 132800, loss = 1.97 (6779.6 examples/sec; 0.019 sec/batch)
2018-01-30 12:54:20.759651: step 133000, loss = 1.88 (8855.5 examples/sec; 0.014 sec/batch)
2018-01-30 12:54:22.583593: step 133200, loss = 1.89 (14035.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:24.438185: step 133400, loss = 2.04 (13803.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:26.282132: step 133600, loss = 2.05 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:28.126078: step 133800, loss = 1.96 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:29.984056: step 134000, loss = 2.00 (13778.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:33.328164: step 134200, loss = 2.10 (7655.3 examples/sec; 0.017 sec/batch)
2018-01-30 12:54:37.359842: step 134400, loss = 1.94 (6349.7 examples/sec; 0.020 sec/batch)
2018-01-30 12:54:41.025959: step 134600, loss = 1.90 (6982.9 examples/sec; 0.018 sec/batch)
2018-01-30 12:54:44.625612: step 134800, loss = 2.04 (7111.8 examples/sec; 0.018 sec/batch)
2018-01-30 12:54:46.453932: step 135000, loss = 2.11 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:48.282253: step 135200, loss = 1.97 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:50.141826: step 135400, loss = 2.09 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:51.954520: step 135600, loss = 2.06 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:53.805405: step 135800, loss = 2.06 (13831.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:54:56.305672: step 136000, loss = 2.04 (10238.9 examples/sec; 0.013 sec/batch)
2018-01-30 12:55:01.634366: step 136200, loss = 2.06 (4804.2 examples/sec; 0.027 sec/batch)
2018-01-30 12:55:05.512704: step 136400, loss = 1.92 (6600.8 examples/sec; 0.019 sec/batch)
2018-01-30 12:55:08.632132: step 136600, loss = 2.06 (8206.6 examples/sec; 0.016 sec/batch)
2018-01-30 12:55:10.484296: step 136800, loss = 1.92 (13821.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:55:12.313832: step 137000, loss = 1.98 (13992.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:55:14.125029: step 137200, loss = 1.96 (14134.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:55:15.968976: step 137400, loss = 1.92 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:55:17.805259: step 137600, loss = 1.86 (13941.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:55:20.727444: step 137800, loss = 2.00 (8760.6 examples/sec; 0.015 sec/batch)
2018-01-30 12:55:24.571604: step 138000, loss = 1.90 (6659.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:55:28.339074: step 138200, loss = 1.91 (6795.0 examples/sec; 0.019 sec/batch)
2018-01-30 12:55:32.241453: step 138400, loss = 1.92 (6560.1 examples/sec; 0.020 sec/batch)
2018-01-30 12:55:34.284637: step 138600, loss = 1.93 (12529.5 examples/sec; 0.010 sec/batch)
2018-01-30 12:55:36.128583: step 138800, loss = 1.85 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:55:37.978034: step 139000, loss = 2.00 (13841.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:55:39.790727: step 139200, loss = 2.01 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:55:41.628174: step 139400, loss = 1.82 (13932.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:55:43.675267: step 139600, loss = 1.93 (12505.5 examples/sec; 0.010 sec/batch)
2018-01-30 12:55:47.394415: step 139800, loss = 1.89 (6883.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:55:51.269828: step 140000, loss = 1.93 (6605.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:55:55.152532: step 140200, loss = 1.81 (6593.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:55:58.135468: step 140400, loss = 1.98 (8582.1 examples/sec; 0.015 sec/batch)
2018-01-30 12:56:00.252933: step 140600, loss = 2.02 (12089.9 examples/sec; 0.011 sec/batch)
2018-01-30 12:56:02.083279: step 140800, loss = 1.73 (13986.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:03.912729: step 141000, loss = 1.97 (13993.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:05.755363: step 141200, loss = 2.01 (13893.2 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:07.614937: step 141400, loss = 1.86 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:11.005924: step 141600, loss = 1.93 (7549.4 examples/sec; 0.017 sec/batch)
2018-01-30 12:56:14.825175: step 141800, loss = 1.85 (6702.9 examples/sec; 0.019 sec/batch)
2018-01-30 12:56:18.797500: step 142000, loss = 1.96 (6444.6 examples/sec; 0.020 sec/batch)
2018-01-30 12:56:22.406158: step 142200, loss = 1.95 (7094.1 examples/sec; 0.018 sec/batch)
2018-01-30 12:56:24.240912: step 142400, loss = 1.95 (13952.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:26.067699: step 142600, loss = 2.01 (14013.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:27.895431: step 142800, loss = 2.02 (14006.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:29.708123: step 143000, loss = 2.07 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:31.535177: step 143200, loss = 1.91 (14011.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:34.316423: step 143400, loss = 1.91 (9204.5 examples/sec; 0.014 sec/batch)
2018-01-30 12:56:38.191837: step 143600, loss = 1.98 (6605.7 examples/sec; 0.019 sec/batch)
2018-01-30 12:56:42.121275: step 143800, loss = 1.94 (6514.9 examples/sec; 0.020 sec/batch)
2018-01-30 12:56:45.933607: step 144000, loss = 1.89 (6715.1 examples/sec; 0.019 sec/batch)
2018-01-30 12:56:48.058025: step 144200, loss = 1.97 (12050.4 examples/sec; 0.011 sec/batch)
2018-01-30 12:56:49.896128: step 144400, loss = 1.81 (13927.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:51.693196: step 144600, loss = 2.01 (14245.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:53.524822: step 144800, loss = 1.87 (13976.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:55.368769: step 145000, loss = 2.03 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:56:57.406768: step 145200, loss = 2.02 (12561.3 examples/sec; 0.010 sec/batch)
2018-01-30 12:57:02.860473: step 145400, loss = 1.97 (4694.1 examples/sec; 0.027 sec/batch)
2018-01-30 12:57:06.589367: step 145600, loss = 1.92 (6865.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:57:10.185899: step 145800, loss = 1.80 (7118.0 examples/sec; 0.018 sec/batch)
2018-01-30 12:57:12.029844: step 146000, loss = 1.94 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:57:13.873790: step 146200, loss = 1.90 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:57:15.706713: step 146400, loss = 2.03 (13966.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:57:17.535035: step 146600, loss = 2.01 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:57:19.371609: step 146800, loss = 1.92 (13939.0 examples/sec; 0.009 sec/batch)
2018-01-30 12:57:21.731236: step 147000, loss = 1.93 (10849.2 examples/sec; 0.012 sec/batch)
2018-01-30 12:57:25.532574: step 147200, loss = 1.91 (6734.5 examples/sec; 0.019 sec/batch)
2018-01-30 12:57:29.482410: step 147400, loss = 1.86 (6481.3 examples/sec; 0.020 sec/batch)
2018-01-30 12:57:33.300564: step 147600, loss = 1.91 (6704.8 examples/sec; 0.019 sec/batch)
2018-01-30 12:57:36.020287: step 147800, loss = 1.94 (9412.7 examples/sec; 0.014 sec/batch)
2018-01-30 12:57:37.847953: step 148000, loss = 1.85 (14006.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:57:39.676273: step 148200, loss = 1.95 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:57:41.512415: step 148400, loss = 1.85 (13942.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:57:43.325108: step 148600, loss = 1.91 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:57:45.169055: step 148800, loss = 1.93 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:57:48.434134: step 149000, loss = 2.00 (7840.5 examples/sec; 0.016 sec/batch)
2018-01-30 12:57:52.135489: step 149200, loss = 2.01 (6916.4 examples/sec; 0.019 sec/batch)
2018-01-30 12:57:55.912223: step 149400, loss = 2.00 (6778.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:58:00.019588: step 149600, loss = 2.07 (6232.7 examples/sec; 0.021 sec/batch)
2018-01-30 12:58:01.880378: step 149800, loss = 2.04 (13757.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:03.703522: step 150000, loss = 2.00 (14041.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:05.519854: step 150200, loss = 1.95 (14094.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:07.357506: step 150400, loss = 2.00 (13930.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:09.201453: step 150600, loss = 1.84 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:11.998626: step 150800, loss = 1.97 (9152.1 examples/sec; 0.014 sec/batch)
2018-01-30 12:58:15.895459: step 151000, loss = 1.95 (6569.4 examples/sec; 0.019 sec/batch)
2018-01-30 12:58:19.780793: step 151200, loss = 1.92 (6588.9 examples/sec; 0.019 sec/batch)
2018-01-30 12:58:23.449952: step 151400, loss = 2.00 (6977.1 examples/sec; 0.018 sec/batch)
2018-01-30 12:58:25.815166: step 151600, loss = 2.05 (10823.5 examples/sec; 0.012 sec/batch)
2018-01-30 12:58:27.695501: step 151800, loss = 2.02 (13614.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:29.532002: step 152000, loss = 1.94 (13939.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:31.414260: step 152200, loss = 2.08 (13600.7 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:33.289460: step 152400, loss = 1.88 (13651.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:35.305301: step 152600, loss = 1.98 (12699.4 examples/sec; 0.010 sec/batch)
2018-01-30 12:58:39.008820: step 152800, loss = 1.76 (6912.3 examples/sec; 0.019 sec/batch)
2018-01-30 12:58:42.656266: step 153000, loss = 1.94 (7018.6 examples/sec; 0.018 sec/batch)
2018-01-30 12:58:46.482442: step 153200, loss = 2.03 (6690.8 examples/sec; 0.019 sec/batch)
2018-01-30 12:58:49.930773: step 153400, loss = 1.90 (7423.9 examples/sec; 0.017 sec/batch)
2018-01-30 12:58:51.790107: step 153600, loss = 1.96 (13768.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:53.587174: step 153800, loss = 1.95 (14245.4 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:55.415494: step 154000, loss = 2.04 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:57.259441: step 154200, loss = 1.91 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:58:59.398296: step 154400, loss = 2.01 (11969.0 examples/sec; 0.011 sec/batch)
2018-01-30 12:59:02.211096: step 154600, loss = 1.98 (9101.3 examples/sec; 0.014 sec/batch)
2018-01-30 12:59:05.961496: step 154800, loss = 1.87 (6825.9 examples/sec; 0.019 sec/batch)
2018-01-30 12:59:09.778882: step 155000, loss = 2.05 (6706.2 examples/sec; 0.019 sec/batch)
2018-01-30 12:59:13.543553: step 155200, loss = 2.03 (6800.1 examples/sec; 0.019 sec/batch)
2018-01-30 12:59:16.143237: step 155400, loss = 2.17 (9847.4 examples/sec; 0.013 sec/batch)
2018-01-30 12:59:18.016708: step 155600, loss = 2.03 (13664.5 examples/sec; 0.009 sec/batch)
2018-01-30 12:59:19.855622: step 155800, loss = 1.95 (13921.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:59:21.793328: step 156000, loss = 1.92 (13211.5 examples/sec; 0.010 sec/batch)
2018-01-30 12:59:23.668228: step 156200, loss = 1.88 (13654.1 examples/sec; 0.009 sec/batch)
2018-01-30 12:59:25.543429: step 156400, loss = 1.88 (13651.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:59:29.153188: step 156600, loss = 1.85 (7091.9 examples/sec; 0.018 sec/batch)
2018-01-30 12:59:33.148943: step 156800, loss = 1.88 (6406.8 examples/sec; 0.020 sec/batch)
2018-01-30 12:59:36.947261: step 157000, loss = 1.88 (6739.8 examples/sec; 0.019 sec/batch)
2018-01-30 12:59:40.444563: step 157200, loss = 1.98 (7319.9 examples/sec; 0.017 sec/batch)
2018-01-30 12:59:42.317170: step 157400, loss = 1.79 (13670.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:59:44.160245: step 157600, loss = 1.98 (13889.8 examples/sec; 0.009 sec/batch)
2018-01-30 12:59:46.035444: step 157800, loss = 2.00 (13651.9 examples/sec; 0.009 sec/batch)
2018-01-30 12:59:47.879391: step 158000, loss = 1.96 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 12:59:49.738965: step 158200, loss = 1.98 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 12:59:52.692404: step 158400, loss = 1.84 (8667.9 examples/sec; 0.015 sec/batch)
2018-01-30 12:59:56.411551: step 158600, loss = 1.97 (6883.3 examples/sec; 0.019 sec/batch)
2018-01-30 13:00:02.467335: step 158800, loss = 1.86 (4227.4 examples/sec; 0.030 sec/batch)
2018-01-30 13:00:04.322183: step 159000, loss = 2.01 (13801.7 examples/sec; 0.009 sec/batch)
2018-01-30 13:00:06.196116: step 159200, loss = 1.93 (13661.1 examples/sec; 0.009 sec/batch)
2018-01-30 13:00:08.011533: step 159400, loss = 1.84 (14101.5 examples/sec; 0.009 sec/batch)
2018-01-30 13:00:09.844459: step 159600, loss = 1.98 (13966.7 examples/sec; 0.009 sec/batch)
2018-01-30 13:00:11.670546: step 159800, loss = 1.92 (14019.1 examples/sec; 0.009 sec/batch)
2018-01-30 13:00:13.901664: step 160000, loss = 1.92 (11474.1 examples/sec; 0.011 sec/batch)
2018-01-30 13:00:17.759610: step 160200, loss = 1.94 (6635.7 examples/sec; 0.019 sec/batch)
2018-01-30 13:00:21.323913: step 160400, loss = 2.10 (7182.3 examples/sec; 0.018 sec/batch)
2018-01-30 13:00:25.080997: step 160600, loss = 1.93 (6813.8 examples/sec; 0.019 sec/batch)
2018-01-30 13:00:28.337492: step 160800, loss = 1.91 (7861.2 examples/sec; 0.016 sec/batch)
2018-01-30 13:00:30.181435: step 161000, loss = 1.88 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:00:32.025781: step 161200, loss = 2.02 (13880.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:00:33.881293: step 161400, loss = 1.91 (13796.7 examples/sec; 0.009 sec/batch)
2018-01-30 13:00:35.739286: step 161600, loss = 2.01 (13778.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:00:37.532473: step 161800, loss = 1.82 (14276.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:00:40.235886: step 162000, loss = 1.93 (9469.5 examples/sec; 0.014 sec/batch)
2018-01-30 13:00:44.017540: step 162200, loss = 2.04 (6769.5 examples/sec; 0.019 sec/batch)
2018-01-30 13:00:47.854338: step 162400, loss = 1.87 (6672.2 examples/sec; 0.019 sec/batch)
2018-01-30 13:00:51.779881: step 162600, loss = 1.85 (6521.4 examples/sec; 0.020 sec/batch)
2018-01-30 13:00:54.402070: step 162800, loss = 1.87 (9762.8 examples/sec; 0.013 sec/batch)
2018-01-30 13:00:56.201752: step 163000, loss = 1.98 (14224.7 examples/sec; 0.009 sec/batch)
2018-01-30 13:00:58.063525: step 163200, loss = 1.98 (13750.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:01:00.166674: step 163400, loss = 1.92 (12172.2 examples/sec; 0.011 sec/batch)
2018-01-30 13:01:02.010619: step 163600, loss = 1.95 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:01:03.930727: step 163800, loss = 1.97 (13332.6 examples/sec; 0.010 sec/batch)
2018-01-30 13:01:07.431100: step 164000, loss = 1.90 (7313.5 examples/sec; 0.018 sec/batch)
2018-01-30 13:01:11.447153: step 164200, loss = 1.96 (6374.4 examples/sec; 0.020 sec/batch)
2018-01-30 13:01:15.135946: step 164400, loss = 2.05 (6939.9 examples/sec; 0.018 sec/batch)
2018-01-30 13:01:18.632926: step 164600, loss = 2.01 (7320.6 examples/sec; 0.017 sec/batch)
2018-01-30 13:01:20.459609: step 164800, loss = 1.85 (14014.5 examples/sec; 0.009 sec/batch)
2018-01-30 13:01:22.287931: step 165000, loss = 1.95 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:01:24.111550: step 165200, loss = 1.95 (14038.0 examples/sec; 0.009 sec/batch)
2018-01-30 13:01:25.986750: step 165400, loss = 1.94 (13651.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:01:27.819888: step 165600, loss = 1.99 (13965.1 examples/sec; 0.009 sec/batch)
2018-01-30 13:01:30.320155: step 165800, loss = 2.04 (10238.9 examples/sec; 0.013 sec/batch)
2018-01-30 13:01:34.123277: step 166000, loss = 2.04 (6731.3 examples/sec; 0.019 sec/batch)
2018-01-30 13:01:37.836726: step 166200, loss = 1.87 (6893.9 examples/sec; 0.019 sec/batch)
2018-01-30 13:01:41.810294: step 166400, loss = 2.03 (6442.6 examples/sec; 0.020 sec/batch)
2018-01-30 13:01:44.350656: step 166600, loss = 1.89 (10077.3 examples/sec; 0.013 sec/batch)
2018-01-30 13:01:46.186537: step 166800, loss = 1.87 (13944.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:01:48.006451: step 167000, loss = 1.95 (14066.6 examples/sec; 0.009 sec/batch)
2018-01-30 13:01:49.834770: step 167200, loss = 1.93 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:01:51.663091: step 167400, loss = 1.93 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:01:53.507037: step 167600, loss = 1.93 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:01:57.069918: step 167800, loss = 1.91 (7185.2 examples/sec; 0.018 sec/batch)
2018-01-30 13:02:02.414236: step 168000, loss = 2.01 (4790.1 examples/sec; 0.027 sec/batch)
2018-01-30 13:02:06.227144: step 168200, loss = 1.97 (6714.0 examples/sec; 0.019 sec/batch)
2018-01-30 13:02:08.242984: step 168400, loss = 1.92 (12699.4 examples/sec; 0.010 sec/batch)
2018-01-30 13:02:10.066158: step 168600, loss = 1.95 (14041.4 examples/sec; 0.009 sec/batch)
2018-01-30 13:02:11.947877: step 168800, loss = 1.98 (13604.6 examples/sec; 0.009 sec/batch)
2018-01-30 13:02:13.756172: step 169000, loss = 1.84 (14157.0 examples/sec; 0.009 sec/batch)
2018-01-30 13:02:15.597091: step 169200, loss = 1.92 (13906.1 examples/sec; 0.009 sec/batch)
2018-01-30 13:02:17.806042: step 169400, loss = 1.99 (11589.2 examples/sec; 0.011 sec/batch)
2018-01-30 13:02:21.853348: step 169600, loss = 1.82 (6325.2 examples/sec; 0.020 sec/batch)
2018-01-30 13:02:25.710712: step 169800, loss = 1.94 (6636.7 examples/sec; 0.019 sec/batch)
2018-01-30 13:02:29.484750: step 170000, loss = 1.85 (6783.2 examples/sec; 0.019 sec/batch)
2018-01-30 13:02:32.275707: step 170200, loss = 2.00 (9172.5 examples/sec; 0.014 sec/batch)
2018-01-30 13:02:34.114437: step 170400, loss = 1.98 (13922.7 examples/sec; 0.009 sec/batch)
2018-01-30 13:02:35.948821: step 170600, loss = 1.80 (13955.6 examples/sec; 0.009 sec/batch)
2018-01-30 13:02:37.786521: step 170800, loss = 1.90 (13930.5 examples/sec; 0.009 sec/batch)
2018-01-30 13:02:39.630468: step 171000, loss = 1.93 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:02:41.458786: step 171200, loss = 1.85 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:02:45.009148: step 171400, loss = 1.98 (7210.5 examples/sec; 0.018 sec/batch)
2018-01-30 13:02:48.674570: step 171600, loss = 1.82 (6984.2 examples/sec; 0.018 sec/batch)
2018-01-30 13:02:52.466539: step 171800, loss = 1.84 (6751.1 examples/sec; 0.019 sec/batch)
2018-01-30 13:02:56.148305: step 172000, loss = 1.86 (6953.2 examples/sec; 0.018 sec/batch)
2018-01-30 13:02:57.965992: step 172200, loss = 1.89 (14083.8 examples/sec; 0.009 sec/batch)
2018-01-30 13:03:00.065182: step 172400, loss = 1.91 (12195.2 examples/sec; 0.010 sec/batch)
2018-01-30 13:03:01.923482: step 172600, loss = 1.77 (13776.0 examples/sec; 0.009 sec/batch)
2018-01-30 13:03:03.741263: step 172800, loss = 2.17 (14083.1 examples/sec; 0.009 sec/batch)
2018-01-30 13:03:05.585210: step 173000, loss = 1.90 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:03:08.413637: step 173200, loss = 1.98 (9051.0 examples/sec; 0.014 sec/batch)
2018-01-30 13:03:12.117157: step 173400, loss = 1.93 (6912.3 examples/sec; 0.019 sec/batch)
2018-01-30 13:03:15.867556: step 173600, loss = 1.75 (6825.9 examples/sec; 0.019 sec/batch)
2018-01-30 13:03:19.645235: step 173800, loss = 1.89 (6776.6 examples/sec; 0.019 sec/batch)
2018-01-30 13:03:22.109182: step 174000, loss = 2.02 (10389.8 examples/sec; 0.012 sec/batch)
2018-01-30 13:03:24.125021: step 174200, loss = 1.92 (12699.4 examples/sec; 0.010 sec/batch)
2018-01-30 13:03:26.218995: step 174400, loss = 1.73 (12225.6 examples/sec; 0.010 sec/batch)
2018-01-30 13:03:28.244955: step 174600, loss = 1.84 (12636.0 examples/sec; 0.010 sec/batch)
2018-01-30 13:03:30.228730: step 174800, loss = 1.98 (12904.7 examples/sec; 0.010 sec/batch)
2018-01-30 13:03:32.827767: step 175000, loss = 1.86 (9849.8 examples/sec; 0.013 sec/batch)
2018-01-30 13:03:36.710785: step 175200, loss = 1.87 (6592.8 examples/sec; 0.019 sec/batch)
2018-01-30 13:03:40.550846: step 175400, loss = 2.00 (6666.6 examples/sec; 0.019 sec/batch)
2018-01-30 13:03:44.249683: step 175600, loss = 1.90 (6921.1 examples/sec; 0.018 sec/batch)
2018-01-30 13:03:46.920675: step 175800, loss = 2.02 (9584.5 examples/sec; 0.013 sec/batch)
2018-01-30 13:03:48.801688: step 176000, loss = 1.92 (13609.7 examples/sec; 0.009 sec/batch)
2018-01-30 13:03:50.614381: step 176200, loss = 1.85 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 13:03:52.494134: step 176400, loss = 2.06 (13618.8 examples/sec; 0.009 sec/batch)
2018-01-30 13:03:54.306827: step 176600, loss = 1.99 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 13:03:56.213280: step 176800, loss = 2.07 (13428.1 examples/sec; 0.010 sec/batch)
2018-01-30 13:04:01.588854: step 177000, loss = 1.94 (4762.3 examples/sec; 0.027 sec/batch)
2018-01-30 13:04:05.542400: step 177200, loss = 1.93 (6475.2 examples/sec; 0.020 sec/batch)
2018-01-30 13:04:09.332324: step 177400, loss = 1.87 (6754.8 examples/sec; 0.019 sec/batch)
2018-01-30 13:04:11.248761: step 177600, loss = 2.02 (13358.1 examples/sec; 0.010 sec/batch)
2018-01-30 13:04:13.077081: step 177800, loss = 2.04 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:04:14.912185: step 178000, loss = 1.77 (13950.2 examples/sec; 0.009 sec/batch)
2018-01-30 13:04:16.743399: step 178200, loss = 1.82 (13979.8 examples/sec; 0.009 sec/batch)
2018-01-30 13:04:18.560067: step 178400, loss = 1.90 (14091.7 examples/sec; 0.009 sec/batch)
2018-01-30 13:04:20.779053: step 178600, loss = 1.94 (11536.8 examples/sec; 0.011 sec/batch)
2018-01-30 13:04:24.482573: step 178800, loss = 1.86 (6912.3 examples/sec; 0.019 sec/batch)
2018-01-30 13:04:28.404866: step 179000, loss = 1.95 (6526.8 examples/sec; 0.020 sec/batch)
2018-01-30 13:04:32.045249: step 179200, loss = 1.91 (7032.2 examples/sec; 0.018 sec/batch)
2018-01-30 13:04:35.209272: step 179400, loss = 1.80 (8091.0 examples/sec; 0.016 sec/batch)
2018-01-30 13:04:37.039751: step 179600, loss = 1.96 (13985.4 examples/sec; 0.009 sec/batch)
2018-01-30 13:04:38.880879: step 179800, loss = 2.00 (13904.5 examples/sec; 0.009 sec/batch)
2018-01-30 13:04:40.727054: step 180000, loss = 1.88 (13866.5 examples/sec; 0.009 sec/batch)
2018-01-30 13:04:42.555375: step 180200, loss = 1.80 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:04:44.383694: step 180400, loss = 1.96 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:04:46.962095: step 180600, loss = 1.87 (9928.6 examples/sec; 0.013 sec/batch)
2018-01-30 13:04:50.603108: step 180800, loss = 2.01 (7031.0 examples/sec; 0.018 sec/batch)
2018-01-30 13:04:54.119108: step 181000, loss = 1.85 (7281.0 examples/sec; 0.018 sec/batch)
2018-01-30 13:04:57.980868: step 181200, loss = 1.87 (6629.1 examples/sec; 0.019 sec/batch)
2018-01-30 13:05:01.174825: step 181400, loss = 2.02 (8015.1 examples/sec; 0.016 sec/batch)
2018-01-30 13:05:03.017257: step 181600, loss = 1.86 (13894.7 examples/sec; 0.009 sec/batch)
2018-01-30 13:05:04.862397: step 181800, loss = 1.86 (13874.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:05:06.727234: step 182000, loss = 1.78 (13727.7 examples/sec; 0.009 sec/batch)
2018-01-30 13:05:08.553500: step 182200, loss = 1.91 (14017.7 examples/sec; 0.009 sec/batch)
2018-01-30 13:05:11.022514: step 182400, loss = 1.81 (10368.5 examples/sec; 0.012 sec/batch)
2018-01-30 13:05:14.897927: step 182600, loss = 1.93 (6605.7 examples/sec; 0.019 sec/batch)
2018-01-30 13:05:18.570194: step 182800, loss = 1.86 (6971.2 examples/sec; 0.018 sec/batch)
2018-01-30 13:05:22.148700: step 183000, loss = 2.03 (7153.8 examples/sec; 0.018 sec/batch)
2018-01-30 13:05:25.178228: step 183200, loss = 2.03 (8450.2 examples/sec; 0.015 sec/batch)
2018-01-30 13:05:26.975296: step 183400, loss = 2.06 (14245.4 examples/sec; 0.009 sec/batch)
2018-01-30 13:05:28.834869: step 183600, loss = 1.94 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 13:05:30.694442: step 183800, loss = 2.05 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 13:05:32.511528: step 184000, loss = 1.85 (14088.5 examples/sec; 0.009 sec/batch)
2018-01-30 13:05:34.379528: step 184200, loss = 2.03 (13704.5 examples/sec; 0.009 sec/batch)
2018-01-30 13:05:37.557623: step 184400, loss = 1.95 (8055.1 examples/sec; 0.016 sec/batch)
2018-01-30 13:05:41.261562: step 184600, loss = 1.97 (6911.6 examples/sec; 0.019 sec/batch)
2018-01-30 13:05:45.098315: step 184800, loss = 2.06 (6672.3 examples/sec; 0.019 sec/batch)
2018-01-30 13:05:48.971686: step 185000, loss = 1.91 (6609.2 examples/sec; 0.019 sec/batch)
2018-01-30 13:05:51.050034: step 185200, loss = 2.05 (12317.5 examples/sec; 0.010 sec/batch)
2018-01-30 13:05:52.878534: step 185400, loss = 1.87 (14000.5 examples/sec; 0.009 sec/batch)
2018-01-30 13:05:54.722480: step 185600, loss = 2.02 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:05:56.566426: step 185800, loss = 1.99 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:05:58.363492: step 186000, loss = 1.92 (14245.4 examples/sec; 0.009 sec/batch)
2018-01-30 13:06:00.838353: step 186200, loss = 1.92 (10344.0 examples/sec; 0.012 sec/batch)
2018-01-30 13:06:04.588753: step 186400, loss = 2.01 (6825.9 examples/sec; 0.019 sec/batch)
2018-01-30 13:06:08.357070: step 186600, loss = 1.93 (6793.5 examples/sec; 0.019 sec/batch)
2018-01-30 13:06:12.181240: step 186800, loss = 1.85 (6694.3 examples/sec; 0.019 sec/batch)
2018-01-30 13:06:15.291881: step 187000, loss = 1.92 (8229.8 examples/sec; 0.016 sec/batch)
2018-01-30 13:06:17.135828: step 187200, loss = 1.85 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:06:18.983527: step 187400, loss = 1.84 (13855.1 examples/sec; 0.009 sec/batch)
2018-01-30 13:06:20.796220: step 187600, loss = 1.94 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 13:06:22.632385: step 187800, loss = 1.97 (13942.1 examples/sec; 0.009 sec/batch)
2018-01-30 13:06:24.445079: step 188000, loss = 1.83 (14122.6 examples/sec; 0.009 sec/batch)
2018-01-30 13:06:27.586038: step 188200, loss = 2.09 (8150.4 examples/sec; 0.016 sec/batch)
2018-01-30 13:06:31.383318: step 188400, loss = 1.92 (6741.7 examples/sec; 0.019 sec/batch)
2018-01-30 13:06:35.230158: step 188600, loss = 1.89 (6654.8 examples/sec; 0.019 sec/batch)
2018-01-30 13:06:39.136260: step 188800, loss = 1.95 (6553.8 examples/sec; 0.020 sec/batch)
2018-01-30 13:06:41.115837: step 189000, loss = 1.92 (12932.1 examples/sec; 0.010 sec/batch)
2018-01-30 13:06:42.944157: step 189200, loss = 2.00 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:06:44.810113: step 189400, loss = 1.93 (13719.5 examples/sec; 0.009 sec/batch)
2018-01-30 13:06:46.638433: step 189600, loss = 1.93 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:06:48.488270: step 189800, loss = 1.85 (13839.1 examples/sec; 0.009 sec/batch)
2018-01-30 13:06:50.922944: step 190000, loss = 1.92 (10514.8 examples/sec; 0.012 sec/batch)
2018-01-30 13:06:54.824948: step 190200, loss = 1.90 (6560.7 examples/sec; 0.020 sec/batch)
2018-01-30 13:07:00.621264: step 190400, loss = 1.85 (4416.6 examples/sec; 0.029 sec/batch)
2018-01-30 13:07:03.090278: step 190600, loss = 2.01 (10368.5 examples/sec; 0.012 sec/batch)
2018-01-30 13:07:04.918597: step 190800, loss = 1.93 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:07:06.736354: step 191000, loss = 2.05 (14083.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:07:08.602789: step 191200, loss = 1.90 (13716.0 examples/sec; 0.009 sec/batch)
2018-01-30 13:07:10.446736: step 191400, loss = 1.93 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:07:12.306312: step 191600, loss = 1.89 (13766.6 examples/sec; 0.009 sec/batch)
2018-01-30 13:07:15.541030: step 191800, loss = 1.82 (7914.1 examples/sec; 0.016 sec/batch)
2018-01-30 13:07:19.213296: step 192000, loss = 1.93 (6971.2 examples/sec; 0.018 sec/batch)
2018-01-30 13:07:22.760549: step 192200, loss = 2.07 (7216.9 examples/sec; 0.018 sec/batch)
2018-01-30 13:07:26.500244: step 192400, loss = 1.92 (6845.5 examples/sec; 0.019 sec/batch)
2018-01-30 13:07:28.896853: step 192600, loss = 1.99 (10681.8 examples/sec; 0.012 sec/batch)
2018-01-30 13:07:30.740801: step 192800, loss = 1.92 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:07:32.584747: step 193000, loss = 1.85 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:07:34.394527: step 193200, loss = 1.92 (14145.4 examples/sec; 0.009 sec/batch)
2018-01-30 13:07:36.220296: step 193400, loss = 1.92 (14021.5 examples/sec; 0.009 sec/batch)
2018-01-30 13:07:38.117104: step 193600, loss = 1.90 (13496.4 examples/sec; 0.009 sec/batch)
2018-01-30 13:07:41.851878: step 193800, loss = 1.93 (6854.5 examples/sec; 0.019 sec/batch)
2018-01-30 13:07:45.633531: step 194000, loss = 2.04 (6769.5 examples/sec; 0.019 sec/batch)
2018-01-30 13:07:49.492116: step 194200, loss = 1.98 (6634.6 examples/sec; 0.019 sec/batch)
2018-01-30 13:07:52.904469: step 194400, loss = 1.86 (7502.2 examples/sec; 0.017 sec/batch)
2018-01-30 13:07:54.748416: step 194600, loss = 1.87 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:07:56.576735: step 194800, loss = 1.94 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:07:58.405055: step 195000, loss = 1.87 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:08:00.542542: step 195200, loss = 1.92 (11976.7 examples/sec; 0.011 sec/batch)
2018-01-30 13:08:02.386489: step 195400, loss = 1.90 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:08:05.782409: step 195600, loss = 2.00 (7538.5 examples/sec; 0.017 sec/batch)
2018-01-30 13:08:09.617609: step 195800, loss = 2.08 (6675.0 examples/sec; 0.019 sec/batch)
2018-01-30 13:08:13.324858: step 196000, loss = 1.93 (6905.4 examples/sec; 0.019 sec/batch)
2018-01-30 13:08:17.122138: step 196200, loss = 1.89 (6741.7 examples/sec; 0.019 sec/batch)
2018-01-30 13:08:18.980006: step 196400, loss = 1.99 (13779.2 examples/sec; 0.009 sec/batch)
2018-01-30 13:08:20.804888: step 196600, loss = 1.90 (14028.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:08:22.634961: step 196800, loss = 1.91 (13988.5 examples/sec; 0.009 sec/batch)
2018-01-30 13:08:24.463281: step 197000, loss = 1.94 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:08:26.307228: step 197200, loss = 1.89 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:08:28.791867: step 197400, loss = 1.89 (10303.3 examples/sec; 0.012 sec/batch)
2018-01-30 13:08:32.682909: step 197600, loss = 1.94 (6579.2 examples/sec; 0.019 sec/batch)
2018-01-30 13:08:36.558322: step 197800, loss = 1.95 (6605.7 examples/sec; 0.019 sec/batch)
2018-01-30 13:08:40.480614: step 198000, loss = 1.91 (6526.8 examples/sec; 0.020 sec/batch)
2018-01-30 13:08:42.777735: step 198200, loss = 1.86 (11144.4 examples/sec; 0.011 sec/batch)
2018-01-30 13:08:44.621681: step 198400, loss = 1.91 (13883.3 examples/sec; 0.009 sec/batch)
2018-01-30 13:08:46.450001: step 198600, loss = 1.90 (14001.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:08:48.278231: step 198800, loss = 1.92 (14002.6 examples/sec; 0.009 sec/batch)
2018-01-30 13:08:50.114684: step 199000, loss = 1.72 (13939.9 examples/sec; 0.009 sec/batch)
2018-01-30 13:08:51.962901: step 199200, loss = 1.89 (13851.2 examples/sec; 0.009 sec/batch)
2018-01-30 13:08:55.440235: step 199400, loss = 1.93 (7362.0 examples/sec; 0.017 sec/batch)
2018-01-30 13:09:01.352240: step 199600, loss = 2.04 (4330.2 examples/sec; 0.030 sec/batch)
2018-01-30 13:09:04.743226: step 199800, loss = 1.89 (7549.4 examples/sec; 0.017 sec/batch)

